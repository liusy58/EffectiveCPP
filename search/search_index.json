{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"I will update my reading notes every day. TODO: [ ] 2022 [x] Morden CPP [ ] What Every Programmer Should Know About Memory [ ] DDIA [ ] C++ Concurrency in Action PDF [ ] Guru of the Week is a regular series of C++ programming problems created and written by Herb Sutter. [ ] CPP best practices [ ] C++ patterns [ ] Crafting Interpreters [ ] \u73b0\u4ee3 C++ \u5b9e\u6218 30 \u8bb2 [ ] The Essentials : Linux Basics TOOLS: Online C++ asm code generator Online editor explainshell","title":"Home"},{"location":"Bookmarks/","text":"Here I will put some websites in case of forgiving. The Black Magic of (Java) Method Dispatch RednaxelaFX","title":"Index"},{"location":"C%2B%2B/","text":"[ ] Guru of the Week is a regular series of C++ programming problems created and written by Herb Sutter. [ ] Modern C++ Tutorial:C++11/14/17/20 On the Fly [ ] cpp best practices [ ] c++ patterns","title":"Index"},{"location":"C%2B%2B/C%2B%2B%20Concurrency%20in%20Action%20by%20Anthony%20Williams/","text":"2.1 \u542f\u52a8\u7ebf\u7a0b \u00b6 launch_a_thread1.cpp void do_some_work (); std :: thread my_thread ( do_some_work ); launch_a_thread2.cpp class background_task { public : void operator ()() const { do_something (); do_something_else (); } }; background_task f ; std :: thread my_thread ( f ); launch_a_thread1.cpp \u663e\u793a\u4e86\u76f4\u63a5\u5c06\u51fd\u6570\u4f20\u9012\u7ed9thread\u7684\u8c03\u7528\u65b9\u5f0f\uff0c launch_a_thread2.cpp \u663e\u793a\u4e86\u4f20\u9012\u4e00\u4e2acallable\u7684\u7c7b\u578b\u7684\u8c03\u7528\u65b9\u5f0f\u3002 C++ vexing parse test1.cpp std :: thread my_thread ( background_task ()); \u8fd9\u4e2a\u5e76\u4e0d\u662f\u542f\u52a8\u4e00\u4e2a\u7ebf\u7a0b\uff0c\u8fd9\u662f\u58f0\u660e\u4e00\u4e2a\u51fd\u6570\uff0c\u6709\u4e00\u4e2a\u53c2\u6570\uff0c\u53c2\u6570\u7c7b\u578b\u662f pointer-to-a-function-taking-no-parameters-and-returning-a-background_task-object","title":"C++ Concurrency in Action by Anthony Williams"},{"location":"C%2B%2B/C%2B%2B%20Concurrency%20in%20Action%20by%20Anthony%20Williams/#21-\u542f\u52a8\u7ebf\u7a0b","text":"launch_a_thread1.cpp void do_some_work (); std :: thread my_thread ( do_some_work ); launch_a_thread2.cpp class background_task { public : void operator ()() const { do_something (); do_something_else (); } }; background_task f ; std :: thread my_thread ( f ); launch_a_thread1.cpp \u663e\u793a\u4e86\u76f4\u63a5\u5c06\u51fd\u6570\u4f20\u9012\u7ed9thread\u7684\u8c03\u7528\u65b9\u5f0f\uff0c launch_a_thread2.cpp \u663e\u793a\u4e86\u4f20\u9012\u4e00\u4e2acallable\u7684\u7c7b\u578b\u7684\u8c03\u7528\u65b9\u5f0f\u3002 C++ vexing parse test1.cpp std :: thread my_thread ( background_task ()); \u8fd9\u4e2a\u5e76\u4e0d\u662f\u542f\u52a8\u4e00\u4e2a\u7ebf\u7a0b\uff0c\u8fd9\u662f\u58f0\u660e\u4e00\u4e2a\u51fd\u6570\uff0c\u6709\u4e00\u4e2a\u53c2\u6570\uff0c\u53c2\u6570\u7c7b\u578b\u662f pointer-to-a-function-taking-no-parameters-and-returning-a-background_task-object","title":"2.1 \u542f\u52a8\u7ebf\u7a0b"},{"location":"C%2B%2B/MordenCPP/","text":"2. \u8bed\u8a00\u53ef\u7528\u6027\u7684\u5f3a\u5316 \u00b6 2.1 nullptr \u00b6 nullptr \u7684\u51fa\u73b0\u662f\u4e3a\u4e86\u66ff\u4ee3 NULL \u3002\u8fd9\u4e3b\u8981\u662f\u56e0\u4e3a NULL \u4f1a\u5b58\u5728\u5f88\u591a\u7684\u95ee\u9898\u3002\u7f16\u8bd1\u5668\u4f1a\u5c06 NULL \u770b\u4f5c 0 \u6216\u8005 (void*)0 \u3002\u5bf9\u4e8e\u90a3\u4e9b\u5c06 NULL \u770b\u4f5c (void*)0 \u7684\u7f16\u8bd1\u5668\u6765\u8bf4\uff0c\u56e0\u4e3a C++ \u4e0d\u5141\u8bb8\u76f4\u63a5\u5c06 void* \u8fdb\u884c\u9690\u5f0f\u8f6c\u5316\uff0c\u90a3\u4e48\u5bf9\u4e8e\u4e00\u4e2a\u5f88\u7b80\u5355\u7684\u8d4b\u503c\u8bed\u53e5 char*ptr = NULL \u90fd\u4f1a\u62a5\u9519\uff0c\u5341\u5206\u9ebb\u70e6\uff0c\u5bf9\u4e8e\u90a3\u4e9b\u90a3\u4e9b\u5c06 NULL \u770b\u4f5c 0 \u7684\u7f16\u8bd1\u5668\u6765\u8bf4\uff0c\u4f9d\u7136\u6709\u95ee\u9898\u5b58\u5728\uff0c\u5bf9\u4e8e\u4e0b\u9762\u4ee3\u7801 test.c void foo ( char * ); void foo ( int ); \u90a3\u4e48\u5982\u679c\u8c03\u7528 foo(NULL) \u4f1a\u5b58\u5728\u4e8c\u4e49\u6027\uff0c\u56e0\u4e3a\u4e24\u4e2a\u51fd\u6570\u90fd\u53ef\u4ee5\u8c03\u7528\u3002 \u4e3a\u4e86\u89e3\u51b3\u4e0a\u9762\u7684\u95ee\u9898\uff0c C++11 \u5f15\u5165\u4e86 nullptr \u5173\u952e\u5b57\uff0c\u5b83\u80fd\u591f\u9690\u5f0f\u8f6c\u6362\u6210\u4e3a\u4efb\u4f55\u6307\u9488\u6216\u548c\u6210\u5458\u6307\u9488\u7684\u7c7b\u578b\u3002 2.2 constexpr \u00b6 constexpr \u7684\u51fa\u73b0\u662f\u4e3a\u4e86\u89e3\u51b3\u4e0b\u9762\u7684\u95ee\u9898 src.cpp const int len = 10; int array[len]; \u5c3d\u7ba1\u73b0\u5728\u5f88\u591a\u7f16\u8bd1\u5668\u5df2\u7ecf\u5141\u8bb8\u4e0a\u9762\u4ee3\u7801\u6b63\u5e38\u6267\u884c\uff0c\u4f46\u662f\u5176\u5b9e\u8fd9\u4e2a\u4ee3\u7801\u662f\u6709\u9519\u8bef\u7684\uff0c","title":"MordenCPP"},{"location":"C%2B%2B/MordenCPP/#2-\u8bed\u8a00\u53ef\u7528\u6027\u7684\u5f3a\u5316","text":"","title":"2. \u8bed\u8a00\u53ef\u7528\u6027\u7684\u5f3a\u5316"},{"location":"C%2B%2B/MordenCPP/#21-nullptr","text":"nullptr \u7684\u51fa\u73b0\u662f\u4e3a\u4e86\u66ff\u4ee3 NULL \u3002\u8fd9\u4e3b\u8981\u662f\u56e0\u4e3a NULL \u4f1a\u5b58\u5728\u5f88\u591a\u7684\u95ee\u9898\u3002\u7f16\u8bd1\u5668\u4f1a\u5c06 NULL \u770b\u4f5c 0 \u6216\u8005 (void*)0 \u3002\u5bf9\u4e8e\u90a3\u4e9b\u5c06 NULL \u770b\u4f5c (void*)0 \u7684\u7f16\u8bd1\u5668\u6765\u8bf4\uff0c\u56e0\u4e3a C++ \u4e0d\u5141\u8bb8\u76f4\u63a5\u5c06 void* \u8fdb\u884c\u9690\u5f0f\u8f6c\u5316\uff0c\u90a3\u4e48\u5bf9\u4e8e\u4e00\u4e2a\u5f88\u7b80\u5355\u7684\u8d4b\u503c\u8bed\u53e5 char*ptr = NULL \u90fd\u4f1a\u62a5\u9519\uff0c\u5341\u5206\u9ebb\u70e6\uff0c\u5bf9\u4e8e\u90a3\u4e9b\u90a3\u4e9b\u5c06 NULL \u770b\u4f5c 0 \u7684\u7f16\u8bd1\u5668\u6765\u8bf4\uff0c\u4f9d\u7136\u6709\u95ee\u9898\u5b58\u5728\uff0c\u5bf9\u4e8e\u4e0b\u9762\u4ee3\u7801 test.c void foo ( char * ); void foo ( int ); \u90a3\u4e48\u5982\u679c\u8c03\u7528 foo(NULL) \u4f1a\u5b58\u5728\u4e8c\u4e49\u6027\uff0c\u56e0\u4e3a\u4e24\u4e2a\u51fd\u6570\u90fd\u53ef\u4ee5\u8c03\u7528\u3002 \u4e3a\u4e86\u89e3\u51b3\u4e0a\u9762\u7684\u95ee\u9898\uff0c C++11 \u5f15\u5165\u4e86 nullptr \u5173\u952e\u5b57\uff0c\u5b83\u80fd\u591f\u9690\u5f0f\u8f6c\u6362\u6210\u4e3a\u4efb\u4f55\u6307\u9488\u6216\u548c\u6210\u5458\u6307\u9488\u7684\u7c7b\u578b\u3002","title":"2.1 nullptr"},{"location":"C%2B%2B/MordenCPP/#22-constexpr","text":"constexpr \u7684\u51fa\u73b0\u662f\u4e3a\u4e86\u89e3\u51b3\u4e0b\u9762\u7684\u95ee\u9898 src.cpp const int len = 10; int array[len]; \u5c3d\u7ba1\u73b0\u5728\u5f88\u591a\u7f16\u8bd1\u5668\u5df2\u7ecf\u5141\u8bb8\u4e0a\u9762\u4ee3\u7801\u6b63\u5e38\u6267\u884c\uff0c\u4f46\u662f\u5176\u5b9e\u8fd9\u4e2a\u4ee3\u7801\u662f\u6709\u9519\u8bef\u7684\uff0c","title":"2.2 constexpr"},{"location":"C%2B%2B/OOPBase/","text":"conversion function Conversion function enables implicit conversion or explicit conversion from a class type to another type. There is an example of conversion function used in std: template < class Alloc > class vector < bool , Alloc > { public : typedef __bit_reference reference ; protected : reference operator []( size_type n ){ return * ( begin () + difference_type ( n )); } }; struct __bit_reference { unsigned int * p ; unsigned int mask ; public : operator bool () const { return ! ( ! ( * p & mask ));} }; pointer-like classes There are 2 kinds of pointer-like classes: smart pointer and iterator. Smart pointer classes must override * and & operators. Iterator need override ++/-- apart from */&. function-like classes Function-like classes are those override () operator so their instances can behave like functions. An example is below: template < class T > struct less { bool operator () ( const T & x , const T & y ) const { return x < y ;} } template example class template function template member template partial specialization template template parameter Static Binding VS. Dynamic Binding Dynamic Binding: virtual function + pointer + upper cast (*(p->vptr[n]))(p)","title":"OOPBase"},{"location":"C%2B%2B/C%2B%2B-DesignPattern/","text":"\u89c6\u9891\u76f4\u8fbe\uff1a C++\u5185\u5b58\u7ba1\u7406\u673a\u5236 \u8bfe\u7a0b\u8bb2\u4e49\u4e0b\u8f7d\u76f4\u8fbe\uff1a slide \u6e90\u4ee3\u7801\u76f4\u8fbe\uff1a code \u5019\u6377\u8001\u5e08 C++ \u7cfb\u5217\u8bfe\u7a0b\u5bfc\u822a\uff1a\uff08\u7f16\u53f7\u987a\u5e8f\u53ef\u4f5c\u4e3a\u5b66\u4e60\u987a\u5e8f\u53c2\u8003\uff09 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0a\uff09-\u57fa\u4e8e\u5bf9\u8c61\u548c\u9762\u5411\u5bf9\u8c61 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0b\uff09-\u517c\u8c08\u5bf9\u8c61\u6a21\u578b C++\u6807\u51c6\u5e93(STL)\u4e0e\u6cdb\u578b\u7f16\u7a0b C++\u65b0\u6807\u51c6-C++11/14 C++\u5185\u5b58\u7ba1\u7406 C++Startup\u63ed\u79d8","title":"Index"},{"location":"C%2B%2B/C%2B%2B-MemoryManagement-HouJie/","text":"\u89c6\u9891\u76f4\u8fbe\uff1a C++\u5185\u5b58\u7ba1\u7406\u673a\u5236 \u8bfe\u7a0b\u8bb2\u4e49\u4e0b\u8f7d\u76f4\u8fbe\uff1a slide \u6e90\u4ee3\u7801\u76f4\u8fbe\uff1a code \u5019\u6377\u8001\u5e08 C++ \u7cfb\u5217\u8bfe\u7a0b\u5bfc\u822a\uff1a\uff08\u7f16\u53f7\u987a\u5e8f\u53ef\u4f5c\u4e3a\u5b66\u4e60\u987a\u5e8f\u53c2\u8003\uff09 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0a\uff09-\u57fa\u4e8e\u5bf9\u8c61\u548c\u9762\u5411\u5bf9\u8c61 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0b\uff09-\u517c\u8c08\u5bf9\u8c61\u6a21\u578b C++\u6807\u51c6\u5e93(STL)\u4e0e\u6cdb\u578b\u7f16\u7a0b C++\u65b0\u6807\u51c6-C++11/14 C++\u5185\u5b58\u7ba1\u7406 C++Startup\u63ed\u79d8 \u8bfe\u7a0b\u7b80\u4ecb \u00b6 \u5185\u5b58\uff08memory\uff0c\u53f0\u6e7e\u672f\u8bed\u79f0\u4e3a\u201c\u8a18\u61b6\u9ad4\u201d\uff09\u662f\u7535\u8111\u4e2d\u7684\u201c\u8111\u201d\u5417\uff1fCPU\u624d\u662f\u8111\uff0c CPU\u624d\u662f\u8ba1\u7b97\u673a\u7684\u4e09\u9b42\u516d\u9b44\u3002\u4f46\u82e5\u6ca1\u6709\u5185\u5b58\uff0c\u4e00\u5207\u53ea\u5b58\u5728\u4e8e\u865a\u65e0\u7f25\u7f08\u95f4\uff0c\u7b49\u540c \u4e8e\u4e0d\u5b58\u5728\u3002 \u5185\u5b58\u66fe\u7ecf\u662f\u6700\u5b9d\u8d35\u4e5f\u6700\u6602\u8d35\u7684\u5468\u8fb9\u8d44\u6e90\uff0c\u73b0\u4ee3\u7a0b\u5e8f\u5458\u65e0\u6cd5\u60f3\u50cfDOS\u65f6\u4ee3\u5bf9\u5185\u5b58 \u7684\u9531\u94e2\u5fc5\u8f83\u3002 \u4ff1\u5f80\u77e3\uff0c\u4e14\u770b\u4eca\u671d\u3002\u6211\u4eec\uff08\u4f3c\u4e4e\uff09\u6709\u7528\u4e0d\u5b8c\u7684\u4fbf\u5b9c\u5185\u5b58\u3002\u4f46\u8868\u8c61\u4e4b\u4e0b\u662f\u64cd\u4f5c\u7cfb\u7edf\u548c \u6807\u51c6\u5e93\u505a\u4e86\u5927\u91cf\u5de5\u4f5c\u3002\u800c\u5982\u679c\u4f60\u5f00\u53d1\u5185\u5b58\u9ad8\u8017\u8f6f\u4ef6\uff0c\u6216\u5904\u4e8e\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e0b\uff08\u4f8b \u5982\u5d4c\u5165\u5f0f\u7cfb\u7edf\uff09\uff0c\u5c31\u6709\u5fc5\u8981\u6df1\u523b\u4e86\u89e3\u64cd\u4f5c\u7cfb\u7edf\u548c\u6807\u51c6\u5e93\u4e3a\u4f60\u6240\u505a\u7684\u5185\u5b58\u7ba1\u7406\uff0c\u751a \u81f3\u9700\u8981\u81ea\u884c\u7ba1\u7406\u5185\u5b58\u3002 \u672c\u8bfe\u7a0b\u5206\u4e3a\u516d\u8bb2\uff1a \u7b2c\u4e00\u8bb2\uff1aPrimitives C++\u8bed\u8a00\u4e2d\u4e0e\u5185\u5b58\u76f8\u5173\u7684\u6240\u6709\u57fa\u7840\u6784\u4ef6\uff08constructs\uff09\uff0c\u5305\u62ecmalloc/free\uff0cnew/delete\uff0c operator new/operator delete\uff0cplacement new/placement delete\uff0c\u6211\u5c06\u63a2\u8ba8\u5b83\u4eec\u7684\u610f \u4e49\u3001\u8fd0\u7528\u65b9\u5f0f\u548c\u91cd\u8f7d\u65b9\u5f0f\u3002\u5e76\u4ee5\u6b64\u5f00\u53d1\u4e00\u4e2a\u6781\u5c0f\u578b\u5185\u5b58\u6c60\uff08memory pool\uff09\u3002 \u7b2c\u4e8c\u8bb2\uff1astd:\uff1aallocator \u6807\u51c6\u5e93\u7684\u5174\u8d77\uff0c\u610f\u5473\u6211\u4eec\u53ef\u4ee5\u6446\u8131\u5185\u5b58\u7ba1\u7406\u7684\u7e41\u590d\u7410\u5c51\uff0c\u76f4\u63a5\u4f7f\u7528\u5bb9\u5668\u3002\u4f46\u662f\u5bb9 \u5668\u80cc\u540e\u7684\u5206\u914d\u5668\uff08allocator\uff09\u6538\u5173\u5bb9\u5668\u7684\u901f\u5ea6\u6027\u80fd\u548c\u7a7a\u95f4\u6027\u80fd\u3002\u6211\u5c06\u6bd4\u8f83Visual C++\uff0c Borland C++\uff0cGNU C++\u6807\u51c6\u5e93\u4e2d\u7684allocator\uff0c\u5e76\u6df1\u5165\u63a2\u7d22\u5176\u4e2d\u6700\u7cbe\u5de7\u7684GNU C++ allocator\u7684\u8bbe\u8ba1\u3002 \u7b2c\u4e09\u8bb2\uff1amalloc/free malloc/free\u662f\u6240\u6709\u5185\u5b58\u7ba1\u7406\u624b\u6bb5\u7684\u6700\u540e\u4e00\u54e9\uff1b\u901a\u8fc7\u5b83\u624d\u548c\u64cd\u4f5c\u7cfb\u7edf\u642d\u4e0a\u7ebf\u3002\u5f53\u7136 \u4f60\u4e5f\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528system API\uff0c\u4f46\u4e0d\u5efa\u8bae\u3002\u56e0\u6b64\u7406\u89e3malloc/free\u7684\u5185\u90e8\u7ba1\u7406\u81f3\u4e3a \u91cd\u8981\u3002\u6211\u5c06\u4ee5Visual C++\u7684CRT\uff08C RunTime Library\uff09\u6240\u5e26\u7684malloc/free\u6e90\u4ee3\u7801 \u4e3a\u57fa\u7840\uff0c\u6df1\u5ea6\u63a2\u7d22\u8fd9\u6700\u57fa\u7840\u6700\u5173\u952e\u7684\u5185\u5b58\u5206\u914d\u4e0e\u91ca\u653e\u51fd\u6570\u3002 \u7b2c\u56db\u8bb2\uff1aloki::allocator \u5373\u4f7f\u77e5\u540d\u5982GNU C++ pool allocator\uff0c\u4e5f\u6709\u5176\u5c0f\u7f3a\u9677\u3002Loki\uff08\u4e00\u5957\u4f5c\u98ce\u524d\u6cbf\u7684\u7a0b\u5e8f \u5e93\uff09\u7684allocator\u8bbe\u8ba1\u7cbe\u7b80\u529f\u80fd\u5b8c\u6574\u51e0\u65e0\u7f3a\u70b9\uff0c\u5f88\u503c\u5f97\u6211\u4eec\u6df1\u7a76\u3002 \u7b2c\u4e94\u8bb2\uff1a\u5176\u4ed6\u4e3b\u9898 \u9664\u4e86std:\uff1aallocator\uff0cGNU C++\u8fd8\u5e26\u4e0d\u5c11allocators\uff0c\u5b83\u4eec\u4e0d\u662f\u6807\u51c6\u5e93\u7684\u4e00\u90e8\u5206\uff0c \u53ef\u89c6\u4e3a\u6807\u51c6\u5e93\u7684\u6269\u5145\u3002\u6211\u5c06\u63a2\u8ba8\u8fd9\u4e9b\u6269\u5145\u7684allocator\uff0c\u7279\u522b\u662fbitmap allocator\u3002 \u6211\u4eec\u8c08\u7684\u4e0d\u53ea\u662f\u5e94\u7528\uff0c\u8fd8\u6df1\u5165\u8bbe\u8ba1\u539f\u7406\u4e0e\u5b9e\u73b0\u624b\u6cd5\u3002\u5728\u7406\u89e3\u4e86\u8fd9\u4e48\u591a\u5e95\u5c42 \uff08Windows Heap\uff0cCRT malloc/free\uff0cC++ new/delete\uff0cC++ allocators\uff09\u4e4b\u540e\uff0c\u4e5f\u8bb8\u4f60\u7ec8 \u4e8e\u604d\u7136\u5927\u609f\uff0c\u518d\u4e0d\u9700\u8981\u81ea\u884c\u7ba1\u7406\u5185\u5b58\u4e86\uff1b\u6216\u4e5f\u8bb8\u4f60\u7ec8\u4e8e\u6709\u80fd\u529b\u60f3\u50cf\uff0c\u8be5\u5728\u4f55\u5904\u4ee5 \u4f55\u79cd\u65b9\u5f0f\u52a0\u5f3a\u5185\u5b58\u7ba1\u7406\u3002 \u4f60\u5c06\u83b7\u5f97\u6574\u4e2avideo\u8bfe\u7a0b\u7684\u5b8c\u6574\u8bb2\u4e49\uff08\u4e5f\u5c31\u662fvideo\u5448\u73b0\u7684\u6bcf\u4e00\u5f20\u6295\u5f71\u7247\u753b\u9762\uff09\uff0c \u548c\u4e00\u4e2a\u5b8c\u6574\u7a0b\u5e8f\u5305\u62ec\u4ee3\u7801\u6587\u4ef6.cpp\u548c\u53ef\u6267\u884c\u6587\u4ef6.exe\u3002\u4f60\u53ef\u4ee5\u5728\u89c6\u542c\u8fc7\u7a0b\u4e2d\u968f\u65f6 \u505c\u683c\u4ed4\u7ec6\u9605\u8bfb\u8bb2\u4e49\uff0c\u7ec6\u7ec6\u5480\u56bc\u6211\u6240\u7ed8\u5236\u7684\u5404\u79cd\u793a\u610f\u56fe\u548c\u6e90\u4ee3\u7801\u4e4b\u95f4\u7684\u6d41\u52a8\u8def \u7ebf\u2014\u2014\u8fd9\u7684\u786e\u5f88\u9700\u8981\u65f6\u95f4\u548c\u8111\u529b\uff0c\u5374\u80fd\u4ee4\u4f60\u8111\u6d1e\u5927\u5f00\u3002 \u4faf\u6377\u7b80\u4ecb\uff1a\u7a0b\u5e8f\u5458\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u53f0\u6e7e\u5de5\u7814\u9662\u526f\u7814\u7a76\u5458\uff0c\u6559\u6388\u3002\u66fe\u4efb\u6559\u4e8e\u4e2d\u575c\u5143 \u667a\u5927\u5b66\u3001\u4e0a\u6d77\u540c\u6d4e\u5927\u5b66\u3001\u5357\u4eac\u5927\u5b66\u3002\u8457\u6709\u300a\u65e0\u8d23\u4efb\u4e66\u8bc4\u300b\u4e09\u5377\u3001\u300a\u6df1\u5165\u6d45\u51faMFC\u300b\u3001 \u300aSTL\u6e90\u7801\u5256\u6790\u300b\u2026\uff0c\u8bd1\u6709\u300aEffective C++\u300b\u300aMore Effective C++\u300b\u300aC++ Primer\u300b \u300aThe C++ Standard Library\u300b\u2026\u3002 \u4ee5\u4e0b\u8fd9\u4efd\u4e0d\u7b97\u592a\u7ec6\u81f4\u7684\u4e3b\u9898\u5212\u5206\uff0c\u534f\u52a9\u60a8\u8ba4\u8bc6\u6574\u4e2a\u8bfe\u7a0b\u5185\u5bb9\uff0c\u4ee5\u53ca\u5728\u89c6\u542c\u8fc7\u7a0b\u4e2d\u6b63\u786e\u7ffb\u627e\u8bb2\u4e49\u3002\u672b\u5c3e\u7684\u7f16\u53f7\u5c31\u662f\u8bb2\u4e49\u7684\u9875\u7801\u3002 \u5185\u5b58\u7ba1\u7406101\u2013\u4ece\u5e73\u5730\u5230\u4e07\u4e08\u9ad8\u697c \u00b6 \u4e3b\u9898\u5212\u5206 \u7b2c\u4e00\u8bb2\uff1aC++\u5185\u5b58\u6784\u4ef6 \u00b6 Overview 1-10 \u5185\u5b58\u5206\u914d\u7684\u6bcf\u4e00\u5c42\u9762 11 \u56db\u4e2a\u57fa\u672c\u5c42\u9762\u7684\u7528\u6cd5 12-14 \u57fa\u672c\u6784\u4ef6\u4e4b\u4e00 new/delete expressions 15-17 \u57fa\u672c\u6784\u4ef6\u4e4b\u4e8c array new/delete 18-21 \u57fa\u672c\u6784\u4ef6\u4e4b\u4e09 placement new/delete 22 \u57fa\u672c\u6784\u4ef6\u4e4b\u5206\u914d\u6d41\u7a0b 23-24 \u57fa\u672c\u6784\u4ef6\u4e4b\u91cd\u8f7d 25-34 Per-class allocator\u7b2c\u4e00\u7248\u672c 35-36 Per-class allocator\u7b2c\u4e8c\u7248\u672c 37-38 Common static allocator\uff08\u7b2c\u4e09\u7248\u672c\uff0939-41 Macro allocator\uff08\u7b2c\u56db\u7248\u672c\uff0942-43 GNU C++ allocator\uff08\u7b2c\u4e94\u7248\u672c\uff09\u6837\u8c8c44 \u6742\u9879\u8ba8\u8bba 45-48 \u7b2c\u4e8c\u8bb2\uff1astd::allocator \u00b6 \u5185\u5b58\u5757\u5e03\u5c40 52 VC6 allocator 53 BC5 allocator 54 GNU allocator 55-60 GNU allocator\u884c\u4e3a\u5256\u6790 61-76 GNU allocator\u6e90\u7801\u5256\u6790 77-87 GNU allocator\u68c0\u8ba8 88-89 GNU allocator\u76d1\u89c6 90-91 GNU allocator\u79fb\u690d\u5230C\u8bed\u8a00 92 \u7b2c\u4e09\u8bb2\uff1amalloc/free \u00b6 VC6\u548cVC10\u7684malloc\u6bd4\u8f83 96-97 Small Block Heap\uff08SBH\uff09\u521d\u59cb\u5316 98-99 SBH\u884c\u4e3a\u5206\u6790\u2013\u5185\u5b58\u5757\u5927\u5c0f\u4e4b\u8ba1\u7b97 100-104 SBH\u884c\u4e3a\u5206\u6790\u2013\u6570\u636e\u7ed3\u6784 105-107 SBH\u884c\u4e3a\u5206\u6790\u2013\u5206\u914d\u4e4b\u8be6\u7ec6\u56fe\u89e3 108 SBH\u884c\u4e3a\u5206\u6790\u2013\u5206\u914d+\u91ca\u653e\u4e4b\u8fde\u7eed\u52a8\u4f5c\u56fe\u89e3 109-115 SBH\u68c0\u8ba8 116-122 \u7b2c\u56db\u8bb2\uff1aLoki:\uff1aallocator \u00b6 \u4e0a\u4e2d\u4e0b\u4e09\u4e2aclasses\u5206\u6790 127 Loki::allocator\u884c\u4e3a\u56fe\u89e3 128-134 class Chunk\u5206\u6790 135-137 class FixedAllocator\u5206\u6790 138-140 Loki::allocator\u68c0\u8ba8 141 \u7b2c\u4e94\u8bb2\uff1aOther Issues \u00b6 GNU C++\u5bf9allocators\u7684\u63cf\u8ff0 144-149 VS2013\u6807\u51c6\u5206\u914d\u5668\u4e0enew_allocator 150 G4.9 \u6807\u51c6\u5206\u914d\u5668\u4e0enew_allocator 151 G4.9 malloc_allocator 152 G4.9 array_allocator 153-155 G4.9 debug_allocator 156 G4.9 _pool_alloc 157-159 G4.9 bitmap_allocator 160-170 G4.9 \u4f7f\u7528G4.9\u5206\u914d\u5668 171-172 -- the end","title":"Index"},{"location":"C%2B%2B/C%2B%2B-MemoryManagement-HouJie/#\u8bfe\u7a0b\u7b80\u4ecb","text":"\u5185\u5b58\uff08memory\uff0c\u53f0\u6e7e\u672f\u8bed\u79f0\u4e3a\u201c\u8a18\u61b6\u9ad4\u201d\uff09\u662f\u7535\u8111\u4e2d\u7684\u201c\u8111\u201d\u5417\uff1fCPU\u624d\u662f\u8111\uff0c CPU\u624d\u662f\u8ba1\u7b97\u673a\u7684\u4e09\u9b42\u516d\u9b44\u3002\u4f46\u82e5\u6ca1\u6709\u5185\u5b58\uff0c\u4e00\u5207\u53ea\u5b58\u5728\u4e8e\u865a\u65e0\u7f25\u7f08\u95f4\uff0c\u7b49\u540c \u4e8e\u4e0d\u5b58\u5728\u3002 \u5185\u5b58\u66fe\u7ecf\u662f\u6700\u5b9d\u8d35\u4e5f\u6700\u6602\u8d35\u7684\u5468\u8fb9\u8d44\u6e90\uff0c\u73b0\u4ee3\u7a0b\u5e8f\u5458\u65e0\u6cd5\u60f3\u50cfDOS\u65f6\u4ee3\u5bf9\u5185\u5b58 \u7684\u9531\u94e2\u5fc5\u8f83\u3002 \u4ff1\u5f80\u77e3\uff0c\u4e14\u770b\u4eca\u671d\u3002\u6211\u4eec\uff08\u4f3c\u4e4e\uff09\u6709\u7528\u4e0d\u5b8c\u7684\u4fbf\u5b9c\u5185\u5b58\u3002\u4f46\u8868\u8c61\u4e4b\u4e0b\u662f\u64cd\u4f5c\u7cfb\u7edf\u548c \u6807\u51c6\u5e93\u505a\u4e86\u5927\u91cf\u5de5\u4f5c\u3002\u800c\u5982\u679c\u4f60\u5f00\u53d1\u5185\u5b58\u9ad8\u8017\u8f6f\u4ef6\uff0c\u6216\u5904\u4e8e\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e0b\uff08\u4f8b \u5982\u5d4c\u5165\u5f0f\u7cfb\u7edf\uff09\uff0c\u5c31\u6709\u5fc5\u8981\u6df1\u523b\u4e86\u89e3\u64cd\u4f5c\u7cfb\u7edf\u548c\u6807\u51c6\u5e93\u4e3a\u4f60\u6240\u505a\u7684\u5185\u5b58\u7ba1\u7406\uff0c\u751a \u81f3\u9700\u8981\u81ea\u884c\u7ba1\u7406\u5185\u5b58\u3002 \u672c\u8bfe\u7a0b\u5206\u4e3a\u516d\u8bb2\uff1a \u7b2c\u4e00\u8bb2\uff1aPrimitives C++\u8bed\u8a00\u4e2d\u4e0e\u5185\u5b58\u76f8\u5173\u7684\u6240\u6709\u57fa\u7840\u6784\u4ef6\uff08constructs\uff09\uff0c\u5305\u62ecmalloc/free\uff0cnew/delete\uff0c operator new/operator delete\uff0cplacement new/placement delete\uff0c\u6211\u5c06\u63a2\u8ba8\u5b83\u4eec\u7684\u610f \u4e49\u3001\u8fd0\u7528\u65b9\u5f0f\u548c\u91cd\u8f7d\u65b9\u5f0f\u3002\u5e76\u4ee5\u6b64\u5f00\u53d1\u4e00\u4e2a\u6781\u5c0f\u578b\u5185\u5b58\u6c60\uff08memory pool\uff09\u3002 \u7b2c\u4e8c\u8bb2\uff1astd:\uff1aallocator \u6807\u51c6\u5e93\u7684\u5174\u8d77\uff0c\u610f\u5473\u6211\u4eec\u53ef\u4ee5\u6446\u8131\u5185\u5b58\u7ba1\u7406\u7684\u7e41\u590d\u7410\u5c51\uff0c\u76f4\u63a5\u4f7f\u7528\u5bb9\u5668\u3002\u4f46\u662f\u5bb9 \u5668\u80cc\u540e\u7684\u5206\u914d\u5668\uff08allocator\uff09\u6538\u5173\u5bb9\u5668\u7684\u901f\u5ea6\u6027\u80fd\u548c\u7a7a\u95f4\u6027\u80fd\u3002\u6211\u5c06\u6bd4\u8f83Visual C++\uff0c Borland C++\uff0cGNU C++\u6807\u51c6\u5e93\u4e2d\u7684allocator\uff0c\u5e76\u6df1\u5165\u63a2\u7d22\u5176\u4e2d\u6700\u7cbe\u5de7\u7684GNU C++ allocator\u7684\u8bbe\u8ba1\u3002 \u7b2c\u4e09\u8bb2\uff1amalloc/free malloc/free\u662f\u6240\u6709\u5185\u5b58\u7ba1\u7406\u624b\u6bb5\u7684\u6700\u540e\u4e00\u54e9\uff1b\u901a\u8fc7\u5b83\u624d\u548c\u64cd\u4f5c\u7cfb\u7edf\u642d\u4e0a\u7ebf\u3002\u5f53\u7136 \u4f60\u4e5f\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528system API\uff0c\u4f46\u4e0d\u5efa\u8bae\u3002\u56e0\u6b64\u7406\u89e3malloc/free\u7684\u5185\u90e8\u7ba1\u7406\u81f3\u4e3a \u91cd\u8981\u3002\u6211\u5c06\u4ee5Visual C++\u7684CRT\uff08C RunTime Library\uff09\u6240\u5e26\u7684malloc/free\u6e90\u4ee3\u7801 \u4e3a\u57fa\u7840\uff0c\u6df1\u5ea6\u63a2\u7d22\u8fd9\u6700\u57fa\u7840\u6700\u5173\u952e\u7684\u5185\u5b58\u5206\u914d\u4e0e\u91ca\u653e\u51fd\u6570\u3002 \u7b2c\u56db\u8bb2\uff1aloki::allocator \u5373\u4f7f\u77e5\u540d\u5982GNU C++ pool allocator\uff0c\u4e5f\u6709\u5176\u5c0f\u7f3a\u9677\u3002Loki\uff08\u4e00\u5957\u4f5c\u98ce\u524d\u6cbf\u7684\u7a0b\u5e8f \u5e93\uff09\u7684allocator\u8bbe\u8ba1\u7cbe\u7b80\u529f\u80fd\u5b8c\u6574\u51e0\u65e0\u7f3a\u70b9\uff0c\u5f88\u503c\u5f97\u6211\u4eec\u6df1\u7a76\u3002 \u7b2c\u4e94\u8bb2\uff1a\u5176\u4ed6\u4e3b\u9898 \u9664\u4e86std:\uff1aallocator\uff0cGNU C++\u8fd8\u5e26\u4e0d\u5c11allocators\uff0c\u5b83\u4eec\u4e0d\u662f\u6807\u51c6\u5e93\u7684\u4e00\u90e8\u5206\uff0c \u53ef\u89c6\u4e3a\u6807\u51c6\u5e93\u7684\u6269\u5145\u3002\u6211\u5c06\u63a2\u8ba8\u8fd9\u4e9b\u6269\u5145\u7684allocator\uff0c\u7279\u522b\u662fbitmap allocator\u3002 \u6211\u4eec\u8c08\u7684\u4e0d\u53ea\u662f\u5e94\u7528\uff0c\u8fd8\u6df1\u5165\u8bbe\u8ba1\u539f\u7406\u4e0e\u5b9e\u73b0\u624b\u6cd5\u3002\u5728\u7406\u89e3\u4e86\u8fd9\u4e48\u591a\u5e95\u5c42 \uff08Windows Heap\uff0cCRT malloc/free\uff0cC++ new/delete\uff0cC++ allocators\uff09\u4e4b\u540e\uff0c\u4e5f\u8bb8\u4f60\u7ec8 \u4e8e\u604d\u7136\u5927\u609f\uff0c\u518d\u4e0d\u9700\u8981\u81ea\u884c\u7ba1\u7406\u5185\u5b58\u4e86\uff1b\u6216\u4e5f\u8bb8\u4f60\u7ec8\u4e8e\u6709\u80fd\u529b\u60f3\u50cf\uff0c\u8be5\u5728\u4f55\u5904\u4ee5 \u4f55\u79cd\u65b9\u5f0f\u52a0\u5f3a\u5185\u5b58\u7ba1\u7406\u3002 \u4f60\u5c06\u83b7\u5f97\u6574\u4e2avideo\u8bfe\u7a0b\u7684\u5b8c\u6574\u8bb2\u4e49\uff08\u4e5f\u5c31\u662fvideo\u5448\u73b0\u7684\u6bcf\u4e00\u5f20\u6295\u5f71\u7247\u753b\u9762\uff09\uff0c \u548c\u4e00\u4e2a\u5b8c\u6574\u7a0b\u5e8f\u5305\u62ec\u4ee3\u7801\u6587\u4ef6.cpp\u548c\u53ef\u6267\u884c\u6587\u4ef6.exe\u3002\u4f60\u53ef\u4ee5\u5728\u89c6\u542c\u8fc7\u7a0b\u4e2d\u968f\u65f6 \u505c\u683c\u4ed4\u7ec6\u9605\u8bfb\u8bb2\u4e49\uff0c\u7ec6\u7ec6\u5480\u56bc\u6211\u6240\u7ed8\u5236\u7684\u5404\u79cd\u793a\u610f\u56fe\u548c\u6e90\u4ee3\u7801\u4e4b\u95f4\u7684\u6d41\u52a8\u8def \u7ebf\u2014\u2014\u8fd9\u7684\u786e\u5f88\u9700\u8981\u65f6\u95f4\u548c\u8111\u529b\uff0c\u5374\u80fd\u4ee4\u4f60\u8111\u6d1e\u5927\u5f00\u3002 \u4faf\u6377\u7b80\u4ecb\uff1a\u7a0b\u5e8f\u5458\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u53f0\u6e7e\u5de5\u7814\u9662\u526f\u7814\u7a76\u5458\uff0c\u6559\u6388\u3002\u66fe\u4efb\u6559\u4e8e\u4e2d\u575c\u5143 \u667a\u5927\u5b66\u3001\u4e0a\u6d77\u540c\u6d4e\u5927\u5b66\u3001\u5357\u4eac\u5927\u5b66\u3002\u8457\u6709\u300a\u65e0\u8d23\u4efb\u4e66\u8bc4\u300b\u4e09\u5377\u3001\u300a\u6df1\u5165\u6d45\u51faMFC\u300b\u3001 \u300aSTL\u6e90\u7801\u5256\u6790\u300b\u2026\uff0c\u8bd1\u6709\u300aEffective C++\u300b\u300aMore Effective C++\u300b\u300aC++ Primer\u300b \u300aThe C++ Standard Library\u300b\u2026\u3002 \u4ee5\u4e0b\u8fd9\u4efd\u4e0d\u7b97\u592a\u7ec6\u81f4\u7684\u4e3b\u9898\u5212\u5206\uff0c\u534f\u52a9\u60a8\u8ba4\u8bc6\u6574\u4e2a\u8bfe\u7a0b\u5185\u5bb9\uff0c\u4ee5\u53ca\u5728\u89c6\u542c\u8fc7\u7a0b\u4e2d\u6b63\u786e\u7ffb\u627e\u8bb2\u4e49\u3002\u672b\u5c3e\u7684\u7f16\u53f7\u5c31\u662f\u8bb2\u4e49\u7684\u9875\u7801\u3002","title":"\u8bfe\u7a0b\u7b80\u4ecb"},{"location":"C%2B%2B/C%2B%2B-MemoryManagement-HouJie/#\u5185\u5b58\u7ba1\u7406101\u4ece\u5e73\u5730\u5230\u4e07\u4e08\u9ad8\u697c","text":"\u4e3b\u9898\u5212\u5206","title":"\u5185\u5b58\u7ba1\u7406101\u2013\u4ece\u5e73\u5730\u5230\u4e07\u4e08\u9ad8\u697c"},{"location":"C%2B%2B/C%2B%2B-MemoryManagement-HouJie/#\u7b2c\u4e00\u8bb2c\u5185\u5b58\u6784\u4ef6","text":"Overview 1-10 \u5185\u5b58\u5206\u914d\u7684\u6bcf\u4e00\u5c42\u9762 11 \u56db\u4e2a\u57fa\u672c\u5c42\u9762\u7684\u7528\u6cd5 12-14 \u57fa\u672c\u6784\u4ef6\u4e4b\u4e00 new/delete expressions 15-17 \u57fa\u672c\u6784\u4ef6\u4e4b\u4e8c array new/delete 18-21 \u57fa\u672c\u6784\u4ef6\u4e4b\u4e09 placement new/delete 22 \u57fa\u672c\u6784\u4ef6\u4e4b\u5206\u914d\u6d41\u7a0b 23-24 \u57fa\u672c\u6784\u4ef6\u4e4b\u91cd\u8f7d 25-34 Per-class allocator\u7b2c\u4e00\u7248\u672c 35-36 Per-class allocator\u7b2c\u4e8c\u7248\u672c 37-38 Common static allocator\uff08\u7b2c\u4e09\u7248\u672c\uff0939-41 Macro allocator\uff08\u7b2c\u56db\u7248\u672c\uff0942-43 GNU C++ allocator\uff08\u7b2c\u4e94\u7248\u672c\uff09\u6837\u8c8c44 \u6742\u9879\u8ba8\u8bba 45-48","title":"\u7b2c\u4e00\u8bb2\uff1aC++\u5185\u5b58\u6784\u4ef6"},{"location":"C%2B%2B/C%2B%2B-MemoryManagement-HouJie/#\u7b2c\u4e8c\u8bb2stdallocator","text":"\u5185\u5b58\u5757\u5e03\u5c40 52 VC6 allocator 53 BC5 allocator 54 GNU allocator 55-60 GNU allocator\u884c\u4e3a\u5256\u6790 61-76 GNU allocator\u6e90\u7801\u5256\u6790 77-87 GNU allocator\u68c0\u8ba8 88-89 GNU allocator\u76d1\u89c6 90-91 GNU allocator\u79fb\u690d\u5230C\u8bed\u8a00 92","title":"\u7b2c\u4e8c\u8bb2\uff1astd::allocator"},{"location":"C%2B%2B/C%2B%2B-MemoryManagement-HouJie/#\u7b2c\u4e09\u8bb2mallocfree","text":"VC6\u548cVC10\u7684malloc\u6bd4\u8f83 96-97 Small Block Heap\uff08SBH\uff09\u521d\u59cb\u5316 98-99 SBH\u884c\u4e3a\u5206\u6790\u2013\u5185\u5b58\u5757\u5927\u5c0f\u4e4b\u8ba1\u7b97 100-104 SBH\u884c\u4e3a\u5206\u6790\u2013\u6570\u636e\u7ed3\u6784 105-107 SBH\u884c\u4e3a\u5206\u6790\u2013\u5206\u914d\u4e4b\u8be6\u7ec6\u56fe\u89e3 108 SBH\u884c\u4e3a\u5206\u6790\u2013\u5206\u914d+\u91ca\u653e\u4e4b\u8fde\u7eed\u52a8\u4f5c\u56fe\u89e3 109-115 SBH\u68c0\u8ba8 116-122","title":"\u7b2c\u4e09\u8bb2\uff1amalloc/free"},{"location":"C%2B%2B/C%2B%2B-MemoryManagement-HouJie/#\u7b2c\u56db\u8bb2lokiallocator","text":"\u4e0a\u4e2d\u4e0b\u4e09\u4e2aclasses\u5206\u6790 127 Loki::allocator\u884c\u4e3a\u56fe\u89e3 128-134 class Chunk\u5206\u6790 135-137 class FixedAllocator\u5206\u6790 138-140 Loki::allocator\u68c0\u8ba8 141","title":"\u7b2c\u56db\u8bb2\uff1aLoki:\uff1aallocator"},{"location":"C%2B%2B/C%2B%2B-MemoryManagement-HouJie/#\u7b2c\u4e94\u8bb2other-issues","text":"GNU C++\u5bf9allocators\u7684\u63cf\u8ff0 144-149 VS2013\u6807\u51c6\u5206\u914d\u5668\u4e0enew_allocator 150 G4.9 \u6807\u51c6\u5206\u914d\u5668\u4e0enew_allocator 151 G4.9 malloc_allocator 152 G4.9 array_allocator 153-155 G4.9 debug_allocator 156 G4.9 _pool_alloc 157-159 G4.9 bitmap_allocator 160-170 G4.9 \u4f7f\u7528G4.9\u5206\u914d\u5668 171-172 -- the end","title":"\u7b2c\u4e94\u8bb2\uff1aOther Issues"},{"location":"C%2B%2B/C%2B%2B-OOPBase1-HouJie/","text":"\u89c6\u9891\u76f4\u8fbe\uff1a C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\u4e0a-\u57fa\u4e8e\u5bf9\u8c61\u548c\u9762\u5411\u5bf9\u8c61 \u8bfe\u7a0b\u8bb2\u4e49\u4e0b\u8f7d\u76f4\u8fbe\uff1a slide \u6e90\u4ee3\u7801\u76f4\u8fbe\uff1a code \u5019\u6377\u8001\u5e08 C++ \u7cfb\u5217\u8bfe\u7a0b\u5bfc\u822a\uff1a\uff08\u7f16\u53f7\u987a\u5e8f\u53ef\u4f5c\u4e3a\u5b66\u4e60\u987a\u5e8f\u53c2\u8003\uff09 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0a\uff09-\u57fa\u4e8e\u5bf9\u8c61\u548c\u9762\u5411\u5bf9\u8c61 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0b\uff09-\u517c\u8c08\u5bf9\u8c61\u6a21\u578b C++\u6807\u51c6\u5e93(STL)\u4e0e\u6cdb\u578b\u7f16\u7a0b C++\u65b0\u6807\u51c6-C++11/14 C++\u5185\u5b58\u7ba1\u7406 C++Startup\u63ed\u79d8 \u8bfe\u7a0b\u7b80\u4ecb \u00b6 \u8fd9\u662f\u4faf\u6377\u8001\u5e08\u7684\u6240\u6709C++\u6280\u672f\u8bfe\u7a0b\u4e2d\u6700\u57fa\u7840\u6700\u6839\u672c\u7684\u4e00\u95e8\u8bfe\u3002 C++\u53ef\u8bf4\u662f\u7b2c\u4e00\u4e2a\u9ad8\u5ea6\u666e\u53ca\u7684Object-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u7a0b\u5e8f\u8bed\u8a00\u3002\u201c\u7b2c\u4e00\u4e2a\u201d \u6216\u201c\u6700\u65e9\u7684\u201d\u5e76\u975e\u91cd\u70b9\uff0c\u91cd\u70b9\u662f\u7ecf\u8fc7\u591a\u5e74\u7684\u6dec\u70bc\u548c\u8003\u9a8cC++\u7684\u5f71\u54cd\u6df1\u5165\u5404\u5c42\u9762\uff0c \u62e5\u6709\u4f17\u591a\u4f7f\u7528\u8005\u548c\u6781\u5176\u4e30\u5bcc\u7684\u8d44\u6e90\uff08\u4e66\u7c4d\u3001\u8bba\u6587\u3001\u671f\u520a\u3001\u89c6\u9891\u3001\u7b2c\u4e09\u65b9\u7a0b\u5e8f\u5e93\u2026\uff09\u3002 \u4f5c\u4e3aObject-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u6280\u672f\u7684\u4e3b\u6d41\u8bed\u8a00\uff0cC++\u5176\u5b9e\u8fd8\u62e5\u6709\u53e6\u4e00\u652f\u7f16\u7a0b \u4e3b\u7ebf\uff1a\u6a21\u677f\u4e0e\u6cdb\u578b\u7f16\u7a0b\uff08Templates and Generic Programming\uff09\u3002 \u672c\u8bfe\u7a0b\u6db5\u76d6\u4e0a\u8ff0\u4e24\u6761\u4e3b\u7ebf\uff1aObject-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u548c\u6cdb\u578b\u7f16\u7a0b\uff08Generic Programming\uff09\u3002 \u7531\u4e8e\u89c6\u9891\u5f55\u5236\u65f6\u7a0b\u7684\u56e0\u7d20\uff0c\u672c\u8bfe\u7a0b\u5206\u4e3aPart I\u548cPart II. Part I\u4e3b\u8981\u8ba8\u8bbaOO\uff08\u9762\u5411\u5bf9\u8c61\uff09\u7684\u57fa\u7840\u6982\u5ff5\u548c\u7f16\u7a0b\u624b\u6cd5\u3002\u57fa\u7840\u6700\u662f\u91cd\u8981\uff0c\u52ff\u5728\u6d6e \u6c99\u7b51\u9ad8\u53f0\uff0c\u7740\u91cd\u7684\u662f\u5927\u5668\u4e0e\u5927\u6c14\u3002\u8bfe\u7a0b\u9996\u5148\u63a2\u8ba8Class without pointer members \u548cClass with pointer members\u4e24\u5927\u7c7b\u578b\uff0c\u800c\u540e\u664b\u5347\u81f3OOP/OOD\uff0c\u5305\u62ecclasses\u4e4b \u95f4\u6700\u91cd\u8981\u7684\u4e09\u79cd\u5173\u7cfb\uff1a\u7ee7\u627f\uff08Inheritance\uff09\u3001\u590d\u5408\uff08Composition\uff09\u3001\u59d4\u6258\uff08Delegation\uff09\u3002 Part II\u7ee7\u7eed\u63a2\u8ba8\u66f4\u591a\u76f8\u5173\u4e3b\u9898\uff0c\u5e76\u52a0\u4e0a\u4f4e\u9636\u7684\u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff0c\u4ee5\u53ca\u9ad8 \u9636\u7684Templates\uff08\u6a21\u677f\uff09\u7f16\u7a0b\u3002 \u672c\u8bfe\u7a0b\u6240\u8c08\u4e3b\u9898\u90fd\u96b6\u5c5eC++1.0\uff08C++98\uff09\uff1b\u81f3\u4e8eC++ 2.0\uff08C++11/14\uff09\u5e26\u6765\u7684\u5d2d\u65b0 \u5185\u5bb9\u5219\u7531\u4faf\u6377\u8001\u5e08\u7684 \u53e6\u4e00\u95e8\u8bfe\u7a0b \u7a0b\u6db5\u76d6\u3002C++2.0\u5728\u8bed\u8a00\u548c\u6807\u51c6\u5e93\u4e24\u65b9\u9762\u90fd\u5e26\u6765\u4e86\u5f88\u591a\u65b0 \u4e8b\u7269\uff0c\u4efd\u91cf\u8db3\u4ee5\u5f62\u6210\u53e6\u4e00\u95e8\u8bfe\u7a0b\u3002 \u4f60\u5c06\u83b7\u5f97\u6574\u4e2avideo\u8bfe\u7a0b\u7684\u5b8c\u6574\u8bb2\u4e49\uff08\u4e5f\u5c31\u662fvideo\u5448\u73b0\u7684\u6bcf\u4e00\u5f20\u6295\u5f71\u7247\u753b\u9762\uff09\uff0c \u548c\u5b8c\u6574\u7684\u793a\u4f8b\u7a0b\u5e8f\u3002\u4f60\u53ef\u4ee5\uff08\u4e5f\u6709\u5fc5\u8981\uff09\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u968f\u65f6\u505c\u4e0b\u6765\u601d\u8003\u548c\u9605\u8bfb\u8bb2\u4e49\u3002 \u4faf\u6377\u7b80\u4ecb\uff1a\u7a0b\u5e8f\u5458\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u53f0\u6e7e\u5de5\u7814\u9662\u526f\u7814\u7a76\u5458\uff0c\u6559\u6388\uff0c\u4e13\u680f\u4e3b\u7b14\u3002\u66fe\u4efb \u6559\u4e8e\u4e2d\u575c\u5143\u667a\u5927\u5b66\u3001\u4e0a\u6d77\u540c\u6d4e\u5927\u5b66\u3001\u5357\u4eac\u5927\u5b66\u3002\u8457\u6709\u300a\u65e0\u8d23\u4efb\u4e66\u8bc4\u300b\u4e09\u5377\u3001\u300a\u6df1 \u5165\u6d45\u51faMFC\u300b\u3001\u300aSTL\u6e90\u7801\u5256\u6790\u300b\u2026\uff0c\u8bd1\u6709\u300aEffective C++\u300b\u300aMore Effective C++\u300b \u300aC++ Primer\u300b\u300aThe C++ Standard Library\u300b\u2026 \u4ee5\u4e0b\u8fd9\u4efd\u4e0d\u592a\u7ec6\u81f4\u7684\u4e3b\u9898\u5212\u5206\uff0c\u5e2e\u52a9\u60a8\u8ba4\u8bc6\u6574\u4e2a\u8bfe\u7a0b\u5185\u5bb9\u3002 C++\u9762\u5411\u5c0d\u8c61\u7de8\u7a0b (C++Object-Oriented Programming) \u00b6 Part I \u00b6 Introduction of C++98, TR1, C++11, C++14 \u2003Bibliography \u2003Data and Functions, from C to C++ \u2003Basic forms of C++ programs \u2003About output \u2003Guard declarations of header files \u2003Layout of headers \u2003Object Based \u2003Class without pointer member \u2003\u2003Class declarations \u2003\u2003Class template, introductions and overviews \u2003\u2003What is 'this' \u2003\u2003Inline functions \u2003\u2003Access levels \u2003\u2003Constructor (ctor) \u2003\u2003Const member functions \u2003\u2003Parameters : pass by value vs. pass by reference \u2003\u2003Return values : return by value vs. return by reference \u2003\u2003Friend \u2003\u2003Definitions outside class body \u2003\u2003Operator overloading, as member function \u2003\u2003Return by reference, again \u2003\u2003Operator overloading, as non-member function \u2003\u2003Temporary objects \u2003\u2003Expertise \u2003\u2003Code demonstration \u2003class with pointer members \u2003\u2003The \"Big Three\" \u2003\u2003\u2003Copy Constructor \u2003\u2003\u2003Copy Assignment Operator \u2003\u2003\u2003Destructor \u2003\u2003Ctor and Dtor, in our String class \u2003\u2003\"MUST HAVE\" in our String class \u2003\u2003\u2003Copy Constructor \u2003\u2003\u2003Copy assignment operator \u2003\u2003Deal with \"self assignment\" \u2003\u2003Another way to deal with \"self assignment\" : Copy and Swap \u2003\u2003Overloading output operator (<<) \u2003\u2003Expertise \u2003\u2003Code demonstration \u2003Objects from stack vs. objects from heap \u2003\u2003Objects lifetime \u2003\u2003new expression : allocate memory and then invoke ctor \u2003\u2003delete expression : invoke dtor and then free memory \u2003\u2003Anatomy of memory blocks from heap \u2003\u2003Allocate an array dynamically \u2003\u2003new[] and delete[] \u2003MORE ISSUES : \u2003\u2003static \u2003\u2003private ctors \u2003\u2003cout \u2003\u2003Class template \u2003\u2003Function template \u2003\u2003namespace \u2003\u2003Standard Library : Introductions and Overviews \u2003Object Oriented \u2003\u2003Composition means \"has-a\" \u2003\u2003\u2003Construction : from inside to outside \u2003\u2003\u2003Destruction : from outside to inside \u2003\u2003Delegation means \"Composition by reference\" \u2003\u2003Inheritance means \"is-a\" \u2003\u2003\u2003Construction : from inside to outside \u2003\u2003\u2003Destruction : from outside to inside \u2003\u2003Construction and Destruction, when Inheritance+Composition \u2003\u2003Inheritance with virtual functions \u2003\u2003Virtual functions typical usage 1 : Template Method \u2003\u2003Virtual functions typical usage 2 : Polymorphism \u2003\u2003Virtual functions inside out : vptr, vtbl, and dynamic binding \u2003\u2003Delegation + Inheritance : Observer \u2003\u2003Delegation + Inheritance : Composite \u2003\u2003Delegation + Inheritance : Prototype Part II \u00b6 \u7eea\u8bba Conversion function\uff08\u8f6c\u6362\u51fd\u6570\uff09 Non-explicit one-argument constructor Pointer-like classes\uff0c\u5173\u4e8e\u667a\u80fd\u6307\u9488 Pointer-like classes\uff0c\u5173\u4e8e\u8fed\u4ee3\u5668 Function-like classes\uff0c\u6240\u8c13\u4eff\u51fd\u6570 \u6807\u51c6\u5e93\u4e2d\u7684\u4eff\u51fd\u6570\u7684\u5947\u7279\u6a21\u6837 namespace\u7ecf\u9a8c\u8c08 class template\uff0c\u7c7b\u6a21\u677f function template\uff0c\u51fd\u6570\u6a21\u677f member template\uff0c\u6210\u5458\u6a21\u677f specialization\uff0c\u6a21\u677f\u7279\u5316 partial specialization\uff0c\u6a21\u677f\u504f\u7279\u5316\u2014\u2014\u4e2a\u6570\u7684\u504f partial specialization\uff0c\u6a21\u677f\u504f\u7279\u5316\u2014\u2014\u8303\u56f4\u7684\u504f template template parameter\uff0c\u6a21\u677f\u6a21\u677f\u53c2\u6570 variadic templates\uff08since C++11\uff09 auto\uff08since C++11\uff09 ranged-base for\uff08since C++11\uff09 reference Composition\uff08\u590d\u5408\uff09\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 Inheritance\uff08\u7ee7\u627f\uff09\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 Inheritance+Composition\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8evptr\u548cvtbl \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8ethis \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8eDynamic Binding \u8c08\u8c08const \u5173\u4e8enew\uff0cdelete \u91cd\u8f7d ::operator new\uff0c::operator delete \u91cd\u8f7d ::operator new[]\uff0c::operator delete[] \u91cd\u8f7d member operator new/delete \u91cd\u8f7d member operator new[]/delete[] \u793a\u4f8b \u91cd\u8f7dnew()\uff0cdelete() \u793a\u4f8b basic_string\u4f7f\u7528new\uff08extra\uff09\u6269\u5145\u7533\u8bf7\u91cf -- the end","title":"Index"},{"location":"C%2B%2B/C%2B%2B-OOPBase1-HouJie/#\u8bfe\u7a0b\u7b80\u4ecb","text":"\u8fd9\u662f\u4faf\u6377\u8001\u5e08\u7684\u6240\u6709C++\u6280\u672f\u8bfe\u7a0b\u4e2d\u6700\u57fa\u7840\u6700\u6839\u672c\u7684\u4e00\u95e8\u8bfe\u3002 C++\u53ef\u8bf4\u662f\u7b2c\u4e00\u4e2a\u9ad8\u5ea6\u666e\u53ca\u7684Object-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u7a0b\u5e8f\u8bed\u8a00\u3002\u201c\u7b2c\u4e00\u4e2a\u201d \u6216\u201c\u6700\u65e9\u7684\u201d\u5e76\u975e\u91cd\u70b9\uff0c\u91cd\u70b9\u662f\u7ecf\u8fc7\u591a\u5e74\u7684\u6dec\u70bc\u548c\u8003\u9a8cC++\u7684\u5f71\u54cd\u6df1\u5165\u5404\u5c42\u9762\uff0c \u62e5\u6709\u4f17\u591a\u4f7f\u7528\u8005\u548c\u6781\u5176\u4e30\u5bcc\u7684\u8d44\u6e90\uff08\u4e66\u7c4d\u3001\u8bba\u6587\u3001\u671f\u520a\u3001\u89c6\u9891\u3001\u7b2c\u4e09\u65b9\u7a0b\u5e8f\u5e93\u2026\uff09\u3002 \u4f5c\u4e3aObject-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u6280\u672f\u7684\u4e3b\u6d41\u8bed\u8a00\uff0cC++\u5176\u5b9e\u8fd8\u62e5\u6709\u53e6\u4e00\u652f\u7f16\u7a0b \u4e3b\u7ebf\uff1a\u6a21\u677f\u4e0e\u6cdb\u578b\u7f16\u7a0b\uff08Templates and Generic Programming\uff09\u3002 \u672c\u8bfe\u7a0b\u6db5\u76d6\u4e0a\u8ff0\u4e24\u6761\u4e3b\u7ebf\uff1aObject-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u548c\u6cdb\u578b\u7f16\u7a0b\uff08Generic Programming\uff09\u3002 \u7531\u4e8e\u89c6\u9891\u5f55\u5236\u65f6\u7a0b\u7684\u56e0\u7d20\uff0c\u672c\u8bfe\u7a0b\u5206\u4e3aPart I\u548cPart II. Part I\u4e3b\u8981\u8ba8\u8bbaOO\uff08\u9762\u5411\u5bf9\u8c61\uff09\u7684\u57fa\u7840\u6982\u5ff5\u548c\u7f16\u7a0b\u624b\u6cd5\u3002\u57fa\u7840\u6700\u662f\u91cd\u8981\uff0c\u52ff\u5728\u6d6e \u6c99\u7b51\u9ad8\u53f0\uff0c\u7740\u91cd\u7684\u662f\u5927\u5668\u4e0e\u5927\u6c14\u3002\u8bfe\u7a0b\u9996\u5148\u63a2\u8ba8Class without pointer members \u548cClass with pointer members\u4e24\u5927\u7c7b\u578b\uff0c\u800c\u540e\u664b\u5347\u81f3OOP/OOD\uff0c\u5305\u62ecclasses\u4e4b \u95f4\u6700\u91cd\u8981\u7684\u4e09\u79cd\u5173\u7cfb\uff1a\u7ee7\u627f\uff08Inheritance\uff09\u3001\u590d\u5408\uff08Composition\uff09\u3001\u59d4\u6258\uff08Delegation\uff09\u3002 Part II\u7ee7\u7eed\u63a2\u8ba8\u66f4\u591a\u76f8\u5173\u4e3b\u9898\uff0c\u5e76\u52a0\u4e0a\u4f4e\u9636\u7684\u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff0c\u4ee5\u53ca\u9ad8 \u9636\u7684Templates\uff08\u6a21\u677f\uff09\u7f16\u7a0b\u3002 \u672c\u8bfe\u7a0b\u6240\u8c08\u4e3b\u9898\u90fd\u96b6\u5c5eC++1.0\uff08C++98\uff09\uff1b\u81f3\u4e8eC++ 2.0\uff08C++11/14\uff09\u5e26\u6765\u7684\u5d2d\u65b0 \u5185\u5bb9\u5219\u7531\u4faf\u6377\u8001\u5e08\u7684 \u53e6\u4e00\u95e8\u8bfe\u7a0b \u7a0b\u6db5\u76d6\u3002C++2.0\u5728\u8bed\u8a00\u548c\u6807\u51c6\u5e93\u4e24\u65b9\u9762\u90fd\u5e26\u6765\u4e86\u5f88\u591a\u65b0 \u4e8b\u7269\uff0c\u4efd\u91cf\u8db3\u4ee5\u5f62\u6210\u53e6\u4e00\u95e8\u8bfe\u7a0b\u3002 \u4f60\u5c06\u83b7\u5f97\u6574\u4e2avideo\u8bfe\u7a0b\u7684\u5b8c\u6574\u8bb2\u4e49\uff08\u4e5f\u5c31\u662fvideo\u5448\u73b0\u7684\u6bcf\u4e00\u5f20\u6295\u5f71\u7247\u753b\u9762\uff09\uff0c \u548c\u5b8c\u6574\u7684\u793a\u4f8b\u7a0b\u5e8f\u3002\u4f60\u53ef\u4ee5\uff08\u4e5f\u6709\u5fc5\u8981\uff09\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u968f\u65f6\u505c\u4e0b\u6765\u601d\u8003\u548c\u9605\u8bfb\u8bb2\u4e49\u3002 \u4faf\u6377\u7b80\u4ecb\uff1a\u7a0b\u5e8f\u5458\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u53f0\u6e7e\u5de5\u7814\u9662\u526f\u7814\u7a76\u5458\uff0c\u6559\u6388\uff0c\u4e13\u680f\u4e3b\u7b14\u3002\u66fe\u4efb \u6559\u4e8e\u4e2d\u575c\u5143\u667a\u5927\u5b66\u3001\u4e0a\u6d77\u540c\u6d4e\u5927\u5b66\u3001\u5357\u4eac\u5927\u5b66\u3002\u8457\u6709\u300a\u65e0\u8d23\u4efb\u4e66\u8bc4\u300b\u4e09\u5377\u3001\u300a\u6df1 \u5165\u6d45\u51faMFC\u300b\u3001\u300aSTL\u6e90\u7801\u5256\u6790\u300b\u2026\uff0c\u8bd1\u6709\u300aEffective C++\u300b\u300aMore Effective C++\u300b \u300aC++ Primer\u300b\u300aThe C++ Standard Library\u300b\u2026 \u4ee5\u4e0b\u8fd9\u4efd\u4e0d\u592a\u7ec6\u81f4\u7684\u4e3b\u9898\u5212\u5206\uff0c\u5e2e\u52a9\u60a8\u8ba4\u8bc6\u6574\u4e2a\u8bfe\u7a0b\u5185\u5bb9\u3002","title":"\u8bfe\u7a0b\u7b80\u4ecb"},{"location":"C%2B%2B/C%2B%2B-OOPBase1-HouJie/#c\u9762\u5411\u5c0d\u8c61\u7de8\u7a0b-cobject-oriented-programming","text":"","title":"C++\u9762\u5411\u5c0d\u8c61\u7de8\u7a0b (C++Object-Oriented Programming)"},{"location":"C%2B%2B/C%2B%2B-OOPBase1-HouJie/#part-i","text":"Introduction of C++98, TR1, C++11, C++14 \u2003Bibliography \u2003Data and Functions, from C to C++ \u2003Basic forms of C++ programs \u2003About output \u2003Guard declarations of header files \u2003Layout of headers \u2003Object Based \u2003Class without pointer member \u2003\u2003Class declarations \u2003\u2003Class template, introductions and overviews \u2003\u2003What is 'this' \u2003\u2003Inline functions \u2003\u2003Access levels \u2003\u2003Constructor (ctor) \u2003\u2003Const member functions \u2003\u2003Parameters : pass by value vs. pass by reference \u2003\u2003Return values : return by value vs. return by reference \u2003\u2003Friend \u2003\u2003Definitions outside class body \u2003\u2003Operator overloading, as member function \u2003\u2003Return by reference, again \u2003\u2003Operator overloading, as non-member function \u2003\u2003Temporary objects \u2003\u2003Expertise \u2003\u2003Code demonstration \u2003class with pointer members \u2003\u2003The \"Big Three\" \u2003\u2003\u2003Copy Constructor \u2003\u2003\u2003Copy Assignment Operator \u2003\u2003\u2003Destructor \u2003\u2003Ctor and Dtor, in our String class \u2003\u2003\"MUST HAVE\" in our String class \u2003\u2003\u2003Copy Constructor \u2003\u2003\u2003Copy assignment operator \u2003\u2003Deal with \"self assignment\" \u2003\u2003Another way to deal with \"self assignment\" : Copy and Swap \u2003\u2003Overloading output operator (<<) \u2003\u2003Expertise \u2003\u2003Code demonstration \u2003Objects from stack vs. objects from heap \u2003\u2003Objects lifetime \u2003\u2003new expression : allocate memory and then invoke ctor \u2003\u2003delete expression : invoke dtor and then free memory \u2003\u2003Anatomy of memory blocks from heap \u2003\u2003Allocate an array dynamically \u2003\u2003new[] and delete[] \u2003MORE ISSUES : \u2003\u2003static \u2003\u2003private ctors \u2003\u2003cout \u2003\u2003Class template \u2003\u2003Function template \u2003\u2003namespace \u2003\u2003Standard Library : Introductions and Overviews \u2003Object Oriented \u2003\u2003Composition means \"has-a\" \u2003\u2003\u2003Construction : from inside to outside \u2003\u2003\u2003Destruction : from outside to inside \u2003\u2003Delegation means \"Composition by reference\" \u2003\u2003Inheritance means \"is-a\" \u2003\u2003\u2003Construction : from inside to outside \u2003\u2003\u2003Destruction : from outside to inside \u2003\u2003Construction and Destruction, when Inheritance+Composition \u2003\u2003Inheritance with virtual functions \u2003\u2003Virtual functions typical usage 1 : Template Method \u2003\u2003Virtual functions typical usage 2 : Polymorphism \u2003\u2003Virtual functions inside out : vptr, vtbl, and dynamic binding \u2003\u2003Delegation + Inheritance : Observer \u2003\u2003Delegation + Inheritance : Composite \u2003\u2003Delegation + Inheritance : Prototype","title":"Part I"},{"location":"C%2B%2B/C%2B%2B-OOPBase1-HouJie/#part-ii","text":"\u7eea\u8bba Conversion function\uff08\u8f6c\u6362\u51fd\u6570\uff09 Non-explicit one-argument constructor Pointer-like classes\uff0c\u5173\u4e8e\u667a\u80fd\u6307\u9488 Pointer-like classes\uff0c\u5173\u4e8e\u8fed\u4ee3\u5668 Function-like classes\uff0c\u6240\u8c13\u4eff\u51fd\u6570 \u6807\u51c6\u5e93\u4e2d\u7684\u4eff\u51fd\u6570\u7684\u5947\u7279\u6a21\u6837 namespace\u7ecf\u9a8c\u8c08 class template\uff0c\u7c7b\u6a21\u677f function template\uff0c\u51fd\u6570\u6a21\u677f member template\uff0c\u6210\u5458\u6a21\u677f specialization\uff0c\u6a21\u677f\u7279\u5316 partial specialization\uff0c\u6a21\u677f\u504f\u7279\u5316\u2014\u2014\u4e2a\u6570\u7684\u504f partial specialization\uff0c\u6a21\u677f\u504f\u7279\u5316\u2014\u2014\u8303\u56f4\u7684\u504f template template parameter\uff0c\u6a21\u677f\u6a21\u677f\u53c2\u6570 variadic templates\uff08since C++11\uff09 auto\uff08since C++11\uff09 ranged-base for\uff08since C++11\uff09 reference Composition\uff08\u590d\u5408\uff09\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 Inheritance\uff08\u7ee7\u627f\uff09\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 Inheritance+Composition\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8evptr\u548cvtbl \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8ethis \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8eDynamic Binding \u8c08\u8c08const \u5173\u4e8enew\uff0cdelete \u91cd\u8f7d ::operator new\uff0c::operator delete \u91cd\u8f7d ::operator new[]\uff0c::operator delete[] \u91cd\u8f7d member operator new/delete \u91cd\u8f7d member operator new[]/delete[] \u793a\u4f8b \u91cd\u8f7dnew()\uff0cdelete() \u793a\u4f8b basic_string\u4f7f\u7528new\uff08extra\uff09\u6269\u5145\u7533\u8bf7\u91cf -- the end","title":"Part II"},{"location":"C%2B%2B/C%2B%2B-OOPBase2-HouJie/","text":"\u89c6\u9891\u76f4\u8fbe\uff1a C++ \u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\u4e0b-\u517c\u8c08\u5bf9\u8c61\u6a21\u578b \u8bfe\u7a0b\u8bb2\u4e49\u4e0b\u8f7d\u76f4\u8fbe\uff1a slide \u6e90\u4ee3\u7801\u76f4\u8fbe\uff1a code \u5019\u6377\u8001\u5e08 C++ \u7cfb\u5217\u8bfe\u7a0b\u5bfc\u822a\uff1a\uff08\u7f16\u53f7\u987a\u5e8f\u53ef\u4f5c\u4e3a\u5b66\u4e60\u987a\u5e8f\u53c2\u8003\uff09 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0a\uff09-\u57fa\u4e8e\u5bf9\u8c61\u548c\u9762\u5411\u5bf9\u8c61 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0b\uff09-\u517c\u8c08\u5bf9\u8c61\u6a21\u578b C++\u6807\u51c6\u5e93(STL)\u4e0e\u6cdb\u578b\u7f16\u7a0b C++\u65b0\u6807\u51c6-C++11/14 C++\u5185\u5b58\u7ba1\u7406 C++Startup\u63ed\u79d8 \u8bfe\u7a0b\u7b80\u4ecb \u00b6 \u8fd9\u662f\u4faf\u6377\u8001\u5e08\u7684\u6240\u6709C++\u6280\u672f\u8bfe\u7a0b\u4e2d\u6700\u57fa\u7840\u6700\u6839\u672c\u7684\u4e00\u95e8\u8bfe\u3002 C++\u53ef\u8bf4\u662f\u7b2c\u4e00\u4e2a\u9ad8\u5ea6\u666e\u53ca\u7684Object-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u7a0b\u5e8f\u8bed\u8a00\u3002\u201c\u7b2c\u4e00\u4e2a\u201d \u6216\u201c\u6700\u65e9\u7684\u201d\u5e76\u975e\u91cd\u70b9\uff0c\u91cd\u70b9\u662f\u7ecf\u8fc7\u591a\u5e74\u7684\u6dec\u70bc\u548c\u8003\u9a8cC++\u7684\u5f71\u54cd\u6df1\u5165\u5404\u5c42\u9762\uff0c \u62e5\u6709\u4f17\u591a\u4f7f\u7528\u8005\u548c\u6781\u5176\u4e30\u5bcc\u7684\u8d44\u6e90\uff08\u4e66\u7c4d\u3001\u8bba\u6587\u3001\u671f\u520a\u3001\u89c6\u9891\u3001\u7b2c\u4e09\u65b9\u7a0b\u5e8f\u5e93\u2026\uff09\u3002 \u4f5c\u4e3aObject-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u6280\u672f\u7684\u4e3b\u6d41\u8bed\u8a00\uff0cC++\u5176\u5b9e\u8fd8\u62e5\u6709\u53e6\u4e00\u652f\u7f16\u7a0b \u4e3b\u7ebf\uff1a\u6a21\u677f\u4e0e\u6cdb\u578b\u7f16\u7a0b\uff08Templates and Generic Programming\uff09\u3002 \u672c\u8bfe\u7a0b\u6db5\u76d6\u4e0a\u8ff0\u4e24\u6761\u4e3b\u7ebf\uff1aObject-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u548c\u6cdb\u578b\u7f16\u7a0b\uff08Generic Programming\uff09\u3002 \u7531\u4e8e\u89c6\u9891\u5f55\u5236\u65f6\u7a0b\u7684\u56e0\u7d20\uff0c\u672c\u8bfe\u7a0b\u5206\u4e3aPart I\u548cPart II. Part I\u4e3b\u8981\u8ba8\u8bbaOO\uff08\u9762\u5411\u5bf9\u8c61\uff09\u7684\u57fa\u7840\u6982\u5ff5\u548c\u7f16\u7a0b\u624b\u6cd5\u3002\u57fa\u7840\u6700\u662f\u91cd\u8981\uff0c\u52ff\u5728\u6d6e \u6c99\u7b51\u9ad8\u53f0\uff0c\u7740\u91cd\u7684\u662f\u5927\u5668\u4e0e\u5927\u6c14\u3002\u8bfe\u7a0b\u9996\u5148\u63a2\u8ba8Class without pointer members \u548cClass with pointer members\u4e24\u5927\u7c7b\u578b\uff0c\u800c\u540e\u664b\u5347\u81f3OOP/OOD\uff0c\u5305\u62ecclasses\u4e4b \u95f4\u6700\u91cd\u8981\u7684\u4e09\u79cd\u5173\u7cfb\uff1a\u7ee7\u627f\uff08Inheritance\uff09\u3001\u590d\u5408\uff08Composition\uff09\u3001\u59d4\u6258\uff08Delegation\uff09\u3002 Part II\u7ee7\u7eed\u63a2\u8ba8\u66f4\u591a\u76f8\u5173\u4e3b\u9898\uff0c\u5e76\u52a0\u4e0a\u4f4e\u9636\u7684\u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff0c\u4ee5\u53ca\u9ad8 \u9636\u7684Templates\uff08\u6a21\u677f\uff09\u7f16\u7a0b\u3002 \u672c\u8bfe\u7a0b\u6240\u8c08\u4e3b\u9898\u90fd\u96b6\u5c5eC++1.0\uff08C++98\uff09\uff1b\u81f3\u4e8eC++ 2.0\uff08C++11/14\uff09\u5e26\u6765\u7684\u5d2d\u65b0 \u5185\u5bb9\u5219\u7531\u4faf\u6377\u8001\u5e08\u7684 \u53e6\u4e00\u95e8\u8bfe\u7a0b \u6db5\u76d6\u3002C++2.0\u5728\u8bed\u8a00\u548c\u6807\u51c6\u5e93\u4e24\u65b9\u9762\u90fd\u5e26\u6765\u4e86\u5f88\u591a\u65b0 \u4e8b\u7269\uff0c\u4efd\u91cf\u8db3\u4ee5\u5f62\u6210\u53e6\u4e00\u95e8\u8bfe\u7a0b\u3002 \u4f60\u5c06\u83b7\u5f97\u6574\u4e2avideo\u8bfe\u7a0b\u7684\u5b8c\u6574\u8bb2\u4e49\uff08\u4e5f\u5c31\u662fvideo\u5448\u73b0\u7684\u6bcf\u4e00\u5f20\u6295\u5f71\u7247\u753b\u9762\uff09\uff0c \u548c\u5b8c\u6574\u7684\u793a\u4f8b\u7a0b\u5e8f\u3002\u4f60\u53ef\u4ee5\uff08\u4e5f\u6709\u5fc5\u8981\uff09\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u968f\u65f6\u505c\u4e0b\u6765\u601d\u8003\u548c\u9605\u8bfb\u8bb2\u4e49\u3002 \u4faf\u6377\u7b80\u4ecb\uff1a\u7a0b\u5e8f\u5458\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u53f0\u6e7e\u5de5\u7814\u9662\u526f\u7814\u7a76\u5458\uff0c\u6559\u6388\uff0c\u4e13\u680f\u4e3b\u7b14\u3002\u66fe\u4efb \u6559\u4e8e\u4e2d\u575c\u5143\u667a\u5927\u5b66\u3001\u4e0a\u6d77\u540c\u6d4e\u5927\u5b66\u3001\u5357\u4eac\u5927\u5b66\u3002\u8457\u6709\u300a\u65e0\u8d23\u4efb\u4e66\u8bc4\u300b\u4e09\u5377\u3001\u300a\u6df1 \u5165\u6d45\u51faMFC\u300b\u3001\u300aSTL\u6e90\u7801\u5256\u6790\u300b\u2026\uff0c\u8bd1\u6709\u300aEffective C++\u300b\u300aMore Effective C++\u300b \u300aC++ Primer\u300b\u300aThe C++ Standard Library\u300b\u2026 \u4ee5\u4e0b\u8fd9\u4efd\u4e0d\u592a\u7ec6\u81f4\u7684\u4e3b\u9898\u5212\u5206\uff0c\u5e2e\u52a9\u60a8\u8ba4\u8bc6\u6574\u4e2a\u8bfe\u7a0b\u5185\u5bb9\u3002 C++\u9762\u5411\u5c0d\u8c61\u7de8\u7a0b (C++Object-Oriented Programming) \u00b6 Part I \u00b6 Introduction of C++98, TR1, C++11, C++14 \u2003Bibliography \u2003Data and Functions, from C to C++ \u2003Basic forms of C++ programs \u2003About output \u2003Guard declarations of header files \u2003Layout of headers \u2003Object Based \u2003Class without pointer member \u2003\u2003Class declarations \u2003\u2003Class template, introductions and overviews \u2003\u2003What is 'this' \u2003\u2003Inline functions \u2003\u2003Access levels \u2003\u2003Constructor (ctor) \u2003\u2003Const member functions \u2003\u2003Parameters : pass by value vs. pass by reference \u2003\u2003Return values : return by value vs. return by reference \u2003\u2003Friend \u2003\u2003Definitions outside class body \u2003\u2003Operator overloading, as member function \u2003\u2003Return by reference, again \u2003\u2003Operator overloading, as non-member function \u2003\u2003Temporary objects \u2003\u2003Expertise \u2003\u2003Code demonstration \u2003class with pointer members \u2003\u2003The \"Big Three\" \u2003\u2003\u2003Copy Constructor \u2003\u2003\u2003Copy Assignment Operator \u2003\u2003\u2003Destructor \u2003\u2003Ctor and Dtor, in our String class \u2003\u2003\"MUST HAVE\" in our String class \u2003\u2003\u2003Copy Constructor \u2003\u2003\u2003Copy assignment operator \u2003\u2003Deal with \"self assignment\" \u2003\u2003Another way to deal with \"self assignment\" : Copy and Swap \u2003\u2003Overloading output operator (<<) \u2003\u2003Expertise \u2003\u2003Code demonstration \u2003Objects from stack vs. objects from heap \u2003\u2003Objects lifetime \u2003\u2003new expression : allocate memory and then invoke ctor \u2003\u2003delete expression : invoke dtor and then free memory \u2003\u2003Anatomy of memory blocks from heap \u2003\u2003Allocate an array dynamically \u2003\u2003new[] and delete[] \u2003MORE ISSUES : \u2003\u2003static \u2003\u2003private ctors \u2003\u2003cout \u2003\u2003Class template \u2003\u2003Function template \u2003\u2003namespace \u2003\u2003Standard Library : Introductions and Overviews \u2003Object Oriented \u2003\u2003Composition means \"has-a\" \u2003\u2003\u2003Construction : from inside to outside \u2003\u2003\u2003Destruction : from outside to inside \u2003\u2003Delegation means \"Composition by reference\" \u2003\u2003Inheritance means \"is-a\" \u2003\u2003\u2003Construction : from inside to outside \u2003\u2003\u2003Destruction : from outside to inside \u2003\u2003Construction and Destruction, when Inheritance+Composition \u2003\u2003Inheritance with virtual functions \u2003\u2003Virtual functions typical usage 1 : Template Method \u2003\u2003Virtual functions typical usage 2 : Polymorphism \u2003\u2003Virtual functions inside out : vptr, vtbl, and dynamic binding \u2003\u2003Delegation + Inheritance : Observer \u2003\u2003Delegation + Inheritance : Composite \u2003\u2003Delegation + Inheritance : Prototype Part II \u00b6 \u7eea\u8bba Conversion function\uff08\u8f6c\u6362\u51fd\u6570\uff09 Non-explicit one-argument constructor Pointer-like classes\uff0c\u5173\u4e8e\u667a\u80fd\u6307\u9488 Pointer-like classes\uff0c\u5173\u4e8e\u8fed\u4ee3\u5668 Function-like classes\uff0c\u6240\u8c13\u4eff\u51fd\u6570 \u6807\u51c6\u5e93\u4e2d\u7684\u4eff\u51fd\u6570\u7684\u5947\u7279\u6a21\u6837 namespace\u7ecf\u9a8c\u8c08 class template\uff0c\u7c7b\u6a21\u677f function template\uff0c\u51fd\u6570\u6a21\u677f member template\uff0c\u6210\u5458\u6a21\u677f specialization\uff0c\u6a21\u677f\u7279\u5316 partial specialization\uff0c\u6a21\u677f\u504f\u7279\u5316\u2014\u2014\u4e2a\u6570\u7684\u504f partial specialization\uff0c\u6a21\u677f\u504f\u7279\u5316\u2014\u2014\u8303\u56f4\u7684\u504f template template parameter\uff0c\u6a21\u677f\u6a21\u677f\u53c2\u6570 variadic templates\uff08since C++11\uff09 auto\uff08since C++11\uff09 ranged-base for\uff08since C++11\uff09 reference Composition\uff08\u590d\u5408\uff09\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 Inheritance\uff08\u7ee7\u627f\uff09\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 Inheritance+Composition\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8evptr\u548cvtbl \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8ethis \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8eDynamic Binding \u8c08\u8c08const \u5173\u4e8enew\uff0cdelete \u91cd\u8f7d ::operator new\uff0c::operator delete \u91cd\u8f7d ::operator new[]\uff0c::operator delete[] \u91cd\u8f7d member operator new/delete \u91cd\u8f7d member operator new[]/delete[] \u793a\u4f8b \u91cd\u8f7dnew()\uff0cdelete() \u793a\u4f8b basic_string\u4f7f\u7528new\uff08extra\uff09\u6269\u5145\u7533\u8bf7\u91cf -- the end","title":"Index"},{"location":"C%2B%2B/C%2B%2B-OOPBase2-HouJie/#\u8bfe\u7a0b\u7b80\u4ecb","text":"\u8fd9\u662f\u4faf\u6377\u8001\u5e08\u7684\u6240\u6709C++\u6280\u672f\u8bfe\u7a0b\u4e2d\u6700\u57fa\u7840\u6700\u6839\u672c\u7684\u4e00\u95e8\u8bfe\u3002 C++\u53ef\u8bf4\u662f\u7b2c\u4e00\u4e2a\u9ad8\u5ea6\u666e\u53ca\u7684Object-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u7a0b\u5e8f\u8bed\u8a00\u3002\u201c\u7b2c\u4e00\u4e2a\u201d \u6216\u201c\u6700\u65e9\u7684\u201d\u5e76\u975e\u91cd\u70b9\uff0c\u91cd\u70b9\u662f\u7ecf\u8fc7\u591a\u5e74\u7684\u6dec\u70bc\u548c\u8003\u9a8cC++\u7684\u5f71\u54cd\u6df1\u5165\u5404\u5c42\u9762\uff0c \u62e5\u6709\u4f17\u591a\u4f7f\u7528\u8005\u548c\u6781\u5176\u4e30\u5bcc\u7684\u8d44\u6e90\uff08\u4e66\u7c4d\u3001\u8bba\u6587\u3001\u671f\u520a\u3001\u89c6\u9891\u3001\u7b2c\u4e09\u65b9\u7a0b\u5e8f\u5e93\u2026\uff09\u3002 \u4f5c\u4e3aObject-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u6280\u672f\u7684\u4e3b\u6d41\u8bed\u8a00\uff0cC++\u5176\u5b9e\u8fd8\u62e5\u6709\u53e6\u4e00\u652f\u7f16\u7a0b \u4e3b\u7ebf\uff1a\u6a21\u677f\u4e0e\u6cdb\u578b\u7f16\u7a0b\uff08Templates and Generic Programming\uff09\u3002 \u672c\u8bfe\u7a0b\u6db5\u76d6\u4e0a\u8ff0\u4e24\u6761\u4e3b\u7ebf\uff1aObject-Oriented\uff08\u9762\u5411\u5bf9\u8c61\uff09\u548c\u6cdb\u578b\u7f16\u7a0b\uff08Generic Programming\uff09\u3002 \u7531\u4e8e\u89c6\u9891\u5f55\u5236\u65f6\u7a0b\u7684\u56e0\u7d20\uff0c\u672c\u8bfe\u7a0b\u5206\u4e3aPart I\u548cPart II. Part I\u4e3b\u8981\u8ba8\u8bbaOO\uff08\u9762\u5411\u5bf9\u8c61\uff09\u7684\u57fa\u7840\u6982\u5ff5\u548c\u7f16\u7a0b\u624b\u6cd5\u3002\u57fa\u7840\u6700\u662f\u91cd\u8981\uff0c\u52ff\u5728\u6d6e \u6c99\u7b51\u9ad8\u53f0\uff0c\u7740\u91cd\u7684\u662f\u5927\u5668\u4e0e\u5927\u6c14\u3002\u8bfe\u7a0b\u9996\u5148\u63a2\u8ba8Class without pointer members \u548cClass with pointer members\u4e24\u5927\u7c7b\u578b\uff0c\u800c\u540e\u664b\u5347\u81f3OOP/OOD\uff0c\u5305\u62ecclasses\u4e4b \u95f4\u6700\u91cd\u8981\u7684\u4e09\u79cd\u5173\u7cfb\uff1a\u7ee7\u627f\uff08Inheritance\uff09\u3001\u590d\u5408\uff08Composition\uff09\u3001\u59d4\u6258\uff08Delegation\uff09\u3002 Part II\u7ee7\u7eed\u63a2\u8ba8\u66f4\u591a\u76f8\u5173\u4e3b\u9898\uff0c\u5e76\u52a0\u4e0a\u4f4e\u9636\u7684\u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff0c\u4ee5\u53ca\u9ad8 \u9636\u7684Templates\uff08\u6a21\u677f\uff09\u7f16\u7a0b\u3002 \u672c\u8bfe\u7a0b\u6240\u8c08\u4e3b\u9898\u90fd\u96b6\u5c5eC++1.0\uff08C++98\uff09\uff1b\u81f3\u4e8eC++ 2.0\uff08C++11/14\uff09\u5e26\u6765\u7684\u5d2d\u65b0 \u5185\u5bb9\u5219\u7531\u4faf\u6377\u8001\u5e08\u7684 \u53e6\u4e00\u95e8\u8bfe\u7a0b \u6db5\u76d6\u3002C++2.0\u5728\u8bed\u8a00\u548c\u6807\u51c6\u5e93\u4e24\u65b9\u9762\u90fd\u5e26\u6765\u4e86\u5f88\u591a\u65b0 \u4e8b\u7269\uff0c\u4efd\u91cf\u8db3\u4ee5\u5f62\u6210\u53e6\u4e00\u95e8\u8bfe\u7a0b\u3002 \u4f60\u5c06\u83b7\u5f97\u6574\u4e2avideo\u8bfe\u7a0b\u7684\u5b8c\u6574\u8bb2\u4e49\uff08\u4e5f\u5c31\u662fvideo\u5448\u73b0\u7684\u6bcf\u4e00\u5f20\u6295\u5f71\u7247\u753b\u9762\uff09\uff0c \u548c\u5b8c\u6574\u7684\u793a\u4f8b\u7a0b\u5e8f\u3002\u4f60\u53ef\u4ee5\uff08\u4e5f\u6709\u5fc5\u8981\uff09\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u968f\u65f6\u505c\u4e0b\u6765\u601d\u8003\u548c\u9605\u8bfb\u8bb2\u4e49\u3002 \u4faf\u6377\u7b80\u4ecb\uff1a\u7a0b\u5e8f\u5458\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u53f0\u6e7e\u5de5\u7814\u9662\u526f\u7814\u7a76\u5458\uff0c\u6559\u6388\uff0c\u4e13\u680f\u4e3b\u7b14\u3002\u66fe\u4efb \u6559\u4e8e\u4e2d\u575c\u5143\u667a\u5927\u5b66\u3001\u4e0a\u6d77\u540c\u6d4e\u5927\u5b66\u3001\u5357\u4eac\u5927\u5b66\u3002\u8457\u6709\u300a\u65e0\u8d23\u4efb\u4e66\u8bc4\u300b\u4e09\u5377\u3001\u300a\u6df1 \u5165\u6d45\u51faMFC\u300b\u3001\u300aSTL\u6e90\u7801\u5256\u6790\u300b\u2026\uff0c\u8bd1\u6709\u300aEffective C++\u300b\u300aMore Effective C++\u300b \u300aC++ Primer\u300b\u300aThe C++ Standard Library\u300b\u2026 \u4ee5\u4e0b\u8fd9\u4efd\u4e0d\u592a\u7ec6\u81f4\u7684\u4e3b\u9898\u5212\u5206\uff0c\u5e2e\u52a9\u60a8\u8ba4\u8bc6\u6574\u4e2a\u8bfe\u7a0b\u5185\u5bb9\u3002","title":"\u8bfe\u7a0b\u7b80\u4ecb"},{"location":"C%2B%2B/C%2B%2B-OOPBase2-HouJie/#c\u9762\u5411\u5c0d\u8c61\u7de8\u7a0b-cobject-oriented-programming","text":"","title":"C++\u9762\u5411\u5c0d\u8c61\u7de8\u7a0b (C++Object-Oriented Programming)"},{"location":"C%2B%2B/C%2B%2B-OOPBase2-HouJie/#part-i","text":"Introduction of C++98, TR1, C++11, C++14 \u2003Bibliography \u2003Data and Functions, from C to C++ \u2003Basic forms of C++ programs \u2003About output \u2003Guard declarations of header files \u2003Layout of headers \u2003Object Based \u2003Class without pointer member \u2003\u2003Class declarations \u2003\u2003Class template, introductions and overviews \u2003\u2003What is 'this' \u2003\u2003Inline functions \u2003\u2003Access levels \u2003\u2003Constructor (ctor) \u2003\u2003Const member functions \u2003\u2003Parameters : pass by value vs. pass by reference \u2003\u2003Return values : return by value vs. return by reference \u2003\u2003Friend \u2003\u2003Definitions outside class body \u2003\u2003Operator overloading, as member function \u2003\u2003Return by reference, again \u2003\u2003Operator overloading, as non-member function \u2003\u2003Temporary objects \u2003\u2003Expertise \u2003\u2003Code demonstration \u2003class with pointer members \u2003\u2003The \"Big Three\" \u2003\u2003\u2003Copy Constructor \u2003\u2003\u2003Copy Assignment Operator \u2003\u2003\u2003Destructor \u2003\u2003Ctor and Dtor, in our String class \u2003\u2003\"MUST HAVE\" in our String class \u2003\u2003\u2003Copy Constructor \u2003\u2003\u2003Copy assignment operator \u2003\u2003Deal with \"self assignment\" \u2003\u2003Another way to deal with \"self assignment\" : Copy and Swap \u2003\u2003Overloading output operator (<<) \u2003\u2003Expertise \u2003\u2003Code demonstration \u2003Objects from stack vs. objects from heap \u2003\u2003Objects lifetime \u2003\u2003new expression : allocate memory and then invoke ctor \u2003\u2003delete expression : invoke dtor and then free memory \u2003\u2003Anatomy of memory blocks from heap \u2003\u2003Allocate an array dynamically \u2003\u2003new[] and delete[] \u2003MORE ISSUES : \u2003\u2003static \u2003\u2003private ctors \u2003\u2003cout \u2003\u2003Class template \u2003\u2003Function template \u2003\u2003namespace \u2003\u2003Standard Library : Introductions and Overviews \u2003Object Oriented \u2003\u2003Composition means \"has-a\" \u2003\u2003\u2003Construction : from inside to outside \u2003\u2003\u2003Destruction : from outside to inside \u2003\u2003Delegation means \"Composition by reference\" \u2003\u2003Inheritance means \"is-a\" \u2003\u2003\u2003Construction : from inside to outside \u2003\u2003\u2003Destruction : from outside to inside \u2003\u2003Construction and Destruction, when Inheritance+Composition \u2003\u2003Inheritance with virtual functions \u2003\u2003Virtual functions typical usage 1 : Template Method \u2003\u2003Virtual functions typical usage 2 : Polymorphism \u2003\u2003Virtual functions inside out : vptr, vtbl, and dynamic binding \u2003\u2003Delegation + Inheritance : Observer \u2003\u2003Delegation + Inheritance : Composite \u2003\u2003Delegation + Inheritance : Prototype","title":"Part I"},{"location":"C%2B%2B/C%2B%2B-OOPBase2-HouJie/#part-ii","text":"\u7eea\u8bba Conversion function\uff08\u8f6c\u6362\u51fd\u6570\uff09 Non-explicit one-argument constructor Pointer-like classes\uff0c\u5173\u4e8e\u667a\u80fd\u6307\u9488 Pointer-like classes\uff0c\u5173\u4e8e\u8fed\u4ee3\u5668 Function-like classes\uff0c\u6240\u8c13\u4eff\u51fd\u6570 \u6807\u51c6\u5e93\u4e2d\u7684\u4eff\u51fd\u6570\u7684\u5947\u7279\u6a21\u6837 namespace\u7ecf\u9a8c\u8c08 class template\uff0c\u7c7b\u6a21\u677f function template\uff0c\u51fd\u6570\u6a21\u677f member template\uff0c\u6210\u5458\u6a21\u677f specialization\uff0c\u6a21\u677f\u7279\u5316 partial specialization\uff0c\u6a21\u677f\u504f\u7279\u5316\u2014\u2014\u4e2a\u6570\u7684\u504f partial specialization\uff0c\u6a21\u677f\u504f\u7279\u5316\u2014\u2014\u8303\u56f4\u7684\u504f template template parameter\uff0c\u6a21\u677f\u6a21\u677f\u53c2\u6570 variadic templates\uff08since C++11\uff09 auto\uff08since C++11\uff09 ranged-base for\uff08since C++11\uff09 reference Composition\uff08\u590d\u5408\uff09\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 Inheritance\uff08\u7ee7\u627f\uff09\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 Inheritance+Composition\u5173\u7cfb\u4e0b\u7684\u6784\u9020\u548c\u6790\u6784 \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8evptr\u548cvtbl \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8ethis \u5bf9\u8c61\u6a21\u578b\uff08Object Model\uff09\uff1a\u5173\u4e8eDynamic Binding \u8c08\u8c08const \u5173\u4e8enew\uff0cdelete \u91cd\u8f7d ::operator new\uff0c::operator delete \u91cd\u8f7d ::operator new[]\uff0c::operator delete[] \u91cd\u8f7d member operator new/delete \u91cd\u8f7d member operator new[]/delete[] \u793a\u4f8b \u91cd\u8f7dnew()\uff0cdelete() \u793a\u4f8b basic_string\u4f7f\u7528new\uff08extra\uff09\u6269\u5145\u7533\u8bf7\u91cf -- the end","title":"Part II"},{"location":"C%2B%2B/C%2B%2B-STL-HouJie/","text":"\u89c6\u9891\u76f4\u8fbe\uff1a C++\u6807\u51c6\u5e93(STL)\u4e0e\u6cdb\u578b\u7f16\u7a0b \u8bfe\u7a0b\u8bb2\u4e49\u4e0b\u8f7d\u76f4\u8fbe\uff1a slide \u6e90\u4ee3\u7801\u76f4\u8fbe\uff1a code \u5019\u6377\u8001\u5e08 C++ \u7cfb\u5217\u8bfe\u7a0b\u5bfc\u822a\uff1a\uff08\u7f16\u53f7\u987a\u5e8f\u53ef\u4f5c\u4e3a\u5b66\u4e60\u987a\u5e8f\u53c2\u8003\uff09 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0a\uff09-\u57fa\u4e8e\u5bf9\u8c61\u548c\u9762\u5411\u5bf9\u8c61 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0b\uff09-\u517c\u8c08\u5bf9\u8c61\u6a21\u578b C++\u6807\u51c6\u5e93(STL)\u4e0e\u6cdb\u578b\u7f16\u7a0b C++\u65b0\u6807\u51c6-C++11/14 C++\u5185\u5b58\u7ba1\u7406 C++Startup\u63ed\u79d8","title":"Index"},{"location":"C%2B%2B/C%2B%2B-newC%2B%2B11%2614-HouJie/","text":"\u89c6\u9891\u76f4\u8fbe\uff1a C++\u65b0\u6807\u51c6-C++11/14 \u8bfe\u7a0b\u8bb2\u4e49\u4e0b\u8f7d\u76f4\u8fbe\uff1a slide \u6e90\u4ee3\u7801\u76f4\u8fbe\uff1a\u62b1\u6b49\uff0cC++11\u7684\u6e90\u4ee3\u7801\u5b9e\u5728\u627e\u4e0d\u5230\uff0c\u8bfe\u4ef6\u662f\u8bfe\u7a0b\u89c6\u9891\u7684\u622a\u56fe\u62fc\u63a5\u8d77\u6765\u7684\uff0c\u53ef\u80fd\u6548\u679c\u4e0d\u597d\uff0c\u4f46\u80fd\u7528\uff01 \u5019\u6377\u8001\u5e08 C++ \u7cfb\u5217\u8bfe\u7a0b\u5bfc\u822a\uff1a\uff08\u7f16\u53f7\u987a\u5e8f\u53ef\u4f5c\u4e3a\u5b66\u4e60\u987a\u5e8f\u53c2\u8003\uff09 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0a\uff09-\u57fa\u4e8e\u5bf9\u8c61\u548c\u9762\u5411\u5bf9\u8c61 C++\u9762\u5411\u5bf9\u8c61\u9ad8\u7ea7\u7f16\u7a0b\uff08\u4e0b\uff09-\u517c\u8c08\u5bf9\u8c61\u6a21\u578b C++\u6807\u51c6\u5e93(STL)\u4e0e\u6cdb\u578b\u7f16\u7a0b C++\u65b0\u6807\u51c6-C++11/14 C++\u5185\u5b58\u7ba1\u7406 C++Startup\u63ed\u79d8","title":"Index"},{"location":"C%2B%2B/Note/C%2B%2BOOP/","text":"\u53ea\u662f\u4e2a\u4eba\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u89c9\u5f97\u4e00\u4e9b\u503c\u5f97\u6ce8\u610f\u7684\u5730\u65b9\uff0c\u5e76\u4e0d\u662f\u7cfb\u7edf\u7684\u7b14\u8bb0\u3002 \u8bb0\u7b14\u8bb0\u7684\u552f\u4e00\u76ee\u7684\u662f\u52a0\u6df1\u5370\u8c61\uff0c\u800c\u4e0d\u662f\u65b9\u4fbf\u67e5\u9605\u3002\u4e8b\u5b9e\u4e0a\uff0c\u4e2a\u4eba\u89c9\u5f97 C++ \u5185\u5bb9\u5e9e\u5927\u4e14\u590d\u6742\uff0c\u800c\u4e14\u91cd\u70b9\u4f3c\u4e4e\u5e76\u4e0d\u975e\u5e38\u7a81\u51fa\uff08\u56e0\u4e3a\u5904\u5904\u662f\u91cd\u70b9\uff09\uff0c\u5982\u679c\u4e3a\u4e86\u65b9\u4fbf\u67e5\u9605\u4e0d\u59a8\u5907\u4e00\u672c\u5de5\u5177\u4e66\u3002 \u300aC++ Primer\u300b \u662f\u4e00\u672c\u975e\u5e38\u4e0d\u9519\u7684\u9009\u62e9\uff0c\u5b83\u9002\u5408\u7cfb\u7edf\u5b66\u4e60\uff0c\u4e5f\u65b9\u4fbf\u4f60\u5bf9\u54ea\u5757\u5185\u5bb9\u6a21\u7cca\u4e86\u56de\u5934\u7ffb\u9605\uff0c\u540c\u65f6\u4e5f\u662f\u4e00\u672c\u4e0d\u9519\u7684\u53c2\u8003\u4e66\u3002 \u4faf\u6377\u8001\u5e08\u7684\u8bfe\u7a0b\uff0c\u9002\u5408\u521d\u5b66\u8005\u5bf9 C++ \u9762\u5411\u5bf9\u8c61\u90e8\u5206\u4e0d\u6c42\u751a\u89e3\u5730\u5927\u4f53\u4e00\u89c8\uff0c\u7136\u540e\u7cfb\u7edf\u5730\u5b66\u4e60 C++ \u4f1a\u66f4\u8f7b\u677e\uff1b\u9002\u5408\u5b66\u4e60\u5230\u4e00\u5b9a\u7a0b\u5ea6\u540e\u5bf9 C++ \u603b\u4f53\u56de\u5473\uff0c\u8fd8\u4f1a\u6536\u83b7\u9887\u4e30\u3002\u4f46\u5982\u679c\u60f3\u7cfb\u7edf\u5168\u9762\u5730\u8ba4\u8bc6\u3001\u5b66\u4e60 C++ \uff0c\u4e00\u672c\u4e0d\u9519\u7684\u4e66\u7c4d\u662f\u66f4\u597d\u7684\u9009\u62e9\u3002 \u57fa\u4e8e\u5bf9\u8c61 \u00b6 \u4e0d\u5e26\u6307\u9488\u7684\u7c7b Complex \u00b6 \u5173\u4e8e\u5934\u6587\u4ef6\u4e2d\u7684\u9632\u536b\u5f0f\u58f0\u660e \u00b6 \u5728\u5934\u6587\u4ef6\u4e2d\u52a0\u5165\u5982\u4e0b\u8fd9\u6837\u7684\u9632\u536b\u5f0f\u58f0\u660e\u662f\u5f88\u6709\u5fc5\u8981\u7684\uff0c\u9632\u6b62\u591a\u6b21\u91cd\u590d\u5f15\u5165\u540c\u4e00\u5934\u6587\u4ef6\uff1a // complex.h #ifndef __COMPLEX__ #define __COMPLEX__ ... #endif \u5173\u4e8e\u6784\u9020\u51fd\u6570 \u00b6 \u9ed8\u8ba4\u6784\u9020\u51fd\u6570 \u00b6 \u5982\u679c\u6ca1\u6709\u81ea\u5b9a\u4e49\u6784\u9020\u51fd\u6570\uff0c\u90a3\u4e48\u7f16\u8bd1\u5668\u4f1a\u4e3a\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u9ed8\u8ba4\u6784\u9020\u51fd\u6570\uff0c\u5bf9\u5927\u591a\u6570\u7c7b\u6765\u8bf4\u5b83\u6309\u7167\u5982\u4e0b\u89c4\u5219\u521d\u59cb\u5316\u7c7b\u7684\u6570\u636e\u6210\u5458\uff1a \u5982\u679c\u5b58\u5728\u7c7b\u5185\u521d\u59cb\u503c\uff0c\u7528\u5b83\u6765\u521d\u59cb\u5316\u6210\u5458\uff08C++11 \u652f\u6301\u4e3a\u6570\u636e\u6210\u5458\u63d0\u4f9b\u4e00\u4e2a\u7c7b\u5185\u521d\u59cb\u503c\uff09\uff1b \u5426\u5219\uff0c\u5bf9\u4e8e\u5185\u7f6e\u7c7b\u578b\u6210\u5458\u5c06\u4e0d\u88ab\u521d\u59cb\u5316\uff0c\u5bf9\u4e8e\u7c7b\u7c7b\u578b\u6210\u5458\u5c06\u8c03\u7528\u9ed8\u8ba4\u6784\u9020\u51fd\u6570\u3002 \u4e00\u4e2a\u672a\u88ab\u521d\u59cb\u5316\u7684\u5185\u7f6e\u7c7b\u578b\u6210\u5458\u7684\u503c\u662f\u672a\u5b9a\u4e49\u7684\uff0c\u56e0\u6b64\u4e3a\u6210\u5458\u53d8\u91cf\u63d0\u4f9b\u4e00\u4e2a\u7c7b\u5185\u521d\u59cb\u503c\u662f\u4e00\u4e2a\u597d\u4e60\u60ef\u3002\u5982\u679c\u7f16\u8bd1\u5668\u4e0d\u652f\u6301C++11\uff0c\u90a3\u4e48\u597d\u7684\u505a\u6cd5\u662f\u5728\u6240\u6709\u6784\u9020\u51fd\u6570\u4e2d\u521d\u59cb\u5316\u6240\u6709\u6210\u5458\u3002 \u5b9a\u4e49\u6784\u9020\u51fd\u6570 \u00b6 \u5199\u4e00\u4e2a\u6784\u9020\u51fd\u6570\u65f6\uff0c\u5e94\u5c3d\u91cf\u4f7f\u7528\u6784\u9020\u51fd\u6570\u7684\u7279\u6b8a\u8bed\u6cd5\uff08\u521d\u59cb\u503c\u5217\u8868\uff09\u6765\u521d\u59cb\u5316\u6210\u5458\u53d8\u91cf\uff0c\u800c\u4e0d\u8981\u5728\u51fd\u6570\u4f53\u5185\u91c7\u7528\u8d4b\u503c\u7684\u65b9\u6cd5\u3002 // \u6784\u9020\u51fd\u6570\u521d\u59cb\u503c\u5217\u8868\uff0c\u63d0\u5021\u7684\u65b9\u6cd5 complex ( double r = 0 , double i = 0 ) : re ( r ), im ( i ) {} // \u4f4e\u6548\u7684\u65b9\u6cd5 // \u4e8b\u5b9e\u4e0a\u5148\u6267\u884c\u9ed8\u8ba4\u6784\u9020\u51fd\u6570\uff0c\u7136\u540e\u6267\u884c\u8be5\u6784\u9020\u51fd\u6570\u4f53\u5185\u7684\u201c\u8d4b\u503c\u8bed\u53e5\u201d complex ( double r = 0 , double i = 0 ) { re = r ; im = i ; // \u8fd9\u4e0d\u662f\u521d\u59cb\u5316\uff0c\u662f\u8d4b\u503c } \u4e8b\u5b9e\u4e0a\uff0c\u6709\u65f6\u5fc5\u987b\u4f7f\u7528\u6784\u9020\u51fd\u6570\u521d\u59cb\u503c\u5217\u8868\u3002 \u5982\u679c\u6ca1\u6709\u5728\u6784\u9020\u51fd\u6570\u7684\u521d\u59cb\u503c\u5217\u8868\u4e2d\u663e\u5f0f\u5730 \u521d\u59cb\u5316 \u6210\u5458\uff0c\u5373\u4f7f\u7528\u7b2c\u4e8c\u79cd\u6784\u9020\u51fd\u6570\uff0c\u5219\u5c06\u5728\u6784\u9020\u51fd\u6570\u4f53\u4e4b\u524d\u6267\u884c\u9ed8\u8ba4\u521d\u59cb\u5316\uff0c\u7136\u540e\u5728\u51fd\u6570\u4f53\u4e2d\u6267\u884c \u8d4b\u503c \u64cd\u4f5c\u3002\u56e0\u6b64\uff0c\u5982\u679c\u6210\u5458\u662f const \u6216\u8005\u662f\u5f15\u7528\u7684\u8bdd\uff0c\u5219\u53ea\u80fd\u4f7f\u7528\u521d\u59cb\u503c\u5217\u8868\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u56e0\u4e3a\u4e0d\u80fd\u5bf9\u4e00\u4e2a const \u6216\u8005\u5f15\u7528\u8d4b\u503c\u3002 \u53c2\u770b \u300aC++ Primer \u4e2d\u6587\u7248 \u7b2c5\u7248\u300b \u7b2c258\u9875 \u5173\u4e8e\u5e38\u91cf\u6210\u5458\u51fd\u6570 \u00b6 // \u5728\u53c2\u6570\u5217\u8868\u4e4b\u540e\u7d27\u63a5\u4e00\u4e2a const \u5173\u952e\u5b57\uff0c\u8fd9\u6837\u7684\u6210\u5458\u51fd\u6570\u79f0\u4e3a\u5e38\u91cf\u6210\u5458\u51fd\u6570 double real () const { return re ; } \u8fd9\u91cc const \u7684\u4f5c\u7528\u662f\u4fee\u6539\u9690\u5f0f this \u6307\u9488\u7684\u7c7b\u578b\u3002\u5728\u9ed8\u8ba4\u60c5\u51b5\u4e0b this \u7684\u7c7b\u578b\u662f\u6307\u5411\u7c7b\u7c7b\u578b\u7684\u975e\u5e38\u91cf\u7248\u672c\u7684\u5e38\u91cf\u6307\u9488\uff0c\u56e0\u6b64\u5bf9\u4e8e\u6ca1\u6709 const \u4fee\u9970\u7684\u666e\u901a\u6210\u5458\u51fd\u6570\uff0c\u5c06\u4e0d\u80fd\u88ab\u4e00\u4e2a\u5e38\u91cf\u5bf9\u8c61\u8c03\u7528\uff08\u65e0\u6cd5\u5c06\u6307\u5411\u975e const \u5bf9\u8c61\u7684 this \u7ed1\u5b9a\u5230\u4e00\u4e2a const \u5bf9\u8c61\u4e0a\uff09\u3002 \u56e0\u6b64\u5bf9\u4e8e\u4e0d\u5e94\u4fee\u6539 data \u7684\u6210\u5458\u51fd\u6570\u4ee5 const \u4fee\u9970\uff0c\u4e0d\u6b62\u662f\u4e3a\u4e86\u9632\u6b62\u4f7f\u7528\u8005\u4fee\u6539 data \u800c\u5df2\u3002\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\uff0c\u4e0d\u4ee5 const \u4fee\u9970\u662f\u4e00\u79cd\u9519\u8bef\u3002 \u5173\u4e8e \u9690\u5f0f this \u6307\u9488\uff0c\u8bd5\u7740\u8fd9\u6837\u7406\u89e3\uff1a\u5bf9\u4e8e\u4e00\u4e2a complex \u5bf9\u8c61 c1 \uff0c\u5b83\u8c03\u7528 real() \u6210\u5458\u51fd\u6570\u65f6\uff0c\u5219\u9690\u5f0f\u5730\u5c06\u4e00\u4e2a\u6307\u5411\u5bf9\u8c61 c1 \u7684\u6307\u9488 this \u4f20\u9012\u7ed9\u4e86\u51fd\u6570 real() \uff0c\u5728\u51fd\u6570\u5185\u6267\u884c return this->re; \u4ece\u800c\u53d6\u5f97\u5bf9\u8c61 c1 \u7684\u5b9e\u90e8\u3002 \u7b80\u5355\u6765\u8bf4\uff1a this \u672c\u8eab\u662f\u4e00\u4e2a\u9876\u5c42 const\uff0c\u5e38\u91cf\u6210\u5458\u51fd\u6570\u4e3a this \u52a0\u4e0a\u4e00\u4e2a\u5e95\u5c42 const\uff0c\u4f7f\u5f97\u5e38\u91cf\u5bf9\u8c61\u4e5f\u53ef\u4ee5\u8c03\u7528\u8be5\u6210\u5458\u51fd\u6570 \uff08\u5373\u5c06\u5176\u5730\u5740\u8d4b\u503c\u7ed9 this\uff09\u3002 \u53c2\u770b \u300aC++ Primer \u4e2d\u6587\u7248 \u7b2c5\u7248\u300b \u7b2c231\u9875\u5bf9 const \u6210\u5458\u51fd\u6570\u7684\u4ecb\u7ecd\u3002 \u5173\u4e8e\u53cb\u5143 \u00b6 complex \u7c7b\u53ef\u4ee5\u5141\u8bb8\u5176\u4ed6\u7c7b\u6216\u51fd\u6570\u8bbf\u95ee\u5b83\u7684 private \u6210\u5458\uff0c\u4ee5 friend \u5173\u952e\u8bcd\u4fee\u9970\u5bf9\u5e94\u7684\u7c7b\u6216\u51fd\u6570\u4f7f\u5176\u6210\u4e3a complex \u7c7b\u7684\u53cb\u5143\u5373\u53ef\uff1a class complex { // \u5c06\u6210\u5458\u51fd\u6570\u58f0\u660e\u4e3a\u53cb\u5143 friend complex & __doapl ( complex * , const complex & ); // \u5c06\u975e\u6210\u5458\u51fd\u6570\u58f0\u660e\u4e3a\u53cb\u5143 friend complex complex & my_doapl ( complex * , const complex & ); } \u76f8\u540c class \u5bf9\u5404\u4e2a\u5bf9\u8c61\u4e92\u4e3a\u53cb\u5143\uff08\u53ef\u4ee5\u4e92\u76f8\u8bbf\u95ee private \u6210\u5458\uff09\u3002 \u5173\u4e8e\u91cd\u8f7d\u51fd\u6570 \u00b6 // \u4ee5\u91cd\u8f7d complex \u7c7b\u7684\u6784\u9020\u51fd\u6570\u4e3a\u4f8b\uff1a complex ( double r = 0 , double i = 0 ) : re ( r ), im ( i ) {} complex () : re ( 0 ), im ( 0 ) {} // \u4e0d\u53ef\u884c\uff01 \u8fd9\u6837\u7684\u91cd\u8f7d\u51fd\u6570\u662f\u4e0d\u53ef\u4ee5\u7684\uff0c\u4e5f\u662f\u591a\u4f59\u7684\uff01\u867d\u7136\u4e8c\u8005\u53c2\u6570\u5217\u8868\u4e0d\u540c\uff0c\u4f46\u7b2c\u4e00\u4e2a\u6784\u9020\u51fd\u6570\u4e3a\u6bcf\u4e00\u4e2a\u5f62\u53c2\u90fd\u63d0\u4f9b\u4e86\u9ed8\u8ba4\u503c\uff0c\u5f53\u4f7f\u7528\u5982\u4e0b\u65b9\u6cd5\u5b9a\u4e49\u4e00\u4e2a complex \u7c7b\u65f6\uff0c\u7f16\u8bd1\u5668\u4e0d\u77e5\u9053\u8be5\u8c03\u7528\u54ea\u4e00\u4e2a\u3002 // \u4e24\u79cd\u65b9\u6cd5\u7b49\u4ef7\uff0c\u90fd\u8868\u793a\u4e0d\u63d0\u4f9b\u53c2\u6570\u8c03\u7528 complex \u6784\u9020\u51fd\u6570 complex c1 ; complex c2 (); \u5e26\u6307\u9488\u7684\u7c7b String \u00b6 \u5173\u4e8e Big Three \u00b6 class with pointer members \u5fc5\u9808\u8981\u6709 copy ctor (\u62f7\u8d1d\u6784\u9020) copy op= (\u8d4b\u503c\u6784\u9020) \u6790\u6784\u51fd\u6570 \u5173\u4e8e\u62f7\u8d1d\u6784\u9020\u51fd\u6570 \u00b6 inline String :: String ( const String & str ){ m_data = new char [ strlen ( str . m_data ) + 1 ]; // \u540c\u7c7b\u5bf9\u8c61\u4e92\u4e3afriend\uff0c\u76f4\u63a5\u53d6\u53e6\u4e00\u4e2aobject\u7684private data strcpy ( m_data , str . m_data ); } { String s1 ( \"hello \" ); String s2 ( s1 ); // String s2 = s1; \u4e0es2(s1)\u4e00\u6837\u8c03\u7528\u62f7\u8d1d\u6784\u9020\u51fd\u6570\uff0c\u56e0\u4e3a\u8fd9\u91cc\u5b9a\u4e49\u4e00\u4e2a\u65b0\u5bf9\u8c61\uff0c\u6240\u4ee5\u4e0d\u662f\u62f7\u8d1d\u8d4b\u503c } \u5173\u4e8e\u62f7\u8d1d\u8d4b\u503c \u00b6 inline String & String :: operator = ( const String & str ){ if ( this == & str ) // \u68c0\u6d4b\u81ea\u6211\u8d4b\u503c return * this ; delete [] m_data ; // \u7b2c\u4e00\u6b65 m_data = new char [ strlen ( str . m_data ) + 1 ]; // \u7b2c\u4e8c\u6b65 strcpy ( m_data , str . m_data ); // \u7b2c\u4e09\u6b65 return * this ; } \u7279\u522b\u6ce8\u610f\u5bf9\u81ea\u6211\u8d4b\u503c\u7684\u68c0\u6d4b\uff01\u8fd9\u4e00\u70b9\u5c24\u5176\u91cd\u8981\uff01 \u770b\u5230\u7684\u7b2c\u4e00\u5c42\u4f3c\u4e4e\u53ea\u662f\u5bf9\u6548\u7387\u7684\u63d0\u5347\uff0c\u800c\u66f4\u6df1\u4e00\u5c42\u66f4\u4e3a\u91cd\u8981\uff1a\u5982\u679c\u6ca1\u6709\u5bf9\u81ea\u6211\u8d4b\u503c\u7684\u68c0\u6d4b\uff0c\u90a3\u4e48\u8fdb\u884c\u7b2c\u4e00\u6b65\u91ca\u653e\u5185\u5b58\u65f6\u5373\u5c06\u81ea\u8eab\u7684 data \u7ed9\u91ca\u653e\u6389\u4e86\uff0c\u90a3\u7b2c\u4e8c\u6b65\u518d\u8981\u53d6 data \u4ece\u4f55\u800c\u6765\u5462\uff1f","title":"C++OOP"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u57fa\u4e8e\u5bf9\u8c61","text":"","title":"\u57fa\u4e8e\u5bf9\u8c61"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u4e0d\u5e26\u6307\u9488\u7684\u7c7b-complex","text":"","title":"\u4e0d\u5e26\u6307\u9488\u7684\u7c7b Complex"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u5173\u4e8e\u5934\u6587\u4ef6\u4e2d\u7684\u9632\u536b\u5f0f\u58f0\u660e","text":"\u5728\u5934\u6587\u4ef6\u4e2d\u52a0\u5165\u5982\u4e0b\u8fd9\u6837\u7684\u9632\u536b\u5f0f\u58f0\u660e\u662f\u5f88\u6709\u5fc5\u8981\u7684\uff0c\u9632\u6b62\u591a\u6b21\u91cd\u590d\u5f15\u5165\u540c\u4e00\u5934\u6587\u4ef6\uff1a // complex.h #ifndef __COMPLEX__ #define __COMPLEX__ ... #endif","title":"\u5173\u4e8e\u5934\u6587\u4ef6\u4e2d\u7684\u9632\u536b\u5f0f\u58f0\u660e"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u5173\u4e8e\u6784\u9020\u51fd\u6570","text":"","title":"\u5173\u4e8e\u6784\u9020\u51fd\u6570"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u9ed8\u8ba4\u6784\u9020\u51fd\u6570","text":"\u5982\u679c\u6ca1\u6709\u81ea\u5b9a\u4e49\u6784\u9020\u51fd\u6570\uff0c\u90a3\u4e48\u7f16\u8bd1\u5668\u4f1a\u4e3a\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u9ed8\u8ba4\u6784\u9020\u51fd\u6570\uff0c\u5bf9\u5927\u591a\u6570\u7c7b\u6765\u8bf4\u5b83\u6309\u7167\u5982\u4e0b\u89c4\u5219\u521d\u59cb\u5316\u7c7b\u7684\u6570\u636e\u6210\u5458\uff1a \u5982\u679c\u5b58\u5728\u7c7b\u5185\u521d\u59cb\u503c\uff0c\u7528\u5b83\u6765\u521d\u59cb\u5316\u6210\u5458\uff08C++11 \u652f\u6301\u4e3a\u6570\u636e\u6210\u5458\u63d0\u4f9b\u4e00\u4e2a\u7c7b\u5185\u521d\u59cb\u503c\uff09\uff1b \u5426\u5219\uff0c\u5bf9\u4e8e\u5185\u7f6e\u7c7b\u578b\u6210\u5458\u5c06\u4e0d\u88ab\u521d\u59cb\u5316\uff0c\u5bf9\u4e8e\u7c7b\u7c7b\u578b\u6210\u5458\u5c06\u8c03\u7528\u9ed8\u8ba4\u6784\u9020\u51fd\u6570\u3002 \u4e00\u4e2a\u672a\u88ab\u521d\u59cb\u5316\u7684\u5185\u7f6e\u7c7b\u578b\u6210\u5458\u7684\u503c\u662f\u672a\u5b9a\u4e49\u7684\uff0c\u56e0\u6b64\u4e3a\u6210\u5458\u53d8\u91cf\u63d0\u4f9b\u4e00\u4e2a\u7c7b\u5185\u521d\u59cb\u503c\u662f\u4e00\u4e2a\u597d\u4e60\u60ef\u3002\u5982\u679c\u7f16\u8bd1\u5668\u4e0d\u652f\u6301C++11\uff0c\u90a3\u4e48\u597d\u7684\u505a\u6cd5\u662f\u5728\u6240\u6709\u6784\u9020\u51fd\u6570\u4e2d\u521d\u59cb\u5316\u6240\u6709\u6210\u5458\u3002","title":"\u9ed8\u8ba4\u6784\u9020\u51fd\u6570"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u5b9a\u4e49\u6784\u9020\u51fd\u6570","text":"\u5199\u4e00\u4e2a\u6784\u9020\u51fd\u6570\u65f6\uff0c\u5e94\u5c3d\u91cf\u4f7f\u7528\u6784\u9020\u51fd\u6570\u7684\u7279\u6b8a\u8bed\u6cd5\uff08\u521d\u59cb\u503c\u5217\u8868\uff09\u6765\u521d\u59cb\u5316\u6210\u5458\u53d8\u91cf\uff0c\u800c\u4e0d\u8981\u5728\u51fd\u6570\u4f53\u5185\u91c7\u7528\u8d4b\u503c\u7684\u65b9\u6cd5\u3002 // \u6784\u9020\u51fd\u6570\u521d\u59cb\u503c\u5217\u8868\uff0c\u63d0\u5021\u7684\u65b9\u6cd5 complex ( double r = 0 , double i = 0 ) : re ( r ), im ( i ) {} // \u4f4e\u6548\u7684\u65b9\u6cd5 // \u4e8b\u5b9e\u4e0a\u5148\u6267\u884c\u9ed8\u8ba4\u6784\u9020\u51fd\u6570\uff0c\u7136\u540e\u6267\u884c\u8be5\u6784\u9020\u51fd\u6570\u4f53\u5185\u7684\u201c\u8d4b\u503c\u8bed\u53e5\u201d complex ( double r = 0 , double i = 0 ) { re = r ; im = i ; // \u8fd9\u4e0d\u662f\u521d\u59cb\u5316\uff0c\u662f\u8d4b\u503c } \u4e8b\u5b9e\u4e0a\uff0c\u6709\u65f6\u5fc5\u987b\u4f7f\u7528\u6784\u9020\u51fd\u6570\u521d\u59cb\u503c\u5217\u8868\u3002 \u5982\u679c\u6ca1\u6709\u5728\u6784\u9020\u51fd\u6570\u7684\u521d\u59cb\u503c\u5217\u8868\u4e2d\u663e\u5f0f\u5730 \u521d\u59cb\u5316 \u6210\u5458\uff0c\u5373\u4f7f\u7528\u7b2c\u4e8c\u79cd\u6784\u9020\u51fd\u6570\uff0c\u5219\u5c06\u5728\u6784\u9020\u51fd\u6570\u4f53\u4e4b\u524d\u6267\u884c\u9ed8\u8ba4\u521d\u59cb\u5316\uff0c\u7136\u540e\u5728\u51fd\u6570\u4f53\u4e2d\u6267\u884c \u8d4b\u503c \u64cd\u4f5c\u3002\u56e0\u6b64\uff0c\u5982\u679c\u6210\u5458\u662f const \u6216\u8005\u662f\u5f15\u7528\u7684\u8bdd\uff0c\u5219\u53ea\u80fd\u4f7f\u7528\u521d\u59cb\u503c\u5217\u8868\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u56e0\u4e3a\u4e0d\u80fd\u5bf9\u4e00\u4e2a const \u6216\u8005\u5f15\u7528\u8d4b\u503c\u3002 \u53c2\u770b \u300aC++ Primer \u4e2d\u6587\u7248 \u7b2c5\u7248\u300b \u7b2c258\u9875","title":"\u5b9a\u4e49\u6784\u9020\u51fd\u6570"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u5173\u4e8e\u5e38\u91cf\u6210\u5458\u51fd\u6570","text":"// \u5728\u53c2\u6570\u5217\u8868\u4e4b\u540e\u7d27\u63a5\u4e00\u4e2a const \u5173\u952e\u5b57\uff0c\u8fd9\u6837\u7684\u6210\u5458\u51fd\u6570\u79f0\u4e3a\u5e38\u91cf\u6210\u5458\u51fd\u6570 double real () const { return re ; } \u8fd9\u91cc const \u7684\u4f5c\u7528\u662f\u4fee\u6539\u9690\u5f0f this \u6307\u9488\u7684\u7c7b\u578b\u3002\u5728\u9ed8\u8ba4\u60c5\u51b5\u4e0b this \u7684\u7c7b\u578b\u662f\u6307\u5411\u7c7b\u7c7b\u578b\u7684\u975e\u5e38\u91cf\u7248\u672c\u7684\u5e38\u91cf\u6307\u9488\uff0c\u56e0\u6b64\u5bf9\u4e8e\u6ca1\u6709 const \u4fee\u9970\u7684\u666e\u901a\u6210\u5458\u51fd\u6570\uff0c\u5c06\u4e0d\u80fd\u88ab\u4e00\u4e2a\u5e38\u91cf\u5bf9\u8c61\u8c03\u7528\uff08\u65e0\u6cd5\u5c06\u6307\u5411\u975e const \u5bf9\u8c61\u7684 this \u7ed1\u5b9a\u5230\u4e00\u4e2a const \u5bf9\u8c61\u4e0a\uff09\u3002 \u56e0\u6b64\u5bf9\u4e8e\u4e0d\u5e94\u4fee\u6539 data \u7684\u6210\u5458\u51fd\u6570\u4ee5 const \u4fee\u9970\uff0c\u4e0d\u6b62\u662f\u4e3a\u4e86\u9632\u6b62\u4f7f\u7528\u8005\u4fee\u6539 data \u800c\u5df2\u3002\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\uff0c\u4e0d\u4ee5 const \u4fee\u9970\u662f\u4e00\u79cd\u9519\u8bef\u3002 \u5173\u4e8e \u9690\u5f0f this \u6307\u9488\uff0c\u8bd5\u7740\u8fd9\u6837\u7406\u89e3\uff1a\u5bf9\u4e8e\u4e00\u4e2a complex \u5bf9\u8c61 c1 \uff0c\u5b83\u8c03\u7528 real() \u6210\u5458\u51fd\u6570\u65f6\uff0c\u5219\u9690\u5f0f\u5730\u5c06\u4e00\u4e2a\u6307\u5411\u5bf9\u8c61 c1 \u7684\u6307\u9488 this \u4f20\u9012\u7ed9\u4e86\u51fd\u6570 real() \uff0c\u5728\u51fd\u6570\u5185\u6267\u884c return this->re; \u4ece\u800c\u53d6\u5f97\u5bf9\u8c61 c1 \u7684\u5b9e\u90e8\u3002 \u7b80\u5355\u6765\u8bf4\uff1a this \u672c\u8eab\u662f\u4e00\u4e2a\u9876\u5c42 const\uff0c\u5e38\u91cf\u6210\u5458\u51fd\u6570\u4e3a this \u52a0\u4e0a\u4e00\u4e2a\u5e95\u5c42 const\uff0c\u4f7f\u5f97\u5e38\u91cf\u5bf9\u8c61\u4e5f\u53ef\u4ee5\u8c03\u7528\u8be5\u6210\u5458\u51fd\u6570 \uff08\u5373\u5c06\u5176\u5730\u5740\u8d4b\u503c\u7ed9 this\uff09\u3002 \u53c2\u770b \u300aC++ Primer \u4e2d\u6587\u7248 \u7b2c5\u7248\u300b \u7b2c231\u9875\u5bf9 const \u6210\u5458\u51fd\u6570\u7684\u4ecb\u7ecd\u3002","title":"\u5173\u4e8e\u5e38\u91cf\u6210\u5458\u51fd\u6570"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u5173\u4e8e\u53cb\u5143","text":"complex \u7c7b\u53ef\u4ee5\u5141\u8bb8\u5176\u4ed6\u7c7b\u6216\u51fd\u6570\u8bbf\u95ee\u5b83\u7684 private \u6210\u5458\uff0c\u4ee5 friend \u5173\u952e\u8bcd\u4fee\u9970\u5bf9\u5e94\u7684\u7c7b\u6216\u51fd\u6570\u4f7f\u5176\u6210\u4e3a complex \u7c7b\u7684\u53cb\u5143\u5373\u53ef\uff1a class complex { // \u5c06\u6210\u5458\u51fd\u6570\u58f0\u660e\u4e3a\u53cb\u5143 friend complex & __doapl ( complex * , const complex & ); // \u5c06\u975e\u6210\u5458\u51fd\u6570\u58f0\u660e\u4e3a\u53cb\u5143 friend complex complex & my_doapl ( complex * , const complex & ); } \u76f8\u540c class \u5bf9\u5404\u4e2a\u5bf9\u8c61\u4e92\u4e3a\u53cb\u5143\uff08\u53ef\u4ee5\u4e92\u76f8\u8bbf\u95ee private \u6210\u5458\uff09\u3002","title":"\u5173\u4e8e\u53cb\u5143"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u5173\u4e8e\u91cd\u8f7d\u51fd\u6570","text":"// \u4ee5\u91cd\u8f7d complex \u7c7b\u7684\u6784\u9020\u51fd\u6570\u4e3a\u4f8b\uff1a complex ( double r = 0 , double i = 0 ) : re ( r ), im ( i ) {} complex () : re ( 0 ), im ( 0 ) {} // \u4e0d\u53ef\u884c\uff01 \u8fd9\u6837\u7684\u91cd\u8f7d\u51fd\u6570\u662f\u4e0d\u53ef\u4ee5\u7684\uff0c\u4e5f\u662f\u591a\u4f59\u7684\uff01\u867d\u7136\u4e8c\u8005\u53c2\u6570\u5217\u8868\u4e0d\u540c\uff0c\u4f46\u7b2c\u4e00\u4e2a\u6784\u9020\u51fd\u6570\u4e3a\u6bcf\u4e00\u4e2a\u5f62\u53c2\u90fd\u63d0\u4f9b\u4e86\u9ed8\u8ba4\u503c\uff0c\u5f53\u4f7f\u7528\u5982\u4e0b\u65b9\u6cd5\u5b9a\u4e49\u4e00\u4e2a complex \u7c7b\u65f6\uff0c\u7f16\u8bd1\u5668\u4e0d\u77e5\u9053\u8be5\u8c03\u7528\u54ea\u4e00\u4e2a\u3002 // \u4e24\u79cd\u65b9\u6cd5\u7b49\u4ef7\uff0c\u90fd\u8868\u793a\u4e0d\u63d0\u4f9b\u53c2\u6570\u8c03\u7528 complex \u6784\u9020\u51fd\u6570 complex c1 ; complex c2 ();","title":"\u5173\u4e8e\u91cd\u8f7d\u51fd\u6570"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u5e26\u6307\u9488\u7684\u7c7b-string","text":"","title":"\u5e26\u6307\u9488\u7684\u7c7b String"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u5173\u4e8e-big-three","text":"class with pointer members \u5fc5\u9808\u8981\u6709 copy ctor (\u62f7\u8d1d\u6784\u9020) copy op= (\u8d4b\u503c\u6784\u9020) \u6790\u6784\u51fd\u6570","title":"\u5173\u4e8e Big Three"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u5173\u4e8e\u62f7\u8d1d\u6784\u9020\u51fd\u6570","text":"inline String :: String ( const String & str ){ m_data = new char [ strlen ( str . m_data ) + 1 ]; // \u540c\u7c7b\u5bf9\u8c61\u4e92\u4e3afriend\uff0c\u76f4\u63a5\u53d6\u53e6\u4e00\u4e2aobject\u7684private data strcpy ( m_data , str . m_data ); } { String s1 ( \"hello \" ); String s2 ( s1 ); // String s2 = s1; \u4e0es2(s1)\u4e00\u6837\u8c03\u7528\u62f7\u8d1d\u6784\u9020\u51fd\u6570\uff0c\u56e0\u4e3a\u8fd9\u91cc\u5b9a\u4e49\u4e00\u4e2a\u65b0\u5bf9\u8c61\uff0c\u6240\u4ee5\u4e0d\u662f\u62f7\u8d1d\u8d4b\u503c }","title":"\u5173\u4e8e\u62f7\u8d1d\u6784\u9020\u51fd\u6570"},{"location":"C%2B%2B/Note/C%2B%2BOOP/#\u5173\u4e8e\u62f7\u8d1d\u8d4b\u503c","text":"inline String & String :: operator = ( const String & str ){ if ( this == & str ) // \u68c0\u6d4b\u81ea\u6211\u8d4b\u503c return * this ; delete [] m_data ; // \u7b2c\u4e00\u6b65 m_data = new char [ strlen ( str . m_data ) + 1 ]; // \u7b2c\u4e8c\u6b65 strcpy ( m_data , str . m_data ); // \u7b2c\u4e09\u6b65 return * this ; } \u7279\u522b\u6ce8\u610f\u5bf9\u81ea\u6211\u8d4b\u503c\u7684\u68c0\u6d4b\uff01\u8fd9\u4e00\u70b9\u5c24\u5176\u91cd\u8981\uff01 \u770b\u5230\u7684\u7b2c\u4e00\u5c42\u4f3c\u4e4e\u53ea\u662f\u5bf9\u6548\u7387\u7684\u63d0\u5347\uff0c\u800c\u66f4\u6df1\u4e00\u5c42\u66f4\u4e3a\u91cd\u8981\uff1a\u5982\u679c\u6ca1\u6709\u5bf9\u81ea\u6211\u8d4b\u503c\u7684\u68c0\u6d4b\uff0c\u90a3\u4e48\u8fdb\u884c\u7b2c\u4e00\u6b65\u91ca\u653e\u5185\u5b58\u65f6\u5373\u5c06\u81ea\u8eab\u7684 data \u7ed9\u91ca\u653e\u6389\u4e86\uff0c\u90a3\u7b2c\u4e8c\u6b65\u518d\u8981\u53d6 data \u4ece\u4f55\u800c\u6765\u5462\uff1f","title":"\u5173\u4e8e\u62f7\u8d1d\u8d4b\u503c"},{"location":"CS241/%20The%20C%20Programming%20Language/","text":"The C and Linux \u00b6","title":" The C Programming Language"},{"location":"CS241/%20The%20C%20Programming%20Language/#the-c-and-linux","text":"","title":"The C and Linux"},{"location":"CS241/Background/","text":"Systems Architecture \u00b6 Assembly \u00b6 Atomic Operations \u00b6 atomic operation An operation is atomic if no other processor should interrupt it. If an instruction is atomic, it makes sure that only one processor or thread performs any intermediate step at a time. Hyperthreading \u00b6 hyperthreading Hyperthreading allows one physical core to appear as many virtual cores to the operating system. How I found a bug in Intel Skylake processors Debugging and Environments \u00b6 ssh \u00b6 ssh ssh is short for secure shell. It is a network protocol that allows you to spawn a shell on the remote machine. You can use ssh-copy-id to skip repeating typing your password every time you use ssh. The config file resides in ~/.ssh/config . git \u00b6 git Git is a version control system that stores the entire history of a directory. clean code \u00b6 midify_before.cpp midify_after.cpp void selection_sort ( int * a , long len ){ for ( long i = len -1 ; i > 0 ; -- i ){ long max_index = i ; for ( long j = len -1 ; j >= 0 ; -- j ){ if ( a [ max_index ] < a [ j ]){ max_index = j ; } } int temp = a [ i ]; a [ i ] = a [ max_index ]; a [ max_index ] = temp ; } } long max_index ( int * a , long start , long end ); void swap ( int * a , long idx1 , long idx2 ); void selection_sort ( int * a , long len ); Make sure that your function does one thing so you need write some helper functions. An example is shown before. Valgrind \u00b6 introduction Valgrind is a suite of tools designed to provide debugging and profiling tools to make your programs more correct and detect some runtime issues. To run valgrind on your program: valgrind --leak-check = full --show-leak-kinds = all myprogram arg1 arg2 TSAN \u00b6 ThreadSanitizer ThreadSanitizer is a tool from Google, built into clang and gcc, to help you detect race conditions in your code. You can compile code by gcc -fsanitize=thread -pie -fPIC -ltsan -g simple_race.c GDB \u00b6 Shell \u00b6 introduction A shell is a programming language that is runnint inside your terminal. A terminal is merely a window to input commands. Undefined Behavior Sanitizer \u00b6 The undefined behavior sanitizer is a wonderful tool provided by the llvm project. Read Chris Lattner\u2019s 3 Part blog post on undefined behavior . Clang Static Build Tools \u00b6 Clang provides a great drop-in replacement tools for compiling programs. If you want to see if there is an error that may cause a race condition, casting error, etc, all you need to do is the following. $ scan-build make strace and ltrace \u00b6 Introduction strace and ltrace are two programs that trace the system calls and library calls respectively of a running program or command. ltrace_test.cpp Use ltrace int main () { FILE * fp = fopen ( \"I don't exist\" , \"r\" ); fprintf ( fp , \"a\" ); fclose ( fp ); return 0 ; } > ltrace ./a.out __libc_start_main ( 0x8048454, 1 , 0xbfc19db4, 0x80484c0, 0x8048530 <unfinished ...> fopen ( \"I don't exist\" , \"r\" ) = 0x0 fwrite ( \"Invalid Write\\n\" , 1 , 14 , 0x0 <unfinished ...> --- SIGSEGV ( Segmentation fault ) --- +++ killed by SIGSEGV +++","title":"Background"},{"location":"CS241/Background/#systems-architecture","text":"","title":"Systems Architecture"},{"location":"CS241/Background/#assembly","text":"","title":"Assembly"},{"location":"CS241/Background/#atomic-operations","text":"atomic operation An operation is atomic if no other processor should interrupt it. If an instruction is atomic, it makes sure that only one processor or thread performs any intermediate step at a time.","title":"Atomic Operations"},{"location":"CS241/Background/#hyperthreading","text":"hyperthreading Hyperthreading allows one physical core to appear as many virtual cores to the operating system. How I found a bug in Intel Skylake processors","title":"Hyperthreading"},{"location":"CS241/Background/#debugging-and-environments","text":"","title":"Debugging and Environments"},{"location":"CS241/Background/#ssh","text":"ssh ssh is short for secure shell. It is a network protocol that allows you to spawn a shell on the remote machine. You can use ssh-copy-id to skip repeating typing your password every time you use ssh. The config file resides in ~/.ssh/config .","title":"ssh"},{"location":"CS241/Background/#git","text":"git Git is a version control system that stores the entire history of a directory.","title":"git"},{"location":"CS241/Background/#clean-code","text":"midify_before.cpp midify_after.cpp void selection_sort ( int * a , long len ){ for ( long i = len -1 ; i > 0 ; -- i ){ long max_index = i ; for ( long j = len -1 ; j >= 0 ; -- j ){ if ( a [ max_index ] < a [ j ]){ max_index = j ; } } int temp = a [ i ]; a [ i ] = a [ max_index ]; a [ max_index ] = temp ; } } long max_index ( int * a , long start , long end ); void swap ( int * a , long idx1 , long idx2 ); void selection_sort ( int * a , long len ); Make sure that your function does one thing so you need write some helper functions. An example is shown before.","title":"clean code"},{"location":"CS241/Background/#valgrind","text":"introduction Valgrind is a suite of tools designed to provide debugging and profiling tools to make your programs more correct and detect some runtime issues. To run valgrind on your program: valgrind --leak-check = full --show-leak-kinds = all myprogram arg1 arg2","title":"Valgrind"},{"location":"CS241/Background/#tsan","text":"ThreadSanitizer ThreadSanitizer is a tool from Google, built into clang and gcc, to help you detect race conditions in your code. You can compile code by gcc -fsanitize=thread -pie -fPIC -ltsan -g simple_race.c","title":"TSAN"},{"location":"CS241/Background/#gdb","text":"","title":"GDB"},{"location":"CS241/Background/#shell","text":"introduction A shell is a programming language that is runnint inside your terminal. A terminal is merely a window to input commands.","title":"Shell"},{"location":"CS241/Background/#undefined-behavior-sanitizer","text":"The undefined behavior sanitizer is a wonderful tool provided by the llvm project. Read Chris Lattner\u2019s 3 Part blog post on undefined behavior .","title":"Undefined Behavior Sanitizer"},{"location":"CS241/Background/#clang-static-build-tools","text":"Clang provides a great drop-in replacement tools for compiling programs. If you want to see if there is an error that may cause a race condition, casting error, etc, all you need to do is the following. $ scan-build make","title":"Clang Static Build Tools"},{"location":"CS241/Background/#strace-and-ltrace","text":"Introduction strace and ltrace are two programs that trace the system calls and library calls respectively of a running program or command. ltrace_test.cpp Use ltrace int main () { FILE * fp = fopen ( \"I don't exist\" , \"r\" ); fprintf ( fp , \"a\" ); fclose ( fp ); return 0 ; } > ltrace ./a.out __libc_start_main ( 0x8048454, 1 , 0xbfc19db4, 0x80484c0, 0x8048530 <unfinished ...> fopen ( \"I don't exist\" , \"r\" ) = 0x0 fwrite ( \"Invalid Write\\n\" , 1 , 14 , 0x0 <unfinished ...> --- SIGSEGV ( Segmentation fault ) --- +++ killed by SIGSEGV +++","title":"strace and ltrace"},{"location":"CS241/Processes/","text":"File Descriptors \u00b6 Processes \u00b6","title":"Processes"},{"location":"CS241/Processes/#file-descriptors","text":"","title":"File Descriptors"},{"location":"CS241/Processes/#processes","text":"","title":"Processes"},{"location":"CS243/","text":"Using Dataflow Analysis to detect Memory Leaks \u00b6 Part A Detecting Memory Leaks \u00b6 A memory leak occurs when memory is allocated but never deallocated after its last use. This can waste memory resource in a long-running program. Detecting memory bugs is difficult because of aliases where multiple variables may point to the same location. We eliminate the complexity of this problem with the following simplified instruction set (p is a pointer variable and v is a scalar non-pointer variable in the program): p = alloc() ; allocate a block of memory and assign its pointer to p. *p = v ; write the scalar (non-pointer) value v to the location p. (Note that the value v is scalar, i.e. not a pointer.) v = *p ; the read version of the above instruction (again, v couldn\u2019t be a pointer). free(p) ; deallocate the block of memory pointed to by p . To simplify the problem, please assume that no pointer arithmetic will happen, and that we can only assign a pointer with the alloc() instruction. Your task is to warn programmers about any potential memory leaks in the program. You may treat each instruction as a basic block. (1) Please describe the possible conditions of memory leaks (hint: there are two possible types). (2) Define a data flow analysis to solve this problem by filling out the table below. (3) Specify how you use the data flow results to issue a warning on each potential memory leak. There are other errors like use-after-free and deleting unallocated memory, but ignore these errors in Part A. Direction of your analysis (forward/backward) Lattice elements and meaning Meet operator or lattice diagram Is there a top element? If yes, what is it? Is there a bottom element? If yes, what is it? Transfer function of a basic block Boundary condition initialization Interior points initialization","title":"Index"},{"location":"CS243/#using-dataflow-analysis-to-detect-memory-leaks","text":"","title":"Using Dataflow Analysis to detect Memory Leaks"},{"location":"CS243/#part-a-detecting-memory-leaks","text":"A memory leak occurs when memory is allocated but never deallocated after its last use. This can waste memory resource in a long-running program. Detecting memory bugs is difficult because of aliases where multiple variables may point to the same location. We eliminate the complexity of this problem with the following simplified instruction set (p is a pointer variable and v is a scalar non-pointer variable in the program): p = alloc() ; allocate a block of memory and assign its pointer to p. *p = v ; write the scalar (non-pointer) value v to the location p. (Note that the value v is scalar, i.e. not a pointer.) v = *p ; the read version of the above instruction (again, v couldn\u2019t be a pointer). free(p) ; deallocate the block of memory pointed to by p . To simplify the problem, please assume that no pointer arithmetic will happen, and that we can only assign a pointer with the alloc() instruction. Your task is to warn programmers about any potential memory leaks in the program. You may treat each instruction as a basic block. (1) Please describe the possible conditions of memory leaks (hint: there are two possible types). (2) Define a data flow analysis to solve this problem by filling out the table below. (3) Specify how you use the data flow results to issue a warning on each potential memory leak. There are other errors like use-after-free and deleting unallocated memory, but ignore these errors in Part A. Direction of your analysis (forward/backward) Lattice elements and meaning Meet operator or lattice diagram Is there a top element? If yes, what is it? Is there a bottom element? If yes, what is it? Transfer function of a basic block Boundary condition initialization Interior points initialization","title":"Part A Detecting Memory Leaks"},{"location":"CSAPP/Linking/Linking/","text":"7.1 \u7f16\u8bd1\u5668\u9a71\u52a8\u7a0b\u5e8f \u00b6 main.c sum.c output by gcc -v -Og -o prog main.c sum.c int sum ( int * a , int b ); int array [ 2 ] = { 1 , 2 }; int main (){ int val = sum ( array , 2 ); return val ; } int sum ( int * a , int n ){ int i , s = 0 ; for ( i = 0 ; i < n ; ++ i ){ s += a [ i ]; } return s ; } Using built - in specs . COLLECT_GCC = gcc COLLECT_LTO_WRAPPER =/ usr / lib / gcc / x86_64 - linux - gnu / 9 / lto - wrapper OFFLOAD_TARGET_NAMES = nvptx - none : hsa OFFLOAD_TARGET_DEFAULT = 1 Target : x86_64 - linux - gnu Configured with : ../ src / configure - v -- with - pkgversion = 'Ubuntu 9.3.0-17ubuntu1~20.04' -- with - bugurl = file : /// usr / share / doc / gcc - 9 / README . Bugs -- enable - languages = c , ada , c ++ , go , brig , d , fortran , objc , obj - c ++ , gm2 -- prefix =/ usr -- with - gcc - major - version - only -- program - suffix =- 9 -- program - prefix = x86_64 - linux - gnu - -- enable - shared -- enable - linker - build - id -- libexecdir =/ usr / lib -- without - included - gettext -- enable - threads = posix -- libdir =/ usr / lib -- enable - nls -- enable - clocale = gnu -- enable - libstdcxx - debug -- enable - libstdcxx - time = yes -- with - default - libstdcxx - abi = new -- enable - gnu - unique - object -- disable - vtable - verify -- enable - plugin -- enable - default - pie -- with - system - zlib -- with - target - system - zlib = auto -- enable - objc - gc = auto -- enable - multiarch -- disable - werror -- with - arch - 32 = i686 -- with - abi = m64 -- with - multilib - list = m32 , m64 , mx32 -- enable - multilib -- with - tune = generic -- enable - offload - targets = nvptx - none =/ build / gcc - 9 - HskZEa / gcc - 9 - 9.3.0 / debian / tmp - nvptx / usr , hsa -- without - cuda - driver -- enable - checking = release -- build = x86_64 - linux - gnu -- host = x86_64 - linux - gnu -- target = x86_64 - linux - gnu Thread model : posix gcc version 9.3.0 ( Ubuntu 9.3.0 - 17 ubuntu1 ~ 20.04 ) COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' / usr / lib / gcc / x86_64 - linux - gnu / 9 / cc1 - quiet - v - imultiarch x86_64 - linux - gnu main . c - quiet - dumpbase main . c - mtune = generic - march = x86 - 64 - auxbase main - Og - version - fasynchronous - unwind - tables - fstack - protector - strong - Wformat - Wformat - security - fstack - clash - protection - fcf - protection - o / tmp / ccEjflk2 . s GNU C17 ( Ubuntu 9.3.0 - 17 ubuntu1 ~ 20.04 ) version 9.3.0 ( x86_64 - linux - gnu ) compiled by GNU C version 9.3.0 , GMP version 6.2.0 , MPFR version 4.0.2 , MPC version 1.1.0 , isl version isl - 0.22.1 - GMP GGC heuristics : -- param ggc - min - expand = 100 -- param ggc - min - heapsize = 131072 ignoring nonexistent directory \"/usr/local/include/x86_64-linux-gnu\" ignoring nonexistent directory \"/usr/lib/gcc/x86_64-linux-gnu/9/include-fixed\" ignoring nonexistent directory \"/usr/lib/gcc/x86_64-linux-gnu/9/../../../../x86_64-linux-gnu/include\" #include \"...\" search starts here: #include <...> search starts here: / usr / lib / gcc / x86_64 - linux - gnu / 9 / include / usr / local / include / usr / include / x86_64 - linux - gnu / usr / include End of search list . GNU C17 ( Ubuntu 9.3.0 - 17 ubuntu1 ~ 20.04 ) version 9.3.0 ( x86_64 - linux - gnu ) compiled by GNU C version 9.3.0 , GMP version 6.2.0 , MPFR version 4.0.2 , MPC version 1.1.0 , isl version isl - 0.22.1 - GMP GGC heuristics : -- param ggc - min - expand = 100 -- param ggc - min - heapsize = 131072 Compiler executable checksum : bbf13931d8de1abe14040c9909cb6969 COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' as - v -- 64 - o / tmp / ccduraS2 . o / tmp / ccEjflk2 . s GNU assembler version 2.34 ( x86_64 - linux - gnu ) using BFD version ( GNU Binutils for Ubuntu ) 2.34 COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' / usr / lib / gcc / x86_64 - linux - gnu / 9 / cc1 - quiet - v - imultiarch x86_64 - linux - gnu sum . c - quiet - dumpbase sum . c - mtune = generic - march = x86 - 64 - auxbase sum - Og - version - fasynchronous - unwind - tables - fstack - protector - strong - Wformat - Wformat - security - fstack - clash - protection - fcf - protection - o / tmp / ccEjflk2 . s GNU C17 ( Ubuntu 9.3.0 - 17 ubuntu1 ~ 20.04 ) version 9.3.0 ( x86_64 - linux - gnu ) compiled by GNU C version 9.3.0 , GMP version 6.2.0 , MPFR version 4.0.2 , MPC version 1.1.0 , isl version isl - 0.22.1 - GMP GGC heuristics : -- param ggc - min - expand = 100 -- param ggc - min - heapsize = 131072 ignoring nonexistent directory \"/usr/local/include/x86_64-linux-gnu\" ignoring nonexistent directory \"/usr/lib/gcc/x86_64-linux-gnu/9/include-fixed\" ignoring nonexistent directory \"/usr/lib/gcc/x86_64-linux-gnu/9/../../../../x86_64-linux-gnu/include\" #include \"...\" search starts here: #include <...> search starts here: / usr / lib / gcc / x86_64 - linux - gnu / 9 / include / usr / local / include / usr / include / x86_64 - linux - gnu / usr / include End of search list . GNU C17 ( Ubuntu 9.3.0 - 17 ubuntu1 ~ 20.04 ) version 9.3.0 ( x86_64 - linux - gnu ) compiled by GNU C version 9.3.0 , GMP version 6.2.0 , MPFR version 4.0.2 , MPC version 1.1.0 , isl version isl - 0.22.1 - GMP GGC heuristics : -- param ggc - min - expand = 100 -- param ggc - min - heapsize = 131072 Compiler executable checksum : bbf13931d8de1abe14040c9909cb6969 COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' as - v -- 64 - o / tmp / ccbCi5h2 . o / tmp / ccEjflk2 . s GNU assembler version 2.34 ( x86_64 - linux - gnu ) using BFD version ( GNU Binutils for Ubuntu ) 2.34 COMPILER_PATH =/ usr / lib / gcc / x86_64 - linux - gnu / 9 / : / usr / lib / gcc / x86_64 - linux - gnu / 9 / : / usr / lib / gcc / x86_64 - linux - gnu / : / usr / lib / gcc / x86_64 - linux - gnu / 9 / : / usr / lib / gcc / x86_64 - linux - gnu / LIBRARY_PATH =/ usr / lib / gcc / x86_64 - linux - gnu / 9 / : / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ x86_64 - linux - gnu / : / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../../ lib / : / lib / x86_64 - linux - gnu / : / lib /../ lib / : / usr / lib / x86_64 - linux - gnu / : / usr / lib /../ lib / : / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ : / lib / : / usr / lib / COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' / usr / lib / gcc / x86_64 - linux - gnu / 9 / collect2 - plugin / usr / lib / gcc / x86_64 - linux - gnu / 9 / liblto_plugin . so - plugin - opt =/ usr / lib / gcc / x86_64 - linux - gnu / 9 / lto - wrapper - plugin - opt =- fresolution =/ tmp / ccwBAed0 . res - plugin - opt =- pass - through =- lgcc - plugin - opt =- pass - through =- lgcc_s - plugin - opt =- pass - through =- lc - plugin - opt =- pass - through =- lgcc - plugin - opt =- pass - through =- lgcc_s -- build - id -- eh - frame - hdr - m elf_x86_64 -- hash - style = gnu -- as - needed - dynamic - linker / lib64 / ld - linux - x86 - 64. so .2 - pie - z now - z relro - o prog / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ x86_64 - linux - gnu / Scrt1 . o / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ x86_64 - linux - gnu / crti . o / usr / lib / gcc / x86_64 - linux - gnu / 9 / crtbeginS . o - L / usr / lib / gcc / x86_64 - linux - gnu / 9 - L / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ x86_64 - linux - gnu - L / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../../ lib - L / lib / x86_64 - linux - gnu - L / lib /../ lib - L / usr / lib / x86_64 - linux - gnu - L / usr / lib /../ lib - L / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../.. / tmp / ccduraS2 . o / tmp / ccbCi5h2 . o - lgcc -- push - state -- as - needed - lgcc_s -- pop - state - lc - lgcc -- push - state -- as - needed - lgcc_s -- pop - state / usr / lib / gcc / x86_64 - linux - gnu / 9 / crtendS . o / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ x86_64 - linux - gnu / crtn . o COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' \u200b \u4ece\u4e0a\u9762\u7684\u65e5\u5fd7\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u4e00\u5171\u7ecf\u5386\u4e86\u4e0b\u9762\u51e0\u4e2a\u9636\u6bb5: \u9a71\u52a8\u7a0b\u5e8f\u8fd0\u884cC\u7f16\u8bd1\u5668( cc1 )\u5c06 main.c \u7f16\u8bd1\u6210 main.s \uff0c\u9a71\u52a8\u7a0b\u5e8f\u8fd0\u884c\u6c47\u7f16\u5668( as )\u5c06 main.s \u7ffb\u8bd1\u6210\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6 \u9a71\u52a8\u7a0b\u5e8f\u8fd0\u884cC\u7f16\u8bd1\u5668( cc1 )\u5c06 sum.c \u7f16\u8bd1\u6210 sum.s \uff0c\u9a71\u52a8\u7a0b\u5e8f\u8fd0\u884c\u6c47\u7f16\u5668( as )\u5c06 sum.s \u7ffb\u8bd1\u6210\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6 \u9a71\u52a8\u7a0b\u5e8f\u8fd0\u884c\u94fe\u63a5\u5668( collect2 )\u5c06\u53ef\u91cd\u5b9a\u4f4d\u6587\u4ef6\u7ec4\u5408\u8d77\u6765\u521b\u5efa\u53ef\u6267\u884c\u6587\u4ef6 prog","title":"Linking"},{"location":"CSAPP/Linking/Linking/#71-\u7f16\u8bd1\u5668\u9a71\u52a8\u7a0b\u5e8f","text":"main.c sum.c output by gcc -v -Og -o prog main.c sum.c int sum ( int * a , int b ); int array [ 2 ] = { 1 , 2 }; int main (){ int val = sum ( array , 2 ); return val ; } int sum ( int * a , int n ){ int i , s = 0 ; for ( i = 0 ; i < n ; ++ i ){ s += a [ i ]; } return s ; } Using built - in specs . COLLECT_GCC = gcc COLLECT_LTO_WRAPPER =/ usr / lib / gcc / x86_64 - linux - gnu / 9 / lto - wrapper OFFLOAD_TARGET_NAMES = nvptx - none : hsa OFFLOAD_TARGET_DEFAULT = 1 Target : x86_64 - linux - gnu Configured with : ../ src / configure - v -- with - pkgversion = 'Ubuntu 9.3.0-17ubuntu1~20.04' -- with - bugurl = file : /// usr / share / doc / gcc - 9 / README . Bugs -- enable - languages = c , ada , c ++ , go , brig , d , fortran , objc , obj - c ++ , gm2 -- prefix =/ usr -- with - gcc - major - version - only -- program - suffix =- 9 -- program - prefix = x86_64 - linux - gnu - -- enable - shared -- enable - linker - build - id -- libexecdir =/ usr / lib -- without - included - gettext -- enable - threads = posix -- libdir =/ usr / lib -- enable - nls -- enable - clocale = gnu -- enable - libstdcxx - debug -- enable - libstdcxx - time = yes -- with - default - libstdcxx - abi = new -- enable - gnu - unique - object -- disable - vtable - verify -- enable - plugin -- enable - default - pie -- with - system - zlib -- with - target - system - zlib = auto -- enable - objc - gc = auto -- enable - multiarch -- disable - werror -- with - arch - 32 = i686 -- with - abi = m64 -- with - multilib - list = m32 , m64 , mx32 -- enable - multilib -- with - tune = generic -- enable - offload - targets = nvptx - none =/ build / gcc - 9 - HskZEa / gcc - 9 - 9.3.0 / debian / tmp - nvptx / usr , hsa -- without - cuda - driver -- enable - checking = release -- build = x86_64 - linux - gnu -- host = x86_64 - linux - gnu -- target = x86_64 - linux - gnu Thread model : posix gcc version 9.3.0 ( Ubuntu 9.3.0 - 17 ubuntu1 ~ 20.04 ) COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' / usr / lib / gcc / x86_64 - linux - gnu / 9 / cc1 - quiet - v - imultiarch x86_64 - linux - gnu main . c - quiet - dumpbase main . c - mtune = generic - march = x86 - 64 - auxbase main - Og - version - fasynchronous - unwind - tables - fstack - protector - strong - Wformat - Wformat - security - fstack - clash - protection - fcf - protection - o / tmp / ccEjflk2 . s GNU C17 ( Ubuntu 9.3.0 - 17 ubuntu1 ~ 20.04 ) version 9.3.0 ( x86_64 - linux - gnu ) compiled by GNU C version 9.3.0 , GMP version 6.2.0 , MPFR version 4.0.2 , MPC version 1.1.0 , isl version isl - 0.22.1 - GMP GGC heuristics : -- param ggc - min - expand = 100 -- param ggc - min - heapsize = 131072 ignoring nonexistent directory \"/usr/local/include/x86_64-linux-gnu\" ignoring nonexistent directory \"/usr/lib/gcc/x86_64-linux-gnu/9/include-fixed\" ignoring nonexistent directory \"/usr/lib/gcc/x86_64-linux-gnu/9/../../../../x86_64-linux-gnu/include\" #include \"...\" search starts here: #include <...> search starts here: / usr / lib / gcc / x86_64 - linux - gnu / 9 / include / usr / local / include / usr / include / x86_64 - linux - gnu / usr / include End of search list . GNU C17 ( Ubuntu 9.3.0 - 17 ubuntu1 ~ 20.04 ) version 9.3.0 ( x86_64 - linux - gnu ) compiled by GNU C version 9.3.0 , GMP version 6.2.0 , MPFR version 4.0.2 , MPC version 1.1.0 , isl version isl - 0.22.1 - GMP GGC heuristics : -- param ggc - min - expand = 100 -- param ggc - min - heapsize = 131072 Compiler executable checksum : bbf13931d8de1abe14040c9909cb6969 COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' as - v -- 64 - o / tmp / ccduraS2 . o / tmp / ccEjflk2 . s GNU assembler version 2.34 ( x86_64 - linux - gnu ) using BFD version ( GNU Binutils for Ubuntu ) 2.34 COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' / usr / lib / gcc / x86_64 - linux - gnu / 9 / cc1 - quiet - v - imultiarch x86_64 - linux - gnu sum . c - quiet - dumpbase sum . c - mtune = generic - march = x86 - 64 - auxbase sum - Og - version - fasynchronous - unwind - tables - fstack - protector - strong - Wformat - Wformat - security - fstack - clash - protection - fcf - protection - o / tmp / ccEjflk2 . s GNU C17 ( Ubuntu 9.3.0 - 17 ubuntu1 ~ 20.04 ) version 9.3.0 ( x86_64 - linux - gnu ) compiled by GNU C version 9.3.0 , GMP version 6.2.0 , MPFR version 4.0.2 , MPC version 1.1.0 , isl version isl - 0.22.1 - GMP GGC heuristics : -- param ggc - min - expand = 100 -- param ggc - min - heapsize = 131072 ignoring nonexistent directory \"/usr/local/include/x86_64-linux-gnu\" ignoring nonexistent directory \"/usr/lib/gcc/x86_64-linux-gnu/9/include-fixed\" ignoring nonexistent directory \"/usr/lib/gcc/x86_64-linux-gnu/9/../../../../x86_64-linux-gnu/include\" #include \"...\" search starts here: #include <...> search starts here: / usr / lib / gcc / x86_64 - linux - gnu / 9 / include / usr / local / include / usr / include / x86_64 - linux - gnu / usr / include End of search list . GNU C17 ( Ubuntu 9.3.0 - 17 ubuntu1 ~ 20.04 ) version 9.3.0 ( x86_64 - linux - gnu ) compiled by GNU C version 9.3.0 , GMP version 6.2.0 , MPFR version 4.0.2 , MPC version 1.1.0 , isl version isl - 0.22.1 - GMP GGC heuristics : -- param ggc - min - expand = 100 -- param ggc - min - heapsize = 131072 Compiler executable checksum : bbf13931d8de1abe14040c9909cb6969 COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' as - v -- 64 - o / tmp / ccbCi5h2 . o / tmp / ccEjflk2 . s GNU assembler version 2.34 ( x86_64 - linux - gnu ) using BFD version ( GNU Binutils for Ubuntu ) 2.34 COMPILER_PATH =/ usr / lib / gcc / x86_64 - linux - gnu / 9 / : / usr / lib / gcc / x86_64 - linux - gnu / 9 / : / usr / lib / gcc / x86_64 - linux - gnu / : / usr / lib / gcc / x86_64 - linux - gnu / 9 / : / usr / lib / gcc / x86_64 - linux - gnu / LIBRARY_PATH =/ usr / lib / gcc / x86_64 - linux - gnu / 9 / : / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ x86_64 - linux - gnu / : / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../../ lib / : / lib / x86_64 - linux - gnu / : / lib /../ lib / : / usr / lib / x86_64 - linux - gnu / : / usr / lib /../ lib / : / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ : / lib / : / usr / lib / COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' / usr / lib / gcc / x86_64 - linux - gnu / 9 / collect2 - plugin / usr / lib / gcc / x86_64 - linux - gnu / 9 / liblto_plugin . so - plugin - opt =/ usr / lib / gcc / x86_64 - linux - gnu / 9 / lto - wrapper - plugin - opt =- fresolution =/ tmp / ccwBAed0 . res - plugin - opt =- pass - through =- lgcc - plugin - opt =- pass - through =- lgcc_s - plugin - opt =- pass - through =- lc - plugin - opt =- pass - through =- lgcc - plugin - opt =- pass - through =- lgcc_s -- build - id -- eh - frame - hdr - m elf_x86_64 -- hash - style = gnu -- as - needed - dynamic - linker / lib64 / ld - linux - x86 - 64. so .2 - pie - z now - z relro - o prog / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ x86_64 - linux - gnu / Scrt1 . o / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ x86_64 - linux - gnu / crti . o / usr / lib / gcc / x86_64 - linux - gnu / 9 / crtbeginS . o - L / usr / lib / gcc / x86_64 - linux - gnu / 9 - L / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ x86_64 - linux - gnu - L / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../../ lib - L / lib / x86_64 - linux - gnu - L / lib /../ lib - L / usr / lib / x86_64 - linux - gnu - L / usr / lib /../ lib - L / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../.. / tmp / ccduraS2 . o / tmp / ccbCi5h2 . o - lgcc -- push - state -- as - needed - lgcc_s -- pop - state - lc - lgcc -- push - state -- as - needed - lgcc_s -- pop - state / usr / lib / gcc / x86_64 - linux - gnu / 9 / crtendS . o / usr / lib / gcc / x86_64 - linux - gnu / 9 /../../../ x86_64 - linux - gnu / crtn . o COLLECT_GCC_OPTIONS = '-v' '-Og' '-o' 'prog' '-mtune=generic' '-march=x86-64' \u200b \u4ece\u4e0a\u9762\u7684\u65e5\u5fd7\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u4e00\u5171\u7ecf\u5386\u4e86\u4e0b\u9762\u51e0\u4e2a\u9636\u6bb5: \u9a71\u52a8\u7a0b\u5e8f\u8fd0\u884cC\u7f16\u8bd1\u5668( cc1 )\u5c06 main.c \u7f16\u8bd1\u6210 main.s \uff0c\u9a71\u52a8\u7a0b\u5e8f\u8fd0\u884c\u6c47\u7f16\u5668( as )\u5c06 main.s \u7ffb\u8bd1\u6210\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6 \u9a71\u52a8\u7a0b\u5e8f\u8fd0\u884cC\u7f16\u8bd1\u5668( cc1 )\u5c06 sum.c \u7f16\u8bd1\u6210 sum.s \uff0c\u9a71\u52a8\u7a0b\u5e8f\u8fd0\u884c\u6c47\u7f16\u5668( as )\u5c06 sum.s \u7ffb\u8bd1\u6210\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6 \u9a71\u52a8\u7a0b\u5e8f\u8fd0\u884c\u94fe\u63a5\u5668( collect2 )\u5c06\u53ef\u91cd\u5b9a\u4f4d\u6587\u4ef6\u7ec4\u5408\u8d77\u6765\u521b\u5efa\u53ef\u6267\u884c\u6587\u4ef6 prog","title":"7.1 \u7f16\u8bd1\u5668\u9a71\u52a8\u7a0b\u5e8f"},{"location":"CSAPP/Linking/Relocation/","text":"\u91cd\u5b9a\u4f4d \u00b6 \u91cd\u5b9a\u4f4d\u6761\u76ee \u00b6 \u91cd\u5b9a\u4f4d\u9700\u8981\u5408\u5e76\u8f93\u5165\u6a21\u5757\uff0c\u4e3a\u6bcf\u4e00\u4e2a\u7b26\u53f7\u5206\u914d\u8fd0\u884c\u65f6\u5730\u5740\uff0c\u91cd\u5b9a\u4f4d\u5206\u4e24\u6b65\u7ec4\u6210\uff1a \u91cd\u56f4\u5b9a\u4f4d\u8282\u548c\u7b26\u53f7\u5b9a\u4e49\u3002 \u91cd\u5b9a\u4f4d\u8282\u4e2d\u7684\u7b26\u53f7\u5f15\u7528\u3002","title":"Relocation"},{"location":"CSAPP/Linking/Relocation/#\u91cd\u5b9a\u4f4d","text":"","title":"\u91cd\u5b9a\u4f4d"},{"location":"CSAPP/Linking/Relocation/#\u91cd\u5b9a\u4f4d\u6761\u76ee","text":"\u91cd\u5b9a\u4f4d\u9700\u8981\u5408\u5e76\u8f93\u5165\u6a21\u5757\uff0c\u4e3a\u6bcf\u4e00\u4e2a\u7b26\u53f7\u5206\u914d\u8fd0\u884c\u65f6\u5730\u5740\uff0c\u91cd\u5b9a\u4f4d\u5206\u4e24\u6b65\u7ec4\u6210\uff1a \u91cd\u56f4\u5b9a\u4f4d\u8282\u548c\u7b26\u53f7\u5b9a\u4e49\u3002 \u91cd\u5b9a\u4f4d\u8282\u4e2d\u7684\u7b26\u53f7\u5f15\u7528\u3002","title":"\u91cd\u5b9a\u4f4d\u6761\u76ee"},{"location":"CSAPP/Linking/Static%20Linking/","text":"7.2 \u9759\u6001\u94fe\u63a5 \u00b6 \u94fe\u63a5\u5668\u7684\u4efb\u52a1 \u7b26\u53f7\u89e3\u6790 \u91cd\u5b9a\u4f4d","title":"Static Linking"},{"location":"CSAPP/Linking/Static%20Linking/#72-\u9759\u6001\u94fe\u63a5","text":"\u94fe\u63a5\u5668\u7684\u4efb\u52a1 \u7b26\u53f7\u89e3\u6790 \u91cd\u5b9a\u4f4d","title":"7.2 \u9759\u6001\u94fe\u63a5"},{"location":"CSAPP/Linking/SymbolResolve/","text":"\u7b26\u53f7\u89e3\u6790 \u00b6 \u94fe\u63a5\u5668\u5982\u4f55\u89e3\u6790\u591a\u91cd\u5b9a\u4e49\u7684\u5168\u5c40\u7b26\u53f7 \u00b6 \u51fd\u6570\u548c\u5df2\u521d\u59cb\u5316\u7684\u5168\u5c40\u53d8\u91cf\u662f\u5f3a\u7b26\u53f7\uff0c\u672a\u521d\u59cb\u5316\u7684\u5168\u5c40\u53d8\u91cf\u662f\u5f31\u7b26\u53f7\u3002 Linux\u94fe\u63a5\u5668\u5904\u7406\u591a\u91cd\u5b9a\u4e49\u7b26\u53f7\u540d\u7684\u89c4\u5219 \u4e0d\u5141\u8bb8\u6709\u591a\u4e2a\u540c\u540d\u7684\u5f3a\u7b26\u53f7 \u5982\u679c\u6709\u4e00\u4e2a\u5f3a\u7b26\u53f7\u548c\u591a\u4e2a\u5f31\u7b26\u53f7\u540c\u540d\uff0c\u90a3\u4e48\u9009\u62e9\u5f3a\u7b26\u53f7\u3002 \u5982\u679c\u6709\u591a\u4e2a\u5f31\u7b26\u53f7\u540c\u540d\uff0c\u90a3\u4e48\u4ece\u8fd9\u4e9b\u5f31\u7b26\u53f7\u4e2d\u4efb\u610f\u9009\u62e9\u4e00\u4e2a\u3002 foo.c bar.c run by gcc -0g foo.c bar.c & ./a.out #include <stdio.h> void f ( void ); int y = 12345 ; int x = 12345 ; int main (){ f (); printf ( \"x = 0x%x y = 0x%x \\n \" , x , y ); return 0 ; } double x ; void f (){ x = -0.0 ; } \u4e0e\u9759\u6001\u5e93\u94fe\u63a5 \u00b6 \u9759\u6001\u5e93 \u5c06\u6240\u6709\u76f8\u5173\u7684\u76ee\u6807\u6a21\u5757\u5927\u5b9d\u6210\u4e3a\u4e00\u4e2a\u5355\u72ec\u7684\u6587\u4ef6\uff0c\u79f0\u4e3a\u9759\u6001\u5e93\uff0c\u5b83\u53ef\u4ee5\u7528\u4f5c\u94fe\u63a5\u5668\u7684\u8f93\u5165\u3002 \u4e3a\u4ec0\u4e48\u9700\u8981\u9759\u6001\u5e93\uff1f \u5982\u679c\u8ba9\u7f16\u8bd1\u5668\u8fa8\u522b\u51fa\u5bf9\u6807\u51c6\u51fd\u6570\u7684\u8c03\u7528\u76f4\u63a5\u751f\u6210\u76f8\u5e94\u7684\u4ee3\u7801\u7684\u8bdd\uff0c\u4f1a\u6781\u5927\u7684\u589e\u52a0\u7f16\u8bd1\u5668\u7684\u590d\u6742\u5ea6\uff0c\u800c\u4e14\u6bcf\u6b21\u589e\u52a0\u3001\u5220\u9664\u6216\u8005\u4fee\u6539\u5e93\u51fd\u6570\u5c31\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u7f16\u8bd1\u5668\u7248\u672c\u3002 \u5982\u679c\u5c06\u6240\u6709\u7684\u6807\u51c6C\u51fd\u6570\u90fd\u653e\u5728\u4e00\u4e2a\u5355\u72ec\u7684\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6a21\u677f\u4e2d\uff0c\u4f1a\u5bf9\u78c1\u76d8\u9020\u6210\u6781\u5927\u7684\u6d6a\u8d39\u3002 \u5982\u679c\u4e3a\u6bcf\u4e2a\u6807\u51c6\u51fd\u6570\u521b\u5efa\u4e00\u4e2a\u72ec\u7acb\u7684\u53ef\u91cd\u5b9a\u4f4d\u6587\u4ef6\uff0c\u90a3\u4e48\u7a0b\u5e8f\u5458\u9700\u8981\u663e\u5f0f\u94fe\u63a5\u5408\u9002\u7684\u76ee\u6807\u6a21\u5757\u5230\u53ef\u6267\u884c\u6587\u4ef6\u4e2d\uff0c\u8fd9\u662f\u4e00\u4e2a\u5bb9\u6613\u51fa\u9519\u5e76\u4e14\u8017\u65f6\u7684\u8fc7\u7a0b\u3002 \u5982\u4f55\u521b\u5efa\u4e00\u4e2a\u9759\u6001\u5e93\uff1f addvec.c int addcnt = 0 ; void addvec ( int * x , int * y , int * z , int n ) { int i ; addcnt ++ ; for ( i = 0 ; i < n ; i ++ ) z [ i ] = x [ i ] + y [ i ]; } multvec.c int multcnt = 0 ; void multvec ( int * x , int * y , int * z , int n ) { int i ; multcnt ++ ; for ( i = 0 ; i < n ; i ++ ) z [ i ] = x [ i ] * y [ i ]; } command gcc -c addvec.c multvec.c ar rcs libvector.a addvec.o multvec.o \u5982\u4f55\u4f7f\u7528\u4e0a\u9762\u521b\u5efa\u7684\u5e93\u5462\uff1f main.c #include <stdio.h> #include \"vector.h\" int x [ 2 ] = { 1 , 2 }; int y [ 2 ] = { 3 , 4 }; int z [ 2 ]; int main () { addvec ( x , y , z , 2 ); printf ( \"z = [%d %d] \\n \" , z [ 0 ], z [ 1 ]); return 0 ; } command1 gcc -c main.c gcc -static -o main main.o ./libvector.a command2 gcc -c main.c gcc -static -o main main.o -L. -lvector // -lvector \u53c2\u6570\u662f libvector.a \u7684\u7f29\u5199, -L. \u53c2\u6570\u544a\u8bc9\u94fe\u63a5\u5668\u5728\u5f53\u524d\u76ee\u5f55\u4e0b\u67e5\u627e libvector.a\u3002 \u94fe\u63a5\u5668\u5982\u4f55\u4f7f\u7528\u9759\u6001\u5e93\u6765\u89e3\u6790\u5f15\u7528 \u00b6 \u5728\u7b26\u53f7\u89e3\u6790\u9636\u6bb5\uff0c\u94fe\u63a5\u5668\u4ece\u5de6\u5230\u53f3\u6309\u7167\u5b83\u4eec\u5728\u7f16\u8bd1\u5668\u9a71\u52a8\u7a0b\u5e8f\u547d\u4ee4\u884c\u4e0a\u51fa\u73b0\u7684\u987a\u5e8f\u6765\u626b\u63cf\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\u548c\u5b58\u6863\u6587\u4ef6\u3002\u5728\u8fd9\u6b21\u626b\u63cf\u4e2d\uff0c\u94fe\u63a5\u5668\u7ef4\u62a4\u4e00\u4e2a\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\u7684\u96c6\u5408E\uff0c\u4e00\u4e2a\u672a\u89e3\u6790\u7684\u7b26\u53f7\u96c6\u5408U\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5728\u524d\u9762\u8f93\u5165\u6587\u4ef6\u4e2d\u5df2\u5b9a\u4e49\u7684\u7b26\u53f7\u96c6\u5408D\u3002 \u5bf9\u4e8e\u547d\u4ee4\u884c\u4e0a\u7684\u6bcf\u4e2a\u8f93\u5165\u6587\u4ef6 f, \u94fe\u63a5\u5668\u4f1a\u5224\u65ad f \u662f\u4e00\u4e2a\u76ee\u6807\u6587\u4ef6\u8fd8\u662f\u4e00\u4e2a\u5b58\u6863\u6587\u4ef6\u3002\u5982\u679c f \u662f\u4e00\u4e2a\u76ee\u6807\u6587\u4ef6,\u90a3\u4e48\u94fe\u63a5\u5668\u628a f \u6dfb\u52a0\u5230 E, \u4fee\u6539 U \u548c D \u6765\u53cd\u6620 f \u4e2d\u7684\u7b26\u53f7\u5b9a\u4e49\u548c\u5f15\u7528,\u5e76\u7ee7\u7eed\u4e0b\u4e00\u4e2a\u8f93\u5165\u6587\u4ef6\u3002 \u5982\u679c f \u662f\u4e00\u4e2a\u5b58\u6863\u6587\u4ef6,\u90a3\u4e48\u94fe\u63a5\u5668\u5c31\u5c1d\u8bd5\u5339\u914d U \u4e2d\u672a\u89e3\u6790\u7684\u7b26\u53f7\u548c\u7531\u5b58\u6863\u6587\u4ef6\u6210\u5458\u5b9a\u4e49\u7684\u7b26\u53f7\u3002\u5982\u679c\u67d0\u4e2a\u5b58\u6863\u6587\u4ef6\u6210\u5458 m, \u5b9a\u4e49\u4e86\u4e00\u4e2a\u7b26\u53f7\u6765\u89e3\u6790 U \u4e2d\u7684\u4e00\u4e2a\u5f15\u7528,\u90a3\u4e48\u5c31\u5c06 m \u52a0\u5230 E \u4e2d,\u5e76\u4e14\u94fe\u63a5\u5668\u4fee\u6539 U \u548c D \u6765\u53cd\u6620 m \u4e2d\u7684\u7b26\u53f7\u5b9a\u4e49\u548c\u5f15\u7528\u3002\u5bf9\u5b58\u6863\u6587\u4ef6\u4e2d\u6240\u6709\u7684\u6210\u5458\u76ee\u6807\u6587\u4ef6\u90fd\u4f9d\u6b21\u8fdb\u884c\u8fd9\u4e2a\u8fc7\u7a0b,\u76f4\u5230 U \u548c D \u90fd\u4e0d\u518d\u53d1\u751f\u53d8\u5316\u3002\u6b64\u65f6,\u4efb\u4f55\u4e0d\u5305\u542b\u5728 E \u4e2d\u7684\u6210\u5458\u76ee\u6807\u6587\u4ef6\u90fd\u7b80\u5355\u5730\u88ab\u4e22\u5f03,\u800c\u94fe\u63a5\u5668\u5c06\u7ee7\u7eed\u5904\u7406\u4e0b\u4e00\u4e2a\u8f93\u5165\u6587\u4ef6\u3002 \u5982\u679c\u5f53\u94fe\u63a5\u5668\u5b8c\u6210\u5bf9\u547d\u4ee4\u884c\u4e0a\u8f93\u5165\u6587\u4ef6\u7684\u626b\u63cf\u540e, U \u662f\u975e\u7a7a\u7684,\u90a3\u4e48\u94fe\u63a5\u5668\u5c31\u4f1a\u8f93\u51fa\u4e00\u4e2a\u9519\u8bef\u5e76\u7ec8\u6b62\u3002\u5426\u5219,\u5b83\u4f1a\u5408\u5e76\u548c\u91cd\u5b9a\u4f4d E \u4e2d\u7684\u76ee\u6807\u6587\u4ef6,\u6784\u5efa\u8f93\u51fa\u7684\u53ef\u6267\u884c\u6587\u4ef6\u3002 \u89e3\u91ca\u4e0b\u9762\u51fa\u9519\u7684\u539f\u56e0 command gcc -static ./libvector.a main.c \u5728\u5904\u7406 libvector.a \u65f6, U \u662f\u7a7a\u7684,\u6240\u4ee5\u6ca1\u6709 libvector.a \u4e2d\u7684\u6210\u5458\u76ee\u6807\u6587\u4ef6\u4f1a\u6dfb\u52a0\u5230 E \u4e2d\u3002\u56e0\u6b64,\u5bf9 addvec \u7684\u5f15\u7528\u662f\u7edd\u4e0d\u4f1a\u88ab\u89e3\u6790\u7684,\u6240\u4ee5\u94fe\u63a5\u5668\u4f1a\u4ea7\u751f\u4e00\u6761\u9519\u8bef\u4fe1\u606f\u5e76\u7ec8\u6b62\u3002 \u4e00\u4e9b\u4f8b\u5b50 \u4e00\u822c\u6765\u8bf4\u6211\u4eec\u5c06\u5e93\u653e\u5230\u547d\u4ee4\u884c\u7684\u7ed3\u5c3e\uff0ca \u548c b \u8868\u793a\u5f53\u524d\u76ee\u5f55\u4e2d\u7684\u76ee\u6807\u6a21\u5757\u6216\u8005\u9759\u6001\u5e93,\u800c a -> b \u8868\u793a a \u4f9d\u8d56\u4e8e b, \u4e5f\u5c31\u662f\u8bf4 b \u5b9a\u4e49\u4e86\u4e00\u4e2a\u88ab a \u5f15\u7528\u7684\u7b26\u53f7\u3002\u5bf9\u4e8e\u4e0b\u9762\u6bcf\u79cd\u573a\u666f,\u8bf7\u7ed9\u51fa\u6700\u5c0f\u7684\u547d\u4ee4\u884c(\u5373\u4e00\u4e2a\u542b\u6709\u6700\u5c11\u6570\u91cf\u7684\u76ee\u6807\u6587\u4ef6\u548c\u5e93\u53c2\u6570\u7684\u547d\u4ee4),\u4f7f\u5f97\u9759\u6001\u94fe\u63a5\u5668\u80fd\u89e3\u6790\u6240\u6709\u7684\u7b26\u53f7\u5f15\u7528\u3002 p.o -> libx.a gcc p.o libx.a p.o -> libx.a -> liby.a gcc p.o libx.a liby.a p.o->libx.a->liby.a && liby.a -> libx.a->p.o gcc p.o libx.a liby.a liby.a","title":"SymbolResolve"},{"location":"CSAPP/Linking/SymbolResolve/#\u7b26\u53f7\u89e3\u6790","text":"","title":"\u7b26\u53f7\u89e3\u6790"},{"location":"CSAPP/Linking/SymbolResolve/#\u94fe\u63a5\u5668\u5982\u4f55\u89e3\u6790\u591a\u91cd\u5b9a\u4e49\u7684\u5168\u5c40\u7b26\u53f7","text":"\u51fd\u6570\u548c\u5df2\u521d\u59cb\u5316\u7684\u5168\u5c40\u53d8\u91cf\u662f\u5f3a\u7b26\u53f7\uff0c\u672a\u521d\u59cb\u5316\u7684\u5168\u5c40\u53d8\u91cf\u662f\u5f31\u7b26\u53f7\u3002 Linux\u94fe\u63a5\u5668\u5904\u7406\u591a\u91cd\u5b9a\u4e49\u7b26\u53f7\u540d\u7684\u89c4\u5219 \u4e0d\u5141\u8bb8\u6709\u591a\u4e2a\u540c\u540d\u7684\u5f3a\u7b26\u53f7 \u5982\u679c\u6709\u4e00\u4e2a\u5f3a\u7b26\u53f7\u548c\u591a\u4e2a\u5f31\u7b26\u53f7\u540c\u540d\uff0c\u90a3\u4e48\u9009\u62e9\u5f3a\u7b26\u53f7\u3002 \u5982\u679c\u6709\u591a\u4e2a\u5f31\u7b26\u53f7\u540c\u540d\uff0c\u90a3\u4e48\u4ece\u8fd9\u4e9b\u5f31\u7b26\u53f7\u4e2d\u4efb\u610f\u9009\u62e9\u4e00\u4e2a\u3002 foo.c bar.c run by gcc -0g foo.c bar.c & ./a.out #include <stdio.h> void f ( void ); int y = 12345 ; int x = 12345 ; int main (){ f (); printf ( \"x = 0x%x y = 0x%x \\n \" , x , y ); return 0 ; } double x ; void f (){ x = -0.0 ; }","title":"\u94fe\u63a5\u5668\u5982\u4f55\u89e3\u6790\u591a\u91cd\u5b9a\u4e49\u7684\u5168\u5c40\u7b26\u53f7"},{"location":"CSAPP/Linking/SymbolResolve/#\u4e0e\u9759\u6001\u5e93\u94fe\u63a5","text":"\u9759\u6001\u5e93 \u5c06\u6240\u6709\u76f8\u5173\u7684\u76ee\u6807\u6a21\u5757\u5927\u5b9d\u6210\u4e3a\u4e00\u4e2a\u5355\u72ec\u7684\u6587\u4ef6\uff0c\u79f0\u4e3a\u9759\u6001\u5e93\uff0c\u5b83\u53ef\u4ee5\u7528\u4f5c\u94fe\u63a5\u5668\u7684\u8f93\u5165\u3002 \u4e3a\u4ec0\u4e48\u9700\u8981\u9759\u6001\u5e93\uff1f \u5982\u679c\u8ba9\u7f16\u8bd1\u5668\u8fa8\u522b\u51fa\u5bf9\u6807\u51c6\u51fd\u6570\u7684\u8c03\u7528\u76f4\u63a5\u751f\u6210\u76f8\u5e94\u7684\u4ee3\u7801\u7684\u8bdd\uff0c\u4f1a\u6781\u5927\u7684\u589e\u52a0\u7f16\u8bd1\u5668\u7684\u590d\u6742\u5ea6\uff0c\u800c\u4e14\u6bcf\u6b21\u589e\u52a0\u3001\u5220\u9664\u6216\u8005\u4fee\u6539\u5e93\u51fd\u6570\u5c31\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u7f16\u8bd1\u5668\u7248\u672c\u3002 \u5982\u679c\u5c06\u6240\u6709\u7684\u6807\u51c6C\u51fd\u6570\u90fd\u653e\u5728\u4e00\u4e2a\u5355\u72ec\u7684\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6a21\u677f\u4e2d\uff0c\u4f1a\u5bf9\u78c1\u76d8\u9020\u6210\u6781\u5927\u7684\u6d6a\u8d39\u3002 \u5982\u679c\u4e3a\u6bcf\u4e2a\u6807\u51c6\u51fd\u6570\u521b\u5efa\u4e00\u4e2a\u72ec\u7acb\u7684\u53ef\u91cd\u5b9a\u4f4d\u6587\u4ef6\uff0c\u90a3\u4e48\u7a0b\u5e8f\u5458\u9700\u8981\u663e\u5f0f\u94fe\u63a5\u5408\u9002\u7684\u76ee\u6807\u6a21\u5757\u5230\u53ef\u6267\u884c\u6587\u4ef6\u4e2d\uff0c\u8fd9\u662f\u4e00\u4e2a\u5bb9\u6613\u51fa\u9519\u5e76\u4e14\u8017\u65f6\u7684\u8fc7\u7a0b\u3002 \u5982\u4f55\u521b\u5efa\u4e00\u4e2a\u9759\u6001\u5e93\uff1f addvec.c int addcnt = 0 ; void addvec ( int * x , int * y , int * z , int n ) { int i ; addcnt ++ ; for ( i = 0 ; i < n ; i ++ ) z [ i ] = x [ i ] + y [ i ]; } multvec.c int multcnt = 0 ; void multvec ( int * x , int * y , int * z , int n ) { int i ; multcnt ++ ; for ( i = 0 ; i < n ; i ++ ) z [ i ] = x [ i ] * y [ i ]; } command gcc -c addvec.c multvec.c ar rcs libvector.a addvec.o multvec.o \u5982\u4f55\u4f7f\u7528\u4e0a\u9762\u521b\u5efa\u7684\u5e93\u5462\uff1f main.c #include <stdio.h> #include \"vector.h\" int x [ 2 ] = { 1 , 2 }; int y [ 2 ] = { 3 , 4 }; int z [ 2 ]; int main () { addvec ( x , y , z , 2 ); printf ( \"z = [%d %d] \\n \" , z [ 0 ], z [ 1 ]); return 0 ; } command1 gcc -c main.c gcc -static -o main main.o ./libvector.a command2 gcc -c main.c gcc -static -o main main.o -L. -lvector // -lvector \u53c2\u6570\u662f libvector.a \u7684\u7f29\u5199, -L. \u53c2\u6570\u544a\u8bc9\u94fe\u63a5\u5668\u5728\u5f53\u524d\u76ee\u5f55\u4e0b\u67e5\u627e libvector.a\u3002","title":"\u4e0e\u9759\u6001\u5e93\u94fe\u63a5"},{"location":"CSAPP/Linking/SymbolResolve/#\u94fe\u63a5\u5668\u5982\u4f55\u4f7f\u7528\u9759\u6001\u5e93\u6765\u89e3\u6790\u5f15\u7528","text":"\u5728\u7b26\u53f7\u89e3\u6790\u9636\u6bb5\uff0c\u94fe\u63a5\u5668\u4ece\u5de6\u5230\u53f3\u6309\u7167\u5b83\u4eec\u5728\u7f16\u8bd1\u5668\u9a71\u52a8\u7a0b\u5e8f\u547d\u4ee4\u884c\u4e0a\u51fa\u73b0\u7684\u987a\u5e8f\u6765\u626b\u63cf\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\u548c\u5b58\u6863\u6587\u4ef6\u3002\u5728\u8fd9\u6b21\u626b\u63cf\u4e2d\uff0c\u94fe\u63a5\u5668\u7ef4\u62a4\u4e00\u4e2a\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\u7684\u96c6\u5408E\uff0c\u4e00\u4e2a\u672a\u89e3\u6790\u7684\u7b26\u53f7\u96c6\u5408U\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5728\u524d\u9762\u8f93\u5165\u6587\u4ef6\u4e2d\u5df2\u5b9a\u4e49\u7684\u7b26\u53f7\u96c6\u5408D\u3002 \u5bf9\u4e8e\u547d\u4ee4\u884c\u4e0a\u7684\u6bcf\u4e2a\u8f93\u5165\u6587\u4ef6 f, \u94fe\u63a5\u5668\u4f1a\u5224\u65ad f \u662f\u4e00\u4e2a\u76ee\u6807\u6587\u4ef6\u8fd8\u662f\u4e00\u4e2a\u5b58\u6863\u6587\u4ef6\u3002\u5982\u679c f \u662f\u4e00\u4e2a\u76ee\u6807\u6587\u4ef6,\u90a3\u4e48\u94fe\u63a5\u5668\u628a f \u6dfb\u52a0\u5230 E, \u4fee\u6539 U \u548c D \u6765\u53cd\u6620 f \u4e2d\u7684\u7b26\u53f7\u5b9a\u4e49\u548c\u5f15\u7528,\u5e76\u7ee7\u7eed\u4e0b\u4e00\u4e2a\u8f93\u5165\u6587\u4ef6\u3002 \u5982\u679c f \u662f\u4e00\u4e2a\u5b58\u6863\u6587\u4ef6,\u90a3\u4e48\u94fe\u63a5\u5668\u5c31\u5c1d\u8bd5\u5339\u914d U \u4e2d\u672a\u89e3\u6790\u7684\u7b26\u53f7\u548c\u7531\u5b58\u6863\u6587\u4ef6\u6210\u5458\u5b9a\u4e49\u7684\u7b26\u53f7\u3002\u5982\u679c\u67d0\u4e2a\u5b58\u6863\u6587\u4ef6\u6210\u5458 m, \u5b9a\u4e49\u4e86\u4e00\u4e2a\u7b26\u53f7\u6765\u89e3\u6790 U \u4e2d\u7684\u4e00\u4e2a\u5f15\u7528,\u90a3\u4e48\u5c31\u5c06 m \u52a0\u5230 E \u4e2d,\u5e76\u4e14\u94fe\u63a5\u5668\u4fee\u6539 U \u548c D \u6765\u53cd\u6620 m \u4e2d\u7684\u7b26\u53f7\u5b9a\u4e49\u548c\u5f15\u7528\u3002\u5bf9\u5b58\u6863\u6587\u4ef6\u4e2d\u6240\u6709\u7684\u6210\u5458\u76ee\u6807\u6587\u4ef6\u90fd\u4f9d\u6b21\u8fdb\u884c\u8fd9\u4e2a\u8fc7\u7a0b,\u76f4\u5230 U \u548c D \u90fd\u4e0d\u518d\u53d1\u751f\u53d8\u5316\u3002\u6b64\u65f6,\u4efb\u4f55\u4e0d\u5305\u542b\u5728 E \u4e2d\u7684\u6210\u5458\u76ee\u6807\u6587\u4ef6\u90fd\u7b80\u5355\u5730\u88ab\u4e22\u5f03,\u800c\u94fe\u63a5\u5668\u5c06\u7ee7\u7eed\u5904\u7406\u4e0b\u4e00\u4e2a\u8f93\u5165\u6587\u4ef6\u3002 \u5982\u679c\u5f53\u94fe\u63a5\u5668\u5b8c\u6210\u5bf9\u547d\u4ee4\u884c\u4e0a\u8f93\u5165\u6587\u4ef6\u7684\u626b\u63cf\u540e, U \u662f\u975e\u7a7a\u7684,\u90a3\u4e48\u94fe\u63a5\u5668\u5c31\u4f1a\u8f93\u51fa\u4e00\u4e2a\u9519\u8bef\u5e76\u7ec8\u6b62\u3002\u5426\u5219,\u5b83\u4f1a\u5408\u5e76\u548c\u91cd\u5b9a\u4f4d E \u4e2d\u7684\u76ee\u6807\u6587\u4ef6,\u6784\u5efa\u8f93\u51fa\u7684\u53ef\u6267\u884c\u6587\u4ef6\u3002 \u89e3\u91ca\u4e0b\u9762\u51fa\u9519\u7684\u539f\u56e0 command gcc -static ./libvector.a main.c \u5728\u5904\u7406 libvector.a \u65f6, U \u662f\u7a7a\u7684,\u6240\u4ee5\u6ca1\u6709 libvector.a \u4e2d\u7684\u6210\u5458\u76ee\u6807\u6587\u4ef6\u4f1a\u6dfb\u52a0\u5230 E \u4e2d\u3002\u56e0\u6b64,\u5bf9 addvec \u7684\u5f15\u7528\u662f\u7edd\u4e0d\u4f1a\u88ab\u89e3\u6790\u7684,\u6240\u4ee5\u94fe\u63a5\u5668\u4f1a\u4ea7\u751f\u4e00\u6761\u9519\u8bef\u4fe1\u606f\u5e76\u7ec8\u6b62\u3002 \u4e00\u4e9b\u4f8b\u5b50 \u4e00\u822c\u6765\u8bf4\u6211\u4eec\u5c06\u5e93\u653e\u5230\u547d\u4ee4\u884c\u7684\u7ed3\u5c3e\uff0ca \u548c b \u8868\u793a\u5f53\u524d\u76ee\u5f55\u4e2d\u7684\u76ee\u6807\u6a21\u5757\u6216\u8005\u9759\u6001\u5e93,\u800c a -> b \u8868\u793a a \u4f9d\u8d56\u4e8e b, \u4e5f\u5c31\u662f\u8bf4 b \u5b9a\u4e49\u4e86\u4e00\u4e2a\u88ab a \u5f15\u7528\u7684\u7b26\u53f7\u3002\u5bf9\u4e8e\u4e0b\u9762\u6bcf\u79cd\u573a\u666f,\u8bf7\u7ed9\u51fa\u6700\u5c0f\u7684\u547d\u4ee4\u884c(\u5373\u4e00\u4e2a\u542b\u6709\u6700\u5c11\u6570\u91cf\u7684\u76ee\u6807\u6587\u4ef6\u548c\u5e93\u53c2\u6570\u7684\u547d\u4ee4),\u4f7f\u5f97\u9759\u6001\u94fe\u63a5\u5668\u80fd\u89e3\u6790\u6240\u6709\u7684\u7b26\u53f7\u5f15\u7528\u3002 p.o -> libx.a gcc p.o libx.a p.o -> libx.a -> liby.a gcc p.o libx.a liby.a p.o->libx.a->liby.a && liby.a -> libx.a->p.o gcc p.o libx.a liby.a liby.a","title":"\u94fe\u63a5\u5668\u5982\u4f55\u4f7f\u7528\u9759\u6001\u5e93\u6765\u89e3\u6790\u5f15\u7528"},{"location":"CSAPP/Linking/Symbols/","text":"\u7b26\u53f7\u548c\u7b26\u53f7\u8868 \u00b6 ELF\u7b26\u53f7\u8868\u4e2d\u7684\u6761\u76ee typedef struct { int name ; /* String table offset */ char type : 4 , /* Function or data (4 bits) */ binding : 4 ; /* Local or global (4 bits) */ char reserved ; /* Unused */ short section ; /* Section header index */ long value ; /* Section offset or absolute address */ long size ; /* Object size in bytes */ } Elf64_Symbol ; Name Description name \u5b57\u7b26\u4e32\u8868\u4e2d\u7684\u5b57\u8282\u504f\u79fb value \u7b26\u53f7\u7684\u5730\u5740 size \u76ee\u6807\u7684\u5927\u5c0f type \u8981\u4e48\u662f\u6570\u636e\u8981\u4e48\u662f\u51fd\u6570 binding \u672c\u5730\u8fd8\u662f\u5168\u5c40\uff1f \u6ce8\u610f\uff0c\u6709\u4e09\u4e2a\u4f2a\u8282\uff0c\u53ea\u6709\u53ef\u91cd\u5b9a\u4f4d\u6587\u4ef6\u4e2d\u624d\u6709\u7684\uff1a ABS \uff1a\u8868\u793a\u4e0d\u8be5\u88ab\u91cd\u5b9a\u4f4d\u7684\u7b26\u53f7 UNDEF \uff1a\u4ee3\u8868\u672a\u5b9a\u4e49\u7684\u7b26\u53f7 COMMON \uff1a\u8868\u793a\u8fd8\u672a\u88ab\u5206\u914d\u4f4d\u7f6e\u7684\u672a\u521d\u59cb\u5316\u7684\u6570\u636e\u6761\u76ee COMMON vs. .bss COMMON \uff1a\u672a\u521d\u59cb\u5316\u7684\u5168\u5c40\u53d8\u91cf .bss \uff1a\u672a\u521d\u59cb\u5316\u7684\u9759\u6001\u53d8\u91cf\u4ee5\u53ca\u521d\u59cb\u5316\u4e3a0\u7684\u5168\u5c40\u6216\u8005\u9759\u6001\u53d8\u91cf\u3002","title":"Symbols"},{"location":"CSAPP/Linking/Symbols/#\u7b26\u53f7\u548c\u7b26\u53f7\u8868","text":"ELF\u7b26\u53f7\u8868\u4e2d\u7684\u6761\u76ee typedef struct { int name ; /* String table offset */ char type : 4 , /* Function or data (4 bits) */ binding : 4 ; /* Local or global (4 bits) */ char reserved ; /* Unused */ short section ; /* Section header index */ long value ; /* Section offset or absolute address */ long size ; /* Object size in bytes */ } Elf64_Symbol ; Name Description name \u5b57\u7b26\u4e32\u8868\u4e2d\u7684\u5b57\u8282\u504f\u79fb value \u7b26\u53f7\u7684\u5730\u5740 size \u76ee\u6807\u7684\u5927\u5c0f type \u8981\u4e48\u662f\u6570\u636e\u8981\u4e48\u662f\u51fd\u6570 binding \u672c\u5730\u8fd8\u662f\u5168\u5c40\uff1f \u6ce8\u610f\uff0c\u6709\u4e09\u4e2a\u4f2a\u8282\uff0c\u53ea\u6709\u53ef\u91cd\u5b9a\u4f4d\u6587\u4ef6\u4e2d\u624d\u6709\u7684\uff1a ABS \uff1a\u8868\u793a\u4e0d\u8be5\u88ab\u91cd\u5b9a\u4f4d\u7684\u7b26\u53f7 UNDEF \uff1a\u4ee3\u8868\u672a\u5b9a\u4e49\u7684\u7b26\u53f7 COMMON \uff1a\u8868\u793a\u8fd8\u672a\u88ab\u5206\u914d\u4f4d\u7f6e\u7684\u672a\u521d\u59cb\u5316\u7684\u6570\u636e\u6761\u76ee COMMON vs. .bss COMMON \uff1a\u672a\u521d\u59cb\u5316\u7684\u5168\u5c40\u53d8\u91cf .bss \uff1a\u672a\u521d\u59cb\u5316\u7684\u9759\u6001\u53d8\u91cf\u4ee5\u53ca\u521d\u59cb\u5316\u4e3a0\u7684\u5168\u5c40\u6216\u8005\u9759\u6001\u53d8\u91cf\u3002","title":"\u7b26\u53f7\u548c\u7b26\u53f7\u8868"},{"location":"CSAPP/Linking/loading/","text":"\u52a0\u8f7d\u53ef\u6267\u884c\u76ee\u6807\u6587\u4ef6 \u00b6 \u5f53\u52a0\u8f7d\u5668\u8fd0\u884c\u65f6,\u5b83\u521b\u5efa \u7c7b\u4f3c\u56fe \u6240\u793a\u7684\u5185\u5b58\u6620\u50cf\u3002 \u5728\u7a0b\u5e8f\u5934\u90e8\u8868\u7684\u5f15\u5bfc\u4e0b,\u52a0\u8f7d\u5668\u5c06\u53ef\u6267\u884c\u6587\u4ef6\u7684\u7247 (chunk) \u590d\u5236\u5230\u4ee3\u7801\u6bb5\u548c\u6570\u636e\u6bb5 \u3002\u63a5 \u4e0b\u6765,\u52a0\u8f7d\u5668\u8df3\u8f6c\u5230\u7a0b\u5e8f\u7684\u5165\u53e3\u70b9,\u4e5f\u5c31\u662f _start \u51fd\u6570\u7684\u5730\u5740\u3002\u8fd9\u4e2a\u51fd\u6570\u662f\u5728\u7cfb\u7edf\u76ee\u6807\u6587\u4ef6 ctrl.o \u4e2d\u5b9a\u4e49\u7684,\u5bf9\u6240\u6709\u7684 C \u7a0b\u5e8f\u90fd\u662f \u4e00 \u6837\u7684\u3002 _start \u51fd\u6570\u8c03\u7528\u7cfb\u7edf\u542f\u52a8\u51fd\u6570 __libc_start_main , \u8be5\u51fd\u6570\u5b9a\u4e49\u5728 libc.so \u4e2d\u3002\u5b83\u521d\u59cb\u5316\u6267\u884c\u73af\u5883,\u8c03\u7528\u7528\u6237\u5c42\u7684 main \u51fd\u6570,\u5904\u7406 main \u51fd\u6570\u7684\u8fd4\u56de\u503c,\u5e76\u4e14\u5728\u9700\u8981\u7684\u65f6\u5019\u628a\u63a7\u5236\u8fd4\u56de\u7ed9\u5185\u6838\u3002","title":"Loading"},{"location":"CSAPP/Linking/loading/#\u52a0\u8f7d\u53ef\u6267\u884c\u76ee\u6807\u6587\u4ef6","text":"\u5f53\u52a0\u8f7d\u5668\u8fd0\u884c\u65f6,\u5b83\u521b\u5efa \u7c7b\u4f3c\u56fe \u6240\u793a\u7684\u5185\u5b58\u6620\u50cf\u3002 \u5728\u7a0b\u5e8f\u5934\u90e8\u8868\u7684\u5f15\u5bfc\u4e0b,\u52a0\u8f7d\u5668\u5c06\u53ef\u6267\u884c\u6587\u4ef6\u7684\u7247 (chunk) \u590d\u5236\u5230\u4ee3\u7801\u6bb5\u548c\u6570\u636e\u6bb5 \u3002\u63a5 \u4e0b\u6765,\u52a0\u8f7d\u5668\u8df3\u8f6c\u5230\u7a0b\u5e8f\u7684\u5165\u53e3\u70b9,\u4e5f\u5c31\u662f _start \u51fd\u6570\u7684\u5730\u5740\u3002\u8fd9\u4e2a\u51fd\u6570\u662f\u5728\u7cfb\u7edf\u76ee\u6807\u6587\u4ef6 ctrl.o \u4e2d\u5b9a\u4e49\u7684,\u5bf9\u6240\u6709\u7684 C \u7a0b\u5e8f\u90fd\u662f \u4e00 \u6837\u7684\u3002 _start \u51fd\u6570\u8c03\u7528\u7cfb\u7edf\u542f\u52a8\u51fd\u6570 __libc_start_main , \u8be5\u51fd\u6570\u5b9a\u4e49\u5728 libc.so \u4e2d\u3002\u5b83\u521d\u59cb\u5316\u6267\u884c\u73af\u5883,\u8c03\u7528\u7528\u6237\u5c42\u7684 main \u51fd\u6570,\u5904\u7406 main \u51fd\u6570\u7684\u8fd4\u56de\u503c,\u5e76\u4e14\u5728\u9700\u8981\u7684\u65f6\u5019\u628a\u63a7\u5236\u8fd4\u56de\u7ed9\u5185\u6838\u3002","title":"\u52a0\u8f7d\u53ef\u6267\u884c\u76ee\u6807\u6587\u4ef6"},{"location":"CSAPP/Linking/objectfile/","text":"\u76ee\u6807\u6587\u4ef6 \u00b6 \u76ee\u6807\u6587\u4ef6\u7684\u4e09\u79cd\u5f62\u5f0f \u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\uff1a\u53ef\u4ee5\u5728\u7f16\u8bd1\u65f6\u5019\u8ddf\u5176\u4ed6\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\u5408\u5e76\u8d77\u6765\u3002\uff08\u7f16\u8bd1\u5668\u548c\u6c47\u7f16\u5668\u751f\u6210\uff09 \u53ef\u6267\u884c\u76ee\u6807\u6587\u4ef6:\u53ef\u4ee5\u76f4\u63a5\u590d\u5236\u5230\u5185\u5b58\u6267\u884c\u3002\uff08\u94fe\u63a5\u5668\u751f\u6210\uff09 \u5171\u4eab\u76ee\u6807\u6587\u4ef6: \u5728\u52a0\u8f7d\u6216\u8005\u8fd0\u884c\u65f6\u5019\u88ab\u52a8\u6001\u5730\u52a0\u8f7d\u8fdb\u5185\u5b58\u5e76\u94fe\u63a5\u3002\uff08\u7f16\u8bd1\u5668\u548c\u6c47\u7f16\u5668\u751f\u6210\uff09","title":"Objectfile"},{"location":"CSAPP/Linking/objectfile/#\u76ee\u6807\u6587\u4ef6","text":"\u76ee\u6807\u6587\u4ef6\u7684\u4e09\u79cd\u5f62\u5f0f \u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\uff1a\u53ef\u4ee5\u5728\u7f16\u8bd1\u65f6\u5019\u8ddf\u5176\u4ed6\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\u5408\u5e76\u8d77\u6765\u3002\uff08\u7f16\u8bd1\u5668\u548c\u6c47\u7f16\u5668\u751f\u6210\uff09 \u53ef\u6267\u884c\u76ee\u6807\u6587\u4ef6:\u53ef\u4ee5\u76f4\u63a5\u590d\u5236\u5230\u5185\u5b58\u6267\u884c\u3002\uff08\u94fe\u63a5\u5668\u751f\u6210\uff09 \u5171\u4eab\u76ee\u6807\u6587\u4ef6: \u5728\u52a0\u8f7d\u6216\u8005\u8fd0\u884c\u65f6\u5019\u88ab\u52a8\u6001\u5730\u52a0\u8f7d\u8fdb\u5185\u5b58\u5e76\u94fe\u63a5\u3002\uff08\u7f16\u8bd1\u5668\u548c\u6c47\u7f16\u5668\u751f\u6210\uff09","title":"\u76ee\u6807\u6587\u4ef6"},{"location":"CSAPP/Linking/objfile/","text":"\u53ef\u6267\u884c\u76ee\u6807\u6587\u4ef6 \u00b6","title":"Objfile"},{"location":"CSAPP/Linking/objfile/#\u53ef\u6267\u884c\u76ee\u6807\u6587\u4ef6","text":"","title":"\u53ef\u6267\u884c\u76ee\u6807\u6587\u4ef6"},{"location":"CSAPP/Linking/relocobj/","text":"\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6 \u00b6 \u6211\u4eec\u4ee5ELF\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\u4e3a\u4f8b\u5b50\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\u7684\u5404\u79cd\u8282\u3002 Name Description .text \u5df2\u7f16\u8bd1\u7a0b\u5e8f\u7684\u673a\u5668\u4ee3\u7801 .rodata \u53ea\u8bfb\u6570\u636e .data \u5df2\u521d\u59cb\u5316\u7684\u5168\u5c40\u548c\u9759\u6001C\u53d8\u91cf bss \u672a\u521d\u59cb\u5316\u7684\u5168\u5c40\u548c\u9759\u6001C\u53d8\u91cf\uff0c\u4ee5\u53ca\u6240\u6709\u88ab\u521d\u59cb\u5316\u4e3a0\u7684\u5168\u5c40\u6216\u8005\u9759\u6001\u53d8\u91cf .symtab \u4e00\u4e2a\u7b26\u53f7\u8868\uff0c\u4ed6\u5b58\u653e\u5728\u7a0b\u5e8f\u4e2d\u5b9a\u4e49\u548c\u5f15\u7528\u7684\u51fd\u6570\u548c\u5168\u5c40\u53d8\u91cf\u7684\u4fe1\u606f .rel.text \u4e00\u4e2a .text \u8282\u4e2d\u4f4d\u7f6e\u7684\u5217\u8868\uff0c\u5f53\u94fe\u63a5\u5668\u628a\u8fd9\u4e2a\u76ee\u6807\u6587\u4ef6\u548c\u5176\u4ed6\u6587\u4ef6\u7ec4\u5408\u65f6\uff0c\u9700\u8981\u4fee\u6539\u8fd9\u4e9b\u4f4d\u7f6e\u3002 .rel.data \u88ab\u6a21\u5757\u5f15\u7528\u6216\u5b9a\u4e49\u7684\u6240\u6709\u5168\u5c40\u53d8\u91cf\u7684\u91cd\u5b9a\u4f4d\u4fe1\u606f\u3002 .debug \u4e00\u4e2a\u8c03\u8bd5\u7b26\u53f7\u8868 .line \u539f\u59cb C \u6e90\u7a0b\u5e8f\u4e2d\u7684\u884c\u53f7\u548c .text \u8282\u4e2d\u673a\u5668\u6307\u4ee4\u4e4b\u95f4\u7684\u6620\u5c04 .strtab \u4e00\u4e2a\u5b57\u7b26\u4e32\u8868\uff0c\u5c31\u662f\u4ee5 null \u7ed3\u5c3e\u7684\u5b57\u7b26\u4e32\u5e8f\u5217\u3002","title":"Relocobj"},{"location":"CSAPP/Linking/relocobj/#\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6","text":"\u6211\u4eec\u4ee5ELF\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\u4e3a\u4f8b\u5b50\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6\u7684\u5404\u79cd\u8282\u3002 Name Description .text \u5df2\u7f16\u8bd1\u7a0b\u5e8f\u7684\u673a\u5668\u4ee3\u7801 .rodata \u53ea\u8bfb\u6570\u636e .data \u5df2\u521d\u59cb\u5316\u7684\u5168\u5c40\u548c\u9759\u6001C\u53d8\u91cf bss \u672a\u521d\u59cb\u5316\u7684\u5168\u5c40\u548c\u9759\u6001C\u53d8\u91cf\uff0c\u4ee5\u53ca\u6240\u6709\u88ab\u521d\u59cb\u5316\u4e3a0\u7684\u5168\u5c40\u6216\u8005\u9759\u6001\u53d8\u91cf .symtab \u4e00\u4e2a\u7b26\u53f7\u8868\uff0c\u4ed6\u5b58\u653e\u5728\u7a0b\u5e8f\u4e2d\u5b9a\u4e49\u548c\u5f15\u7528\u7684\u51fd\u6570\u548c\u5168\u5c40\u53d8\u91cf\u7684\u4fe1\u606f .rel.text \u4e00\u4e2a .text \u8282\u4e2d\u4f4d\u7f6e\u7684\u5217\u8868\uff0c\u5f53\u94fe\u63a5\u5668\u628a\u8fd9\u4e2a\u76ee\u6807\u6587\u4ef6\u548c\u5176\u4ed6\u6587\u4ef6\u7ec4\u5408\u65f6\uff0c\u9700\u8981\u4fee\u6539\u8fd9\u4e9b\u4f4d\u7f6e\u3002 .rel.data \u88ab\u6a21\u5757\u5f15\u7528\u6216\u5b9a\u4e49\u7684\u6240\u6709\u5168\u5c40\u53d8\u91cf\u7684\u91cd\u5b9a\u4f4d\u4fe1\u606f\u3002 .debug \u4e00\u4e2a\u8c03\u8bd5\u7b26\u53f7\u8868 .line \u539f\u59cb C \u6e90\u7a0b\u5e8f\u4e2d\u7684\u884c\u53f7\u548c .text \u8282\u4e2d\u673a\u5668\u6307\u4ee4\u4e4b\u95f4\u7684\u6620\u5c04 .strtab \u4e00\u4e2a\u5b57\u7b26\u4e32\u8868\uff0c\u5c31\u662f\u4ee5 null \u7ed3\u5c3e\u7684\u5b57\u7b26\u4e32\u5e8f\u5217\u3002","title":"\u53ef\u91cd\u5b9a\u4f4d\u76ee\u6807\u6587\u4ef6"},{"location":"CSAPP/source/cachelab-handout/","text":"https://azrael.digipen.edu/~mmead/www/Courses/CS180/getopt.html reference","title":"Index"},{"location":"CSAPP/source/malloclab-handout/traces/","text":"Traces \u00b6 This directory contains traces of allocate and free requests that are used by the test harness to evaluate the student malloc packages. 1. Files \u00b6 .rep Original traces -bal.rep Balanced versions of the original traces Note: A \"balanced\" trace has a matching free request for each allocate request. 2. Trace file format \u00b6 A trace file is an ASCII file. It begins with a 4-line header: <sugg_heapsize> /* suggested heap size (unused) */ <num_ids> /* number of request id's */ <num_ops> /* number of requests (operations) */ <weight> /* weight for this trace (unused) */ The header is followed by num_ops text lines. Each line denotes either an allocate [a], reallocate [r], or free [f] request. The <alloc_id> is an integer that uniquely identifies an allocate or reallocate request. a <id> <bytes> /* ptr_<id> = malloc(<bytes>) */ r <id> <bytes> /* realloc(ptr_<id>, <bytes>) */ f <id> /* free(ptr_<id>) */ For example, the following trace file: <beginning of file> 20000 3 8 1 a 0 512 a 1 128 r 0 640 a 2 128 f 1 r 0 768 f 0 f 2 <end of file> is balanced. It has a recommended heap size of 20000 bytes (ignored), three distinct request ids (0, 1, and 2), eight different requests (one per line), and a weight of 1 (ignored).","title":"Traces"},{"location":"CSAPP/source/malloclab-handout/traces/#traces","text":"This directory contains traces of allocate and free requests that are used by the test harness to evaluate the student malloc packages.","title":"Traces"},{"location":"CSAPP/source/malloclab-handout/traces/#1-files","text":".rep Original traces -bal.rep Balanced versions of the original traces Note: A \"balanced\" trace has a matching free request for each allocate request.","title":"1. Files"},{"location":"CSAPP/source/malloclab-handout/traces/#2-trace-file-format","text":"A trace file is an ASCII file. It begins with a 4-line header: <sugg_heapsize> /* suggested heap size (unused) */ <num_ids> /* number of request id's */ <num_ops> /* number of requests (operations) */ <weight> /* weight for this trace (unused) */ The header is followed by num_ops text lines. Each line denotes either an allocate [a], reallocate [r], or free [f] request. The <alloc_id> is an integer that uniquely identifies an allocate or reallocate request. a <id> <bytes> /* ptr_<id> = malloc(<bytes>) */ r <id> <bytes> /* realloc(ptr_<id>, <bytes>) */ f <id> /* free(ptr_<id>) */ For example, the following trace file: <beginning of file> 20000 3 8 1 a 0 512 a 1 128 r 0 640 a 2 128 f 1 r 0 768 f 0 f 2 <end of file> is balanced. It has a recommended heap size of 20000 bytes (ignored), three distinct request ids (0, 1, and 2), eight different requests (one per line), and a weight of 1 (ignored).","title":"2. Trace file format"},{"location":"Compiler/CS143/","text":"14-01 Intermediate language \u00b6 What is Intermediate language? \u00b6 The intermediate language is a language between the source and the target. Why bother to introduce Intermediate language? \u00b6 Because it provides an intermediate level of abstraction, it has more details than the source. For example, we want to optimize register usage, most source languages have no notion of the register at the source level so there is no way to even express the kinds of optimization you might want to do with registers. It will also have fewer details than the target. For example, the intermediate language is a little bit above the level of the particular instruction set of a particular machine, and therefore, it is easier to retarget that intermediate level of code to lots of different kinds of machines because it doesn't have all the grubby details of a particular machine. 14-02 Optimization Overview \u00b6 When should we perform optimizations? \u00b6 In fact, we can perform them on the AST, a big advantage of that is that it's machine-independent, but it turns out AST is too high for a lot of optimizations we want to do because optimizations depend on lower-level details of the machine. Another possibility would be to perform optimizations directly on the assembly language but they are machine-dependent and we would have to reimplement optimizations for each kind of architecture. So intermediate language is an ideal choice. What is the purpose of optimization? \u00b6 The purpose of optimization is to improve a program's resource utilization such as execution time, code size, network messages sent, and so on. For languages like C and Cool, there are three granularities of optimizations. One is called Local optimizations which occur within a single block. Then there're what are called Global optimizations. This is really misnamed because it is not global across the entire program, it's global across an entire function. So global optimizations would apply to a single function and apply to all the basic blocks of that function. And finally, there are inter-procedural optimizations. These are optimizations that work across method boundaries. They take multiple functions and move things around to try to optimize the collection of functions as a whole. In practice, often a conscious decision is made not to implement the fanciest optimization known, why? \u00b6 First, some optimizations are hard to implement for SE. Second, some optimizations are costly in compilation time. Even though the compiling happens offline not part of the running of the program, the programmer still has to wait when the optimizing compiler does its optimizations. Third, some of these optimizations have a low payoff. They might only do it by a small amount. Last, unfortunately, many fancy optimizations are all there! So the goal of optimization is to maximum benefit for minimum cost. 14-03 Local Optimizations \u00b6 Algebraic Simplification \u00b6 Some statements can be deleted. \u00b6 x : = x + 0 ; x : = x * 1 ; Some statements can be simplified. \u00b6 x : = x * 0 ; => x := 0 ; y : = y ** 2 ; => y := y * y ; z : = z * 8 ; => z := z << 3 ; p : = p * 15 ; => t := p << 4 ; p : = t - p ; For the operator ** , it's probably that's going to wind up in our generated code is a call to some built-in math library which will introduce the function call overhead and some kind of general loop in there. So in a special case where we know the exponent is 2, it's much more efficient to just replace that call to exponentiate by an explicit multiply. Another example is z := z * 8; . If we have a multiplication by a power of 2 , we can replace that with a left bit shift. In fact, it doesn't have to be a power of two if we have a multiplication by some other number, that can be replaced by some combination of shifting and subtractions. I want to point out that these transformations will not result in any kind of speedup because, on modern machines, multiplication is just as fast as any other single instruction. constant folding \u00b6 Operations on constants can be computed at compile time. x : = 2 + 2 ; => x := 4 ; if 2 > 0 jump L => jump L ; There is one situation that you should be aware of in which constant folding can be very dangerous. It's something that really illustrates some of the subtleties of program optimization and programming language semantics. Let's consider the scenario where we have two machines, X, Y. Now the compiler is running on machine X, and the compiler is producing code for machine Y, and the code will run on it. This is called cross-compiler(Just considering the embedded system code). The problem comes, if X and Y are different architectures. So let's say we have the instruction a := 1.5 + 3.7; , and you would like to constant fold that down to equal 5.2 . Now the problem is that if you simply execute this as a floating-point operation on X, the roundoff and the pointing number semantics may be slightly different from Y. So on Y you may get something like a:= 5.19; . There might be a small difference in the floating-point result. Eliminate unreachable basic blocks \u00b6 An unreachable basic block is one that is not the target of any jump or falls through. It will make the code smaller and run faster because of the cache effects to increase the spatial locality. Why would unreachable basic blocks occur? \u00b6 There are several ways in which unreachable code can arise. The most common cause is that the code is actually parameterized with code that is only compiled and used in certain situations. In c, it would be sort of typical to see some code that looks like this: #define DEBUG 0 if ( DEBUG ){ ...} Another case where unreachable code comes up is with libraries. So very frequently, programs are written to use generic libraries that the program might only use a very small part of the interface. But the library might supply hundreds of methods to cover all the situations. But for your program, you might only be using three of those methods and the rest of the methods could potentially be removed from the final binary to make the code smaller. And finally, another way that unreachable basic blocks occur is as the result of other optimizations. So as we can see, optimizations frequently lead to more optimizations. And it could just be through other rearrangements of the compiler to make some redundant BBs removed. Some optimizations are simplified if each register occurs only once on the left-hand side of an assignment. \u00b6 If each register is assigned at most once then some of these optimizations are easier to talk about. Common subexpression elimination \u00b6 In SSA and x := is the first use of x in a block. Then when two assignments have the same rhs, they compute the same value. x : = y + z ; ... w : = y + z ; can be replaced by : x : = y + z ; ... w : = x ; copy propogation \u00b6 If w := x appears in a block, replace subsequent uses of w with the use of x . b : = z + y ; a : = b ; x : = 2 * a ; can be replaced by: b : = z + y ; a : = b ; x : = 2 * b ; This optimization can only be useful in conjunction with some of other optimizations such as constant folding and dead code elimination. Sumarry \u00b6 Each of these optimizations presented actually doesn't make the program run faster at all. They don't make program run slower either, but by themselves, they don't actually make any improvement to the program. But typically, the optimizations will interact , so performing one optimization will enable another. So the way to think about an optimizing compiler is that it has a big bag of tricks(program transformations), when faced with a program to optimize, it is going to rummage around in its bag looking for an optimization that applies to some part of the code. If it finds one, it will do the optimization. And it will repeat it and look back and see if there is another optimization that applies. Then it will just keep doing this until it reaches a point where none of the optimizations it knows can be applied. 14-04 Peephole Optimizations \u00b6 Let's see a variation on local optimization that applies directly to assembly code called peephole optimization. Peephole optimization in one such technique that peephole stands for a short (usually continuous) sequence of instructions, what optimizer will do is to replace the sequence with another equivalent one(but faster). One example is: move $a $b move $b $a can be replaced by the following code if move $b $a is not the target of a jump. move $a $b Another example is addiu $a $a i ; addiu $a $a j ; can be replaced by the following code addiu $a $a i + j ; Many basic block optimizations can be cast also as peephole optimizations.: addiu $a $b 0 -> move $a $b move $a $a -> Peephole optimizations must be applied repeatedly for maximum effect. In fact, program optimization is grossly misnamed, I think program improvement is a more appropriate term because compilers will just improve the program as much as they can, and there is no guarantee that the best code will be produced. 16-01 Register Allocation \u00b6 Overview \u00b6 Intermediate code can use an unlimited number of temporaries, this simplifies optimization because they don't have to worry about preserving the right number of registers in the code but it does complicate the final translation into assembly code because we might be using too many temporaries and this is actually a problem in practice. So it's common for intermediate code to use more temporaries than physical registers on the machine. Then the problem is to rewrite the intermediate code to use no more temporaries than physical registers. And we are going to assign multiple temporaries to each register. So we are going to have a many-one mapping from temporaries to registers. How can we actually make a single register hold multiple values? Well, the trick is that it's fine for registers to have local values as long as it only has one value at a time. Let's consider this program: a : = c + d ; e : = a + b ; f : = e - 1 ; Here, I'm assuming that a and e are not used anywhere else and so it turns out that a, e, and f could all actually live in the same register. Alright, that's assuming that a and e are dead after their uses. And what will that look like, well let's allocate them all to a particular register r1 and let's assign c , d , and b into their own individual registers and the code would like this: r1 : = r2 + r3 ; r1 : = r1 + r4 ; r1 : = r1 - 1 ; And so now notice this is just a translation of the code over here into registers but there is a many one mapping of names above to register names below. History \u00b6 A register allocation is an old problem. In fact, it was first recognized way back in the 1950s in the original Fortran project but originally, register allocation was done with a fairly crude algorithm, and someone rapidly or very quickly noticed that was actually a bottleneck in the quality of code generation that actually limitations on the ability of register allocation have a really significant effect on the overall quality of the code that compilers could produce. And then about 30 years later, in 1980, a breakthrough occurred where a group of researchers at IBM discovered a register allocation scheme based on graph coloring. And the great thing about this scheme is that it's pretty simple. It's easy to explain. It's global, meaning it takes advantage of information from the entire control flow graph at the same time and also happens to work well in practice. register interface graph(RIG) \u00b6 And here's the basic principle that underlies the modern register allocation algorithms. So, if I have two temporaries t1 and t2 , I want to know when they can share register. So, they're allowed to share a register if they are not live at the same time. Let's take a look at a control flow graph and now, we know that in order to do the register allocation to solve the register allocation at least in this in this way, we're going to need liveness information. Well, we're going to construct an undirected graph and in this graph, there will be a node for each temporary so each variable will have a node in the graph and there'll be an edge between two temporaries if they are live simultaneously at some point in the program. This is the graph (RIG) constructed from the code and the line analysis above, it's easy to read off from the graph what the constraints are. So, for example, b and c cannot be in the same register because b and c are connected by an edge, which means they're live simultaneously at some part, some point in the program and so they have to live in different registers. On the other hand, there is at, there is no edge between b and d. So, this edge is missing, and therefore, it's possible that b and d could be allocated in the same register. So a great thing about the register interference graph (RIG) is that it extracts exactly the information needed to characterize a legal register assignment. So, it gives us a representation of all the possible legal register assignments. Now, we haven't actually gotten a register assignment out of the register interference graph, but the first step is to characterize the problem in some kind of precise way. The other thing that is good about is a global view of the register requirements meaning it's over the entire control flow graphs. So, takes into account information from every part of the control flow graph which will help us to make good global decisions about what value is very important to live in registers. And finally, the other thing to notice is that, after reconstruction, the register allocation for the algorithm is architecture-independent. 16-02 Graph Coloring \u00b6 A graph coloring is an assignment of colors to nodes such that the nodes connected by an edge have different colors. And then the graph is k-colorable if it has a coloring that uses k or fewer colors. In our problem, the colors correspond to registers so we want to do is to assign colors or registers to the graph nodes. And we're going to let k, the number, the maximum number of colors we're allowed to use be the number of machine registers. Algorithm \u00b6 Step1 Pick a node t with fewer than k neighbors in RIG Eliminate t and its edges from RIG If the resulting graph is k-colorable, then so is the original graph Step2: Assign colors to nodes on the stack Start with the last node added At each step pick a color different from those assigned to already colored neighbors 16-03 Spilling \u00b6 In this lecture, we are going to continue our discussion of register allocation, and this time we are going to talk about what happens when we can't successfully color the graph, in which case we have to do something known as spilling. The graph coloring algorithm that we discussed in the previous last doesn't always succeed in coloring an arbitrary graph. And it may well get stuck and not be able to find a coloring. And so in that case the only conclusion we can reach is that we can't hold all the values to register. And those temporary values have to live somewhere so where should they live? Well, they're going to have to live in memory. That's the only other kind of story that we have. And so we're going to pick some values and spill them into memory. The ideas that we have, the picture in your mind should be a bucket and it can hold a fixed amount of stuff, those are the registers and when it gets too full, some of the stuff spills over, and ends up someplace else. Now, when does the graph coloring do get stuck? Well, the only situation in which we won't be able to make progress is all the nodes have k or more neighbors. Given that the machine we want to use only has three registers and so we, instead of finding a 4-coloring of this graph, we need to find a 3-coloring. So let's think about how to find the three coloring of this graph. If we apply the heuristic, we'll remove A from the graph but then we're going to get stuck. Because once you take A out of the graph and its edge is out and every node left has three or more neighbors as at least three neighbors. So, there's no node that we can delete from the graph and be guaranteed to be able to find the coloring for it with the heuristic that we discussed in the previous lecture. So, in this situation, what we're going to do is we're going to pick and know that there is a candidate for spilling. This is a node that we think we may have to assign into a memory location rather than to our register. Let's assume for the sake of this example that we pick f and we're going to spill f . Now we have to try to assign a color to f and it could be, we could get lucky and discover that even though f had more than there neighbors or three or more neighbors when we remove it from the graph, it could be that when we go to construct the coloring for the subgraph that those neighbors actually don't use all of the registers. And so, this is called optimistic coloring . So we pick a candidate for spilling. We tried to color the subgraph. Once we have a coloring for the sub-graph, now we see if we just get lucky are able to assign a register to f in which case we can just go ahead and continue the color of the rest of the graph as if nothing had happened. So in this case let's take a look at what happens. We're going to add f back into the graph. And in this case, optimistic coloring will not work so, in fact, f had more than K neighbors and after we color the sub-graph, it turns out that those neighbors are using all K. And so there is no register leftover for f and we're going to have to actually spill it and store it in memory. So, if optimistic coloring fails as it does in this example, then we spill f . So, what we're going to do is allocate the memory location for f and typically, what that means is that we'll allocate a position in the current stack frame. Let's call this address fa for the address of f . And then we're going to modify the control flow graph. We're going to change the code for that compiling. So, before each operation that reads f , we're going to insert a load that loads from that address to the current value of f into a temporary name. And similarly, after each operation that writes f , we're going to insert the store so we're going to save the current value of f into its location in memory. So, here is the original code from which we constructed the registry interference graph and notice that there are few references to f in here and we just highlight them, alright. So, here we had the use of f , the read of f in this statement and now we preceded that by a load. And notice that I've given a new name here I've called f1 , that's because the different uses of f in the control flow graph don't all have to have the same temporary name and actually, it would be a good idea to separate them so each distinct to use of f will get its own name. So here we load the value of f and then it gets to use in the statement. Here we have a write to f and so we store the current value of f to a different name f2 . And finally, the third use of f there's another load of f right here which is then used in this computation here of b . Okay. So, that is the systematic way to modify the code to use f in storage. And now, we have to recompute the aliveness of f . And so, whathappens there? Well, here is the original aliveness information from which we computed the register interference graph, okay. And now notice that f is gone. We no longer use f in the programs so we can delete all the places where we mentioned that f was live and now we have the three new names, f1 , f2 , and f3 . And we have to add in their aliveness information so it creates a new program where we inserted statements. And of course, where we have a load of the current value of f lives right before the use in the next statement. Here, we have the right of the current value of f and that's live right before the store, and then here's another load of the current value of f which is live until the use in the next statement. Okay. And so, now notice here that f used to be live in many places in the code. And now not only is f of the different versions in fewer places also we've distinguished them. So, it actually separates the different uses of f and so this will have their own nodes in their own set of interferences in the graph and they won't share them with the other users of f and that will actually also reduce the number of edges in the graph. To summarize the example above, once we have decided that we are actually going to spill a temporary f , that means we're going to change the program where have loads and stores to the program and now we're going to have a different program and that's going to change our register allocation problems. We're going to have to recompute the aliveness of information, we have to rebuild the restrain interference graph and then we're going to have to try again to color that block graph. Now, it turns out that this new aliveness information is almost the same as it was before. So, all the temporary names other than f are not much affected by new statements that are added. And, f itself has changed fairly dramatically. Certainly the old name f is no longer used and so it's like this information goes away and then we've also split f into three, in this case, three different temporaries, one for each of the different uses of f in the control flow graph. And I noticed that each of these new uses of f or these new versions of f is live in a very, very small area. For a load instruction, f is live only between the load and the next instruction where it's used and similarly for a store, f is live only between the store itself and the proceeding instruction, the one they created f . And the effect is to greatly reduce the live range of the spilled variable . So because the live range of f is reduced by spilling, it has fewer interferences in the new program than it did in the old program. And so what that means the particulars in the rebuild register interference graph. f will have fewer neighbors. Some of the neighbors that it had before have gone away because it's live in fewer places. So if we look at the new register interference graph, we can see that among all the different versions of f . Remember that f has been split into three temporaries in this graph. We see that they only interfere with d and c , whereas before f have several other neighbors in the graph. And now, in fact, this new graph is three colorable. Of course, it might be the case that we can't just spill one name. We might have to spill several different temporaries before the coloring is found. And, the tricky part is what to spill. So, this is the hard decision that has to be made during restore allocation. Now any choice is correct. It's only a question of performance so you know some choices of spilling will lead to better code than others but any choice of spilling is going to resolve in a correct program. And there's heuristics that people use to pick which temporaries to spill and here are a few or I think three of the most popular ones. One is to spill the temporaries have the most conflicts. And the reason for that is that the temporary will most affect the number of interferences in the graph. We'll remove enough edges from the graph that they become tolerable with the number of registers we have. Another possibility is spilling temporaries that have few definitions and uses. And, here the idea is that by spilling those since they're not used very much, the number of load and write in storage will have to add, will be relatively small and so if a variable just isn't used in many places, then the actual cost, in terms of additional instructions that are going to be executed to spill it, is relatively small. And another one and this is actually the one that I think that all the compilers implement is to avoid spilling in an inner loops. So, if you have a choice between spilling a variable that's used within innermost loop for the program and one that is used someplace else. It's probably preferred that you spill the one that is used not in the innermost loop absolutely because again, that will result in fewer loads in stores. You really want to avoid adding additional instructions to your inner loop. 16-04 Managing Caches \u00b6 In this lecture, we're going to talk about another very important resource, the cache, and what compilers can and can't do to manage them. Modern computer systems have quite elaborate memory hierarchies. So the bottom line is that it's very important for high performance to manage these resources properly. Particular to manage the registers and the cache as well if you want your program to perform well. Compilers have become very good at managing registers and in fact, I think today, most people would agree that for almost all programs, compilers do a better job at managing registers than programmers can. And so, it's very worthwhile to leave the job of allocating registers or assigning registers to the compiler. However, compilers are not good at managing caches. If programmers want to get good cache performance, they have to understand the behavior of the cache is on the machine and have to understand what their program is doing, you have to understand a little bit about what the compiler is capable of doing and then they still have to write the program in such a way that is going to be cache-friendly. So, it's still very much an open question. How much a compiler can do to improve cache performance? Although, there are a few things that we've found compilers can do reliably. So, to see one of those things that compilers can actually do let's take a look at this example loop. So, we have an outer loop on j and inner loop on i and then in each iteration of the inner loop we're reading from, some vector B , performing some computational and storing the results into the ith element of the vector. Now, as it turns out, this particular program has really, really terrible cache performance. This is going to behave very badly. And so, let's think about what's going to happen. for ( j := 1 ; j < 10 ; j ++ ) for ( i = 1 ; i < 100000 ; i ++ ) a [ i ] *= b [ j ]; The important thing here is that on every iteration of the loop, we're referring to fresh data. And, and if these data values are large enough, if they take up an entire cache line, then each iteration of the loop is going to be a cache miss for both elements, and we won't get any benefit of the cache. And this loop will run at the rate of the main memory and not at the rate of the cache. Now, the other thing that's important here is that this loop bound here is very large and I picked it to be very large to suggest that it's much larger than the size of the cache. So, as we get towards the end of the loop what's going to happen is we will have filled up the whole cache, so this whole cache will be filled with values from a and b, and then it's going to start swapping values that are already in the cache. And if this loop, the size of these vectors is twice the size of the cache, by the time we come around and complete the entire execution of the inner loop, what's in the cache is the second half of the a and b arrays, it's not the first half of the a and b arrays. And so, then when we go back around and execute another iteration of the outer loop, now what's in the cache is also, going to be not the data that we're referencing. And so when we come back and begin the execution of the inner loop the second time, what's in the cache are the values from the high numbered elements of the a and b vector but not the low numbered elements. And so, these references are all misses again. A better version is below. for ( i = 1 ; i < 100000 ; i ++ ) for ( j := 1 ; j < 10 ; j ++ ) a [ i ] *= b [ j ]; Now compilers can perform this simple loop interchange optimization. This particular kind of optimization is called loop interchange , where you just switch in the order of loops. Not many compilers actually implement this optimization because in general, it's not easy to decide whether you can reverse the orders of the loops. 17-01 Automatic Memory Management \u00b6 In this lecture, we're going to start our discussion of garbage collection or automatic memory management. To set the stage, let's first talk about the problem that we're trying to solve. So, if one has to manage memory manually, meaning you have to do all the allocation and deallocation explicitly yourself, that is a hard way to programming leads to certain kinds of bugs that are very difficult to eliminate from programs. So, in particular, these days you see this primarily in C and C++ programs, those are the main languages that are used that have manual memory management and, the kinds of storage bugs that you can get because it has manual memory management are things like forgetting to free unused memory so that's a memory leak, dereferencing dangling pointers, overriding parts of a data structure, unintentionally. And I want to emphasize that these kinds of bugs are often some of the very last bugs to be found in complex systems. They often persist into production and sometimes for a very long time after the code is in production use. And why is that? The reason is that these kinds of bugs, storage bugs, typically have effects that are far away in time and space from the source and so how can that happen? Well let's think about some objects in memory and now let's say for these objects you might have some fields, let's say you have a few fields and I am keeping some pointers to it. So somewhere on the program is a reference to this particular object and now I free it. So I am doing my own memory management like free this object but I forget that I had this pointer. And so now what's happened all the storage has been freed it's no longer really valid memory but the pointer still exist to it. And then when I come along and allocate something else it might allocate the same piece of memory. So this might now be a different kind of object, okay. So I might have a different type here even. This memory might be used for something completely different and that will probably cause my program to crash. So this is a very, very old problem, it's been studied since at least the 1950s. It was first thought about carefully in Lisp. And there are some well-known techniques for completely automatic memory management so you don't have to manage memory yourself. And this only became mainstream actually in the 1990s so with the popularity of Java. The basic strategy in automatic memory management is pretty simple. When an object is created, when we allocate a new object, the run time system will find some unused space for that object and it will just allocate it. So whenever you say new of some class name in Cool. Some memory is automatically allocated by the system, some previously unused memory is automatically allocated by the system for that object. And if you keep doing this over and over and over again and after a while, you're going to run out of space. So eventually there is no more unused space left for additional objects. And at that point, you have to do something, you have to reclaim some of the space in order to allocate more objects and the observation that garbage collection systems rely upon is that some of the spaces being used are probably occupied by objects that will never be used again. So some of these objects are not going to be referred to again by the program and if we can figure out which objects those are then we could deallocate them and reuse the space for new objects. So the big question is, how can we know that an object will never be used again? And, most of the garbage collection techniques that are out there today rely on the following observation that a program can only use the objects that it can find. We're going to say that an object x is reachable if and only if one of the following two things is true. So either a register contains a pointer to x or either the x is reachable immediately from some register. So all the other objects, the ones that you were not able to reach by recursively starting at registers and following pointers as far as you could, those objects can never be used. Reachability is an approximation. x := new A; y := new B x := y; if alwaysTrue() then x := new A else x.foo() fi So let's take a look at another example that illustrates some interesting aspects of reachability and its use in automatic memory management. So what does this example do? The first thing it does is to allocate an A object, on the heap and assigns that to the variable x. So, x is a pointer to that object. And then it allocates a B object and y will point to that object. And then, it assigns the value of y to x, alright. And then we're going to go off and we're going to execute this conditional. And notice that this conditional is going to do. It's going to always be true, alright? So the predicate will always be true so it'll never take the false branch. All it's going to ever do is take the true branch and what's it going to do there, is immediately going to overwrite x. And so x is going to wind up pointing at some other new object. It doesn't matter what it is. And now, let's say that at this point right here, is where we try to do a garbage collection. So you know, for some reason this is the point where the program stops and tries to collect unused memory. And what can it collect? We can see that this object is unreachable, okay. So the first A object becomes unreachable at that point and it can be collected. Now, what about the second object? Well, it is reachable, it's clearly reachable. It's reachable through x, okay at that point and it's also reachable as it happens through y. And so it's not garbage and it's not going to be collected but notice that the x value is always going to be overwritten, okay? So the program, the compiler doesn't know that this branch is always going to be true. So, it doesn't realize that the value that x has at this point won't ever be used again but that value is immediately going to be overwritten, every time we take this conditional. So in fact the B value will never be used again even though it is reachable. And so what this tells you is that reachability is an approximation. And by that I mean it's an approximation for the objects that will never be used again. What we're really interested in when we do garbage collection is collecting objects that will never be used in the future execution of the program. Because obviously that space is wasted and could be put to some other use that might be better and reachability approximates that. So if an object is unreachable it definitely won't be used again however, just because an object is reachable it's not a guarantee that it will be used again. So now let's talk about how we do garbage collection in Cool. So Cool has a fairly simple structure. It uses an accumulator which of course points to an object and that object may point to other objects and so on. So we have to trace all the objects reachable from the accumulator but we also have to worry about the stack pointer so there's also stuff reachable from the stack. And each stack frame of course may contain pointers like, and you know for example the method parameters that are stored on the stack. Each stack frame may also contain some non-pointers, alright? So if I think about the layout of each activation record there would be some mix of pointers and non-pointers. Things like the return address so we have to know the layout of the frame. But if we do know the layout and of course, the compiler is deciding on the layout so it naturally does know the layout, it can find all the pointers in the frame. Essentially, the compiler has to keep a record for each kind of activation record it builds for each method. In Cool, we start tracing from the accumulator and the stack and these are called the roots. 17-03 Stop-and-Copy \u00b6 In this lecture, we are going to look at the second garbage collection technique, stop and copy. In stop-and-copy garbage collection, memory is organized into two areas. The old space is used for allocation and the new space is reserved for the garbage collector. How does it work? \u00b6 In fact, there are some more advanced techniques that allow the program to use more than half of the space, but a fairly significant fraction of the space has to be reversed for the GC. There's a heap pointer in the old space and everything to the left of the heap pointer is currently in use. When it comes to allocating an object, it will just keep marching through the old space. When the old space is full, the program stops, and GC will copy all the reachable objects from the old space to the new space. After that, simply swap the roles of the old and new space, and then the program resumes. how to implement the traversal of the object graph without using any extra space \u00b6 We're going to partition the new space into three contiguous regions. There's a region called the empty region where we're allocating new objects and there's an allocation pointer that points to the beginning of that region. Immediately to the left of that region are the objects that have already been copied, but not scanned. What does that mean? Well, that means that the object has been copied but we haven't yet looked at its pointers inside the object to see where they go. To the left of that are the objects that have been copied and scanned. These are objects that have been copied over and we've also processed all the pointers inside those objects. The area between the scanned pointer and the allocation pointer is the work quest. Alogrithm \u00b6 Example \u00b6 forwarding pointer: a pointer stored in the old version object points to the new copy. step graph 1 2 3 4 5 6 Advantages \u00b6 Very simple and fast for allocation. (just increment the heap pointer) Collection is relatively cheap (mark-and-sweep: O(memory), strop-and-copy: O(reachable objects)) Disadvantage \u00b6 Not suitable for C/C++ because pointer is part of the semantics.","title":"CS143"},{"location":"Compiler/CS143/#14-01-intermediate-language","text":"","title":"14-01 Intermediate language"},{"location":"Compiler/CS143/#what-is-intermediate-language","text":"The intermediate language is a language between the source and the target.","title":"What is Intermediate language?"},{"location":"Compiler/CS143/#why-bother-to-introduce-intermediate-language","text":"Because it provides an intermediate level of abstraction, it has more details than the source. For example, we want to optimize register usage, most source languages have no notion of the register at the source level so there is no way to even express the kinds of optimization you might want to do with registers. It will also have fewer details than the target. For example, the intermediate language is a little bit above the level of the particular instruction set of a particular machine, and therefore, it is easier to retarget that intermediate level of code to lots of different kinds of machines because it doesn't have all the grubby details of a particular machine.","title":"Why bother to introduce Intermediate language?"},{"location":"Compiler/CS143/#14-02-optimization-overview","text":"","title":"14-02 Optimization Overview"},{"location":"Compiler/CS143/#when-should-we-perform-optimizations","text":"In fact, we can perform them on the AST, a big advantage of that is that it's machine-independent, but it turns out AST is too high for a lot of optimizations we want to do because optimizations depend on lower-level details of the machine. Another possibility would be to perform optimizations directly on the assembly language but they are machine-dependent and we would have to reimplement optimizations for each kind of architecture. So intermediate language is an ideal choice.","title":"When should we perform optimizations?"},{"location":"Compiler/CS143/#what-is-the-purpose-of-optimization","text":"The purpose of optimization is to improve a program's resource utilization such as execution time, code size, network messages sent, and so on. For languages like C and Cool, there are three granularities of optimizations. One is called Local optimizations which occur within a single block. Then there're what are called Global optimizations. This is really misnamed because it is not global across the entire program, it's global across an entire function. So global optimizations would apply to a single function and apply to all the basic blocks of that function. And finally, there are inter-procedural optimizations. These are optimizations that work across method boundaries. They take multiple functions and move things around to try to optimize the collection of functions as a whole.","title":"What is the purpose of optimization?"},{"location":"Compiler/CS143/#in-practice-often-a-conscious-decision-is-made-not-to-implement-the-fanciest-optimization-known-why","text":"First, some optimizations are hard to implement for SE. Second, some optimizations are costly in compilation time. Even though the compiling happens offline not part of the running of the program, the programmer still has to wait when the optimizing compiler does its optimizations. Third, some of these optimizations have a low payoff. They might only do it by a small amount. Last, unfortunately, many fancy optimizations are all there! So the goal of optimization is to maximum benefit for minimum cost.","title":"In practice, often a conscious decision is made not to implement the fanciest optimization known, why?"},{"location":"Compiler/CS143/#14-03-local-optimizations","text":"","title":"14-03 Local Optimizations"},{"location":"Compiler/CS143/#algebraic-simplification","text":"","title":"Algebraic Simplification"},{"location":"Compiler/CS143/#some-statements-can--be-deleted","text":"x : = x + 0 ; x : = x * 1 ;","title":"Some statements can  be deleted."},{"location":"Compiler/CS143/#some-statements-can-be-simplified","text":"x : = x * 0 ; => x := 0 ; y : = y ** 2 ; => y := y * y ; z : = z * 8 ; => z := z << 3 ; p : = p * 15 ; => t := p << 4 ; p : = t - p ; For the operator ** , it's probably that's going to wind up in our generated code is a call to some built-in math library which will introduce the function call overhead and some kind of general loop in there. So in a special case where we know the exponent is 2, it's much more efficient to just replace that call to exponentiate by an explicit multiply. Another example is z := z * 8; . If we have a multiplication by a power of 2 , we can replace that with a left bit shift. In fact, it doesn't have to be a power of two if we have a multiplication by some other number, that can be replaced by some combination of shifting and subtractions. I want to point out that these transformations will not result in any kind of speedup because, on modern machines, multiplication is just as fast as any other single instruction.","title":"Some statements can be simplified."},{"location":"Compiler/CS143/#constant-folding","text":"Operations on constants can be computed at compile time. x : = 2 + 2 ; => x := 4 ; if 2 > 0 jump L => jump L ; There is one situation that you should be aware of in which constant folding can be very dangerous. It's something that really illustrates some of the subtleties of program optimization and programming language semantics. Let's consider the scenario where we have two machines, X, Y. Now the compiler is running on machine X, and the compiler is producing code for machine Y, and the code will run on it. This is called cross-compiler(Just considering the embedded system code). The problem comes, if X and Y are different architectures. So let's say we have the instruction a := 1.5 + 3.7; , and you would like to constant fold that down to equal 5.2 . Now the problem is that if you simply execute this as a floating-point operation on X, the roundoff and the pointing number semantics may be slightly different from Y. So on Y you may get something like a:= 5.19; . There might be a small difference in the floating-point result.","title":"constant folding"},{"location":"Compiler/CS143/#eliminate-unreachable-basic-blocks","text":"An unreachable basic block is one that is not the target of any jump or falls through. It will make the code smaller and run faster because of the cache effects to increase the spatial locality.","title":"Eliminate unreachable basic blocks"},{"location":"Compiler/CS143/#why-would-unreachable-basic-blocks-occur","text":"There are several ways in which unreachable code can arise. The most common cause is that the code is actually parameterized with code that is only compiled and used in certain situations. In c, it would be sort of typical to see some code that looks like this: #define DEBUG 0 if ( DEBUG ){ ...} Another case where unreachable code comes up is with libraries. So very frequently, programs are written to use generic libraries that the program might only use a very small part of the interface. But the library might supply hundreds of methods to cover all the situations. But for your program, you might only be using three of those methods and the rest of the methods could potentially be removed from the final binary to make the code smaller. And finally, another way that unreachable basic blocks occur is as the result of other optimizations. So as we can see, optimizations frequently lead to more optimizations. And it could just be through other rearrangements of the compiler to make some redundant BBs removed.","title":"Why would unreachable basic blocks occur?"},{"location":"Compiler/CS143/#some-optimizations-are-simplified-if-each-register-occurs-only-once-on-the-left-hand-side-of-an-assignment","text":"If each register is assigned at most once then some of these optimizations are easier to talk about.","title":"Some optimizations are simplified if each register occurs only once on the left-hand side of an assignment."},{"location":"Compiler/CS143/#common-subexpression-elimination","text":"In SSA and x := is the first use of x in a block. Then when two assignments have the same rhs, they compute the same value. x : = y + z ; ... w : = y + z ; can be replaced by : x : = y + z ; ... w : = x ;","title":"Common subexpression elimination"},{"location":"Compiler/CS143/#copy-propogation","text":"If w := x appears in a block, replace subsequent uses of w with the use of x . b : = z + y ; a : = b ; x : = 2 * a ; can be replaced by: b : = z + y ; a : = b ; x : = 2 * b ; This optimization can only be useful in conjunction with some of other optimizations such as constant folding and dead code elimination.","title":"copy propogation"},{"location":"Compiler/CS143/#sumarry","text":"Each of these optimizations presented actually doesn't make the program run faster at all. They don't make program run slower either, but by themselves, they don't actually make any improvement to the program. But typically, the optimizations will interact , so performing one optimization will enable another. So the way to think about an optimizing compiler is that it has a big bag of tricks(program transformations), when faced with a program to optimize, it is going to rummage around in its bag looking for an optimization that applies to some part of the code. If it finds one, it will do the optimization. And it will repeat it and look back and see if there is another optimization that applies. Then it will just keep doing this until it reaches a point where none of the optimizations it knows can be applied.","title":"Sumarry"},{"location":"Compiler/CS143/#14-04-peephole-optimizations","text":"Let's see a variation on local optimization that applies directly to assembly code called peephole optimization. Peephole optimization in one such technique that peephole stands for a short (usually continuous) sequence of instructions, what optimizer will do is to replace the sequence with another equivalent one(but faster). One example is: move $a $b move $b $a can be replaced by the following code if move $b $a is not the target of a jump. move $a $b Another example is addiu $a $a i ; addiu $a $a j ; can be replaced by the following code addiu $a $a i + j ; Many basic block optimizations can be cast also as peephole optimizations.: addiu $a $b 0 -> move $a $b move $a $a -> Peephole optimizations must be applied repeatedly for maximum effect. In fact, program optimization is grossly misnamed, I think program improvement is a more appropriate term because compilers will just improve the program as much as they can, and there is no guarantee that the best code will be produced.","title":"14-04 Peephole Optimizations"},{"location":"Compiler/CS143/#16-01-register-allocation","text":"","title":"16-01 Register Allocation"},{"location":"Compiler/CS143/#overview","text":"Intermediate code can use an unlimited number of temporaries, this simplifies optimization because they don't have to worry about preserving the right number of registers in the code but it does complicate the final translation into assembly code because we might be using too many temporaries and this is actually a problem in practice. So it's common for intermediate code to use more temporaries than physical registers on the machine. Then the problem is to rewrite the intermediate code to use no more temporaries than physical registers. And we are going to assign multiple temporaries to each register. So we are going to have a many-one mapping from temporaries to registers. How can we actually make a single register hold multiple values? Well, the trick is that it's fine for registers to have local values as long as it only has one value at a time. Let's consider this program: a : = c + d ; e : = a + b ; f : = e - 1 ; Here, I'm assuming that a and e are not used anywhere else and so it turns out that a, e, and f could all actually live in the same register. Alright, that's assuming that a and e are dead after their uses. And what will that look like, well let's allocate them all to a particular register r1 and let's assign c , d , and b into their own individual registers and the code would like this: r1 : = r2 + r3 ; r1 : = r1 + r4 ; r1 : = r1 - 1 ; And so now notice this is just a translation of the code over here into registers but there is a many one mapping of names above to register names below.","title":"Overview"},{"location":"Compiler/CS143/#history","text":"A register allocation is an old problem. In fact, it was first recognized way back in the 1950s in the original Fortran project but originally, register allocation was done with a fairly crude algorithm, and someone rapidly or very quickly noticed that was actually a bottleneck in the quality of code generation that actually limitations on the ability of register allocation have a really significant effect on the overall quality of the code that compilers could produce. And then about 30 years later, in 1980, a breakthrough occurred where a group of researchers at IBM discovered a register allocation scheme based on graph coloring. And the great thing about this scheme is that it's pretty simple. It's easy to explain. It's global, meaning it takes advantage of information from the entire control flow graph at the same time and also happens to work well in practice.","title":"History"},{"location":"Compiler/CS143/#register-interface-graphrig","text":"And here's the basic principle that underlies the modern register allocation algorithms. So, if I have two temporaries t1 and t2 , I want to know when they can share register. So, they're allowed to share a register if they are not live at the same time. Let's take a look at a control flow graph and now, we know that in order to do the register allocation to solve the register allocation at least in this in this way, we're going to need liveness information. Well, we're going to construct an undirected graph and in this graph, there will be a node for each temporary so each variable will have a node in the graph and there'll be an edge between two temporaries if they are live simultaneously at some point in the program. This is the graph (RIG) constructed from the code and the line analysis above, it's easy to read off from the graph what the constraints are. So, for example, b and c cannot be in the same register because b and c are connected by an edge, which means they're live simultaneously at some part, some point in the program and so they have to live in different registers. On the other hand, there is at, there is no edge between b and d. So, this edge is missing, and therefore, it's possible that b and d could be allocated in the same register. So a great thing about the register interference graph (RIG) is that it extracts exactly the information needed to characterize a legal register assignment. So, it gives us a representation of all the possible legal register assignments. Now, we haven't actually gotten a register assignment out of the register interference graph, but the first step is to characterize the problem in some kind of precise way. The other thing that is good about is a global view of the register requirements meaning it's over the entire control flow graphs. So, takes into account information from every part of the control flow graph which will help us to make good global decisions about what value is very important to live in registers. And finally, the other thing to notice is that, after reconstruction, the register allocation for the algorithm is architecture-independent.","title":"register interface graph(RIG)"},{"location":"Compiler/CS143/#16-02-graph-coloring","text":"A graph coloring is an assignment of colors to nodes such that the nodes connected by an edge have different colors. And then the graph is k-colorable if it has a coloring that uses k or fewer colors. In our problem, the colors correspond to registers so we want to do is to assign colors or registers to the graph nodes. And we're going to let k, the number, the maximum number of colors we're allowed to use be the number of machine registers.","title":"16-02 Graph Coloring"},{"location":"Compiler/CS143/#algorithm","text":"Step1 Pick a node t with fewer than k neighbors in RIG Eliminate t and its edges from RIG If the resulting graph is k-colorable, then so is the original graph Step2: Assign colors to nodes on the stack Start with the last node added At each step pick a color different from those assigned to already colored neighbors","title":"Algorithm"},{"location":"Compiler/CS143/#16-03-spilling","text":"In this lecture, we are going to continue our discussion of register allocation, and this time we are going to talk about what happens when we can't successfully color the graph, in which case we have to do something known as spilling. The graph coloring algorithm that we discussed in the previous last doesn't always succeed in coloring an arbitrary graph. And it may well get stuck and not be able to find a coloring. And so in that case the only conclusion we can reach is that we can't hold all the values to register. And those temporary values have to live somewhere so where should they live? Well, they're going to have to live in memory. That's the only other kind of story that we have. And so we're going to pick some values and spill them into memory. The ideas that we have, the picture in your mind should be a bucket and it can hold a fixed amount of stuff, those are the registers and when it gets too full, some of the stuff spills over, and ends up someplace else. Now, when does the graph coloring do get stuck? Well, the only situation in which we won't be able to make progress is all the nodes have k or more neighbors. Given that the machine we want to use only has three registers and so we, instead of finding a 4-coloring of this graph, we need to find a 3-coloring. So let's think about how to find the three coloring of this graph. If we apply the heuristic, we'll remove A from the graph but then we're going to get stuck. Because once you take A out of the graph and its edge is out and every node left has three or more neighbors as at least three neighbors. So, there's no node that we can delete from the graph and be guaranteed to be able to find the coloring for it with the heuristic that we discussed in the previous lecture. So, in this situation, what we're going to do is we're going to pick and know that there is a candidate for spilling. This is a node that we think we may have to assign into a memory location rather than to our register. Let's assume for the sake of this example that we pick f and we're going to spill f . Now we have to try to assign a color to f and it could be, we could get lucky and discover that even though f had more than there neighbors or three or more neighbors when we remove it from the graph, it could be that when we go to construct the coloring for the subgraph that those neighbors actually don't use all of the registers. And so, this is called optimistic coloring . So we pick a candidate for spilling. We tried to color the subgraph. Once we have a coloring for the sub-graph, now we see if we just get lucky are able to assign a register to f in which case we can just go ahead and continue the color of the rest of the graph as if nothing had happened. So in this case let's take a look at what happens. We're going to add f back into the graph. And in this case, optimistic coloring will not work so, in fact, f had more than K neighbors and after we color the sub-graph, it turns out that those neighbors are using all K. And so there is no register leftover for f and we're going to have to actually spill it and store it in memory. So, if optimistic coloring fails as it does in this example, then we spill f . So, what we're going to do is allocate the memory location for f and typically, what that means is that we'll allocate a position in the current stack frame. Let's call this address fa for the address of f . And then we're going to modify the control flow graph. We're going to change the code for that compiling. So, before each operation that reads f , we're going to insert a load that loads from that address to the current value of f into a temporary name. And similarly, after each operation that writes f , we're going to insert the store so we're going to save the current value of f into its location in memory. So, here is the original code from which we constructed the registry interference graph and notice that there are few references to f in here and we just highlight them, alright. So, here we had the use of f , the read of f in this statement and now we preceded that by a load. And notice that I've given a new name here I've called f1 , that's because the different uses of f in the control flow graph don't all have to have the same temporary name and actually, it would be a good idea to separate them so each distinct to use of f will get its own name. So here we load the value of f and then it gets to use in the statement. Here we have a write to f and so we store the current value of f to a different name f2 . And finally, the third use of f there's another load of f right here which is then used in this computation here of b . Okay. So, that is the systematic way to modify the code to use f in storage. And now, we have to recompute the aliveness of f . And so, whathappens there? Well, here is the original aliveness information from which we computed the register interference graph, okay. And now notice that f is gone. We no longer use f in the programs so we can delete all the places where we mentioned that f was live and now we have the three new names, f1 , f2 , and f3 . And we have to add in their aliveness information so it creates a new program where we inserted statements. And of course, where we have a load of the current value of f lives right before the use in the next statement. Here, we have the right of the current value of f and that's live right before the store, and then here's another load of the current value of f which is live until the use in the next statement. Okay. And so, now notice here that f used to be live in many places in the code. And now not only is f of the different versions in fewer places also we've distinguished them. So, it actually separates the different uses of f and so this will have their own nodes in their own set of interferences in the graph and they won't share them with the other users of f and that will actually also reduce the number of edges in the graph. To summarize the example above, once we have decided that we are actually going to spill a temporary f , that means we're going to change the program where have loads and stores to the program and now we're going to have a different program and that's going to change our register allocation problems. We're going to have to recompute the aliveness of information, we have to rebuild the restrain interference graph and then we're going to have to try again to color that block graph. Now, it turns out that this new aliveness information is almost the same as it was before. So, all the temporary names other than f are not much affected by new statements that are added. And, f itself has changed fairly dramatically. Certainly the old name f is no longer used and so it's like this information goes away and then we've also split f into three, in this case, three different temporaries, one for each of the different uses of f in the control flow graph. And I noticed that each of these new uses of f or these new versions of f is live in a very, very small area. For a load instruction, f is live only between the load and the next instruction where it's used and similarly for a store, f is live only between the store itself and the proceeding instruction, the one they created f . And the effect is to greatly reduce the live range of the spilled variable . So because the live range of f is reduced by spilling, it has fewer interferences in the new program than it did in the old program. And so what that means the particulars in the rebuild register interference graph. f will have fewer neighbors. Some of the neighbors that it had before have gone away because it's live in fewer places. So if we look at the new register interference graph, we can see that among all the different versions of f . Remember that f has been split into three temporaries in this graph. We see that they only interfere with d and c , whereas before f have several other neighbors in the graph. And now, in fact, this new graph is three colorable. Of course, it might be the case that we can't just spill one name. We might have to spill several different temporaries before the coloring is found. And, the tricky part is what to spill. So, this is the hard decision that has to be made during restore allocation. Now any choice is correct. It's only a question of performance so you know some choices of spilling will lead to better code than others but any choice of spilling is going to resolve in a correct program. And there's heuristics that people use to pick which temporaries to spill and here are a few or I think three of the most popular ones. One is to spill the temporaries have the most conflicts. And the reason for that is that the temporary will most affect the number of interferences in the graph. We'll remove enough edges from the graph that they become tolerable with the number of registers we have. Another possibility is spilling temporaries that have few definitions and uses. And, here the idea is that by spilling those since they're not used very much, the number of load and write in storage will have to add, will be relatively small and so if a variable just isn't used in many places, then the actual cost, in terms of additional instructions that are going to be executed to spill it, is relatively small. And another one and this is actually the one that I think that all the compilers implement is to avoid spilling in an inner loops. So, if you have a choice between spilling a variable that's used within innermost loop for the program and one that is used someplace else. It's probably preferred that you spill the one that is used not in the innermost loop absolutely because again, that will result in fewer loads in stores. You really want to avoid adding additional instructions to your inner loop.","title":"16-03 Spilling"},{"location":"Compiler/CS143/#16-04-managing-caches","text":"In this lecture, we're going to talk about another very important resource, the cache, and what compilers can and can't do to manage them. Modern computer systems have quite elaborate memory hierarchies. So the bottom line is that it's very important for high performance to manage these resources properly. Particular to manage the registers and the cache as well if you want your program to perform well. Compilers have become very good at managing registers and in fact, I think today, most people would agree that for almost all programs, compilers do a better job at managing registers than programmers can. And so, it's very worthwhile to leave the job of allocating registers or assigning registers to the compiler. However, compilers are not good at managing caches. If programmers want to get good cache performance, they have to understand the behavior of the cache is on the machine and have to understand what their program is doing, you have to understand a little bit about what the compiler is capable of doing and then they still have to write the program in such a way that is going to be cache-friendly. So, it's still very much an open question. How much a compiler can do to improve cache performance? Although, there are a few things that we've found compilers can do reliably. So, to see one of those things that compilers can actually do let's take a look at this example loop. So, we have an outer loop on j and inner loop on i and then in each iteration of the inner loop we're reading from, some vector B , performing some computational and storing the results into the ith element of the vector. Now, as it turns out, this particular program has really, really terrible cache performance. This is going to behave very badly. And so, let's think about what's going to happen. for ( j := 1 ; j < 10 ; j ++ ) for ( i = 1 ; i < 100000 ; i ++ ) a [ i ] *= b [ j ]; The important thing here is that on every iteration of the loop, we're referring to fresh data. And, and if these data values are large enough, if they take up an entire cache line, then each iteration of the loop is going to be a cache miss for both elements, and we won't get any benefit of the cache. And this loop will run at the rate of the main memory and not at the rate of the cache. Now, the other thing that's important here is that this loop bound here is very large and I picked it to be very large to suggest that it's much larger than the size of the cache. So, as we get towards the end of the loop what's going to happen is we will have filled up the whole cache, so this whole cache will be filled with values from a and b, and then it's going to start swapping values that are already in the cache. And if this loop, the size of these vectors is twice the size of the cache, by the time we come around and complete the entire execution of the inner loop, what's in the cache is the second half of the a and b arrays, it's not the first half of the a and b arrays. And so, then when we go back around and execute another iteration of the outer loop, now what's in the cache is also, going to be not the data that we're referencing. And so when we come back and begin the execution of the inner loop the second time, what's in the cache are the values from the high numbered elements of the a and b vector but not the low numbered elements. And so, these references are all misses again. A better version is below. for ( i = 1 ; i < 100000 ; i ++ ) for ( j := 1 ; j < 10 ; j ++ ) a [ i ] *= b [ j ]; Now compilers can perform this simple loop interchange optimization. This particular kind of optimization is called loop interchange , where you just switch in the order of loops. Not many compilers actually implement this optimization because in general, it's not easy to decide whether you can reverse the orders of the loops.","title":"16-04 Managing Caches"},{"location":"Compiler/CS143/#17-01-automatic-memory-management","text":"In this lecture, we're going to start our discussion of garbage collection or automatic memory management. To set the stage, let's first talk about the problem that we're trying to solve. So, if one has to manage memory manually, meaning you have to do all the allocation and deallocation explicitly yourself, that is a hard way to programming leads to certain kinds of bugs that are very difficult to eliminate from programs. So, in particular, these days you see this primarily in C and C++ programs, those are the main languages that are used that have manual memory management and, the kinds of storage bugs that you can get because it has manual memory management are things like forgetting to free unused memory so that's a memory leak, dereferencing dangling pointers, overriding parts of a data structure, unintentionally. And I want to emphasize that these kinds of bugs are often some of the very last bugs to be found in complex systems. They often persist into production and sometimes for a very long time after the code is in production use. And why is that? The reason is that these kinds of bugs, storage bugs, typically have effects that are far away in time and space from the source and so how can that happen? Well let's think about some objects in memory and now let's say for these objects you might have some fields, let's say you have a few fields and I am keeping some pointers to it. So somewhere on the program is a reference to this particular object and now I free it. So I am doing my own memory management like free this object but I forget that I had this pointer. And so now what's happened all the storage has been freed it's no longer really valid memory but the pointer still exist to it. And then when I come along and allocate something else it might allocate the same piece of memory. So this might now be a different kind of object, okay. So I might have a different type here even. This memory might be used for something completely different and that will probably cause my program to crash. So this is a very, very old problem, it's been studied since at least the 1950s. It was first thought about carefully in Lisp. And there are some well-known techniques for completely automatic memory management so you don't have to manage memory yourself. And this only became mainstream actually in the 1990s so with the popularity of Java. The basic strategy in automatic memory management is pretty simple. When an object is created, when we allocate a new object, the run time system will find some unused space for that object and it will just allocate it. So whenever you say new of some class name in Cool. Some memory is automatically allocated by the system, some previously unused memory is automatically allocated by the system for that object. And if you keep doing this over and over and over again and after a while, you're going to run out of space. So eventually there is no more unused space left for additional objects. And at that point, you have to do something, you have to reclaim some of the space in order to allocate more objects and the observation that garbage collection systems rely upon is that some of the spaces being used are probably occupied by objects that will never be used again. So some of these objects are not going to be referred to again by the program and if we can figure out which objects those are then we could deallocate them and reuse the space for new objects. So the big question is, how can we know that an object will never be used again? And, most of the garbage collection techniques that are out there today rely on the following observation that a program can only use the objects that it can find. We're going to say that an object x is reachable if and only if one of the following two things is true. So either a register contains a pointer to x or either the x is reachable immediately from some register. So all the other objects, the ones that you were not able to reach by recursively starting at registers and following pointers as far as you could, those objects can never be used. Reachability is an approximation. x := new A; y := new B x := y; if alwaysTrue() then x := new A else x.foo() fi So let's take a look at another example that illustrates some interesting aspects of reachability and its use in automatic memory management. So what does this example do? The first thing it does is to allocate an A object, on the heap and assigns that to the variable x. So, x is a pointer to that object. And then it allocates a B object and y will point to that object. And then, it assigns the value of y to x, alright. And then we're going to go off and we're going to execute this conditional. And notice that this conditional is going to do. It's going to always be true, alright? So the predicate will always be true so it'll never take the false branch. All it's going to ever do is take the true branch and what's it going to do there, is immediately going to overwrite x. And so x is going to wind up pointing at some other new object. It doesn't matter what it is. And now, let's say that at this point right here, is where we try to do a garbage collection. So you know, for some reason this is the point where the program stops and tries to collect unused memory. And what can it collect? We can see that this object is unreachable, okay. So the first A object becomes unreachable at that point and it can be collected. Now, what about the second object? Well, it is reachable, it's clearly reachable. It's reachable through x, okay at that point and it's also reachable as it happens through y. And so it's not garbage and it's not going to be collected but notice that the x value is always going to be overwritten, okay? So the program, the compiler doesn't know that this branch is always going to be true. So, it doesn't realize that the value that x has at this point won't ever be used again but that value is immediately going to be overwritten, every time we take this conditional. So in fact the B value will never be used again even though it is reachable. And so what this tells you is that reachability is an approximation. And by that I mean it's an approximation for the objects that will never be used again. What we're really interested in when we do garbage collection is collecting objects that will never be used in the future execution of the program. Because obviously that space is wasted and could be put to some other use that might be better and reachability approximates that. So if an object is unreachable it definitely won't be used again however, just because an object is reachable it's not a guarantee that it will be used again. So now let's talk about how we do garbage collection in Cool. So Cool has a fairly simple structure. It uses an accumulator which of course points to an object and that object may point to other objects and so on. So we have to trace all the objects reachable from the accumulator but we also have to worry about the stack pointer so there's also stuff reachable from the stack. And each stack frame of course may contain pointers like, and you know for example the method parameters that are stored on the stack. Each stack frame may also contain some non-pointers, alright? So if I think about the layout of each activation record there would be some mix of pointers and non-pointers. Things like the return address so we have to know the layout of the frame. But if we do know the layout and of course, the compiler is deciding on the layout so it naturally does know the layout, it can find all the pointers in the frame. Essentially, the compiler has to keep a record for each kind of activation record it builds for each method. In Cool, we start tracing from the accumulator and the stack and these are called the roots.","title":"17-01 Automatic Memory Management"},{"location":"Compiler/CS143/#17-03-stop-and-copy","text":"In this lecture, we are going to look at the second garbage collection technique, stop and copy. In stop-and-copy garbage collection, memory is organized into two areas. The old space is used for allocation and the new space is reserved for the garbage collector.","title":"17-03 Stop-and-Copy"},{"location":"Compiler/CS143/#how-does-it-work","text":"In fact, there are some more advanced techniques that allow the program to use more than half of the space, but a fairly significant fraction of the space has to be reversed for the GC. There's a heap pointer in the old space and everything to the left of the heap pointer is currently in use. When it comes to allocating an object, it will just keep marching through the old space. When the old space is full, the program stops, and GC will copy all the reachable objects from the old space to the new space. After that, simply swap the roles of the old and new space, and then the program resumes.","title":"How does it work?"},{"location":"Compiler/CS143/#how-to-implement-the-traversal-of-the-object-graph-without-using-any-extra-space","text":"We're going to partition the new space into three contiguous regions. There's a region called the empty region where we're allocating new objects and there's an allocation pointer that points to the beginning of that region. Immediately to the left of that region are the objects that have already been copied, but not scanned. What does that mean? Well, that means that the object has been copied but we haven't yet looked at its pointers inside the object to see where they go. To the left of that are the objects that have been copied and scanned. These are objects that have been copied over and we've also processed all the pointers inside those objects. The area between the scanned pointer and the allocation pointer is the work quest.","title":"how to implement the traversal of the object graph without using any extra space"},{"location":"Compiler/CS143/#alogrithm","text":"","title":"Alogrithm"},{"location":"Compiler/CS143/#example","text":"forwarding pointer: a pointer stored in the old version object points to the new copy. step graph 1 2 3 4 5 6","title":"Example"},{"location":"Compiler/CS143/#advantages","text":"Very simple and fast for allocation. (just increment the heap pointer) Collection is relatively cheap (mark-and-sweep: O(memory), strop-and-copy: O(reachable objects))","title":"Advantages"},{"location":"Compiler/CS143/#disadvantage","text":"Not suitable for C/C++ because pointer is part of the semantics.","title":"Disadvantage"},{"location":"Compiler/CMU15411%20cmu_compiler_design/","text":"cmu_compiler_design \u00b6","title":"cmu_compiler_design"},{"location":"Compiler/CMU15411%20cmu_compiler_design/#cmu_compiler_design","text":"","title":"cmu_compiler_design"},{"location":"Compiler/CMU15745%20OptimizingCompiler/","text":"OptimizingCompiler \u00b6 CMU 15745 with Xian Zhang This project contains three kinds of optimization passes written using LLVM framework for CMU 15745 with Xian Zhang. In order to make the dataflow analysis work, we implemented a dataflow analysis framework using LLVM framework under dataflowOpt folder. The three kinds of optimizations include: (1) Scalar Optimization: algebraic identities, constant folding, strength reduction (2) Dataflow Optimization: deadcode elimination, liveness analysis, common subexpression elimination (3) Loop Optimization: loop invariant code motion","title":"OptimizingCompiler"},{"location":"Compiler/CMU15745%20OptimizingCompiler/#optimizingcompiler","text":"CMU 15745 with Xian Zhang This project contains three kinds of optimization passes written using LLVM framework for CMU 15745 with Xian Zhang. In order to make the dataflow analysis work, we implemented a dataflow analysis framework using LLVM framework under dataflowOpt folder. The three kinds of optimizations include: (1) Scalar Optimization: algebraic identities, constant folding, strength reduction (2) Dataflow Optimization: deadcode elimination, liveness analysis, common subexpression elimination (3) Loop Optimization: loop invariant code motion","title":"OptimizingCompiler"},{"location":"Compiler/CS143/labs/","text":"Cool \u00b6 This repo contains my study resources from CS143. Cool is a tiny compiler. Enjoy it and have fun.","title":"Cool"},{"location":"Compiler/CS143/labs/#cool","text":"This repo contains my study resources from CS143. Cool is a tiny compiler. Enjoy it and have fun.","title":"Cool"},{"location":"Compiler/CS143/labs/assignments/PA3/","text":"first we need to install bison sudo apt-get install -y bison GNU bison GNU Bison, commonly known as Bison, is a parser generator that is part of the GNU Project. Bison reads a specification in the BNF notation (a context-free language),warns about any parsing ambiguities, and generates a parser that reads sequences of tokens and decides whether the sequence conforms to the syntax specified by the grammar. 3. class hierarchy tree_node Program_class //typedef Program_class *Program; program_class Case_class //typedef Case_class *Case; branch_class Class__class //typedef Class__class Class_; //typedef list_node Classes class__class Expression_class //typedef Expression_class *Expression; assign_class block_class bool_const_class comp_class conn_class dispatch_class divide_class eq_class int_const_class isvoid_class leq_class let_class loop_class lt_class mul_class neg_class new__class no_expr_class object_class plus_class static_dispatch_class string_const_class sub_class typecase_class Feature_class // typedef Feature_class *Feature; attr_class methopd_class Formal_class // typedef Formal_class *Formal; formal_class Entry IdEntry IntEntry StringEntry how to write let grammar?","title":"Index"},{"location":"Courses/CSCD70/","text":"Loops \u00b6 Definitions \u00b6 Dominator \u00b6 Node d {==dominates==} node n in agraph (d dom n) if every path from the start node to n goes through d. Dominators can be organized as a tree. Natural loops \u00b6 A header dominates all nodes in the loop, and a back edge is an arc whose head dominates its tail. (tail -> head) The natural loop of a back edge is the smallest set of nodes that includes the head and tail of the back edge, and has no predecessors outside the set, except for the predecessors of the header. Algorithm to find Natural Loops \u00b6 Finding Dominators \u00b6 Use dataflow analysis framework to find Dominators. Direction forward Values Basic blocks Meet operator $\\cap$ Top all BBs Bottom Empty set Boundary condition $OUT(E) = E$ Initialization for internal nodes $OUT(BB) = T$ Transfer function $f(b) = {b} \\cup (\\cap_{p = pre(b)}OUT[p])$ Finding Back Edges \u00b6 Traverse edges in a depth-first search of the flow graph form a depth-first spanning tree. Then we categorize edges in graph into : - Advancing (A) edges: from ancestor to proper descendant - Cross (C) edges: from right to left - Retreating (R) edges: from descendant to ancestor (not necessarily proper) Then for each retreating edge t->h, we will check if h is in t's dominator list. Constructing Natural Loops \u00b6 The natural loop of a back edge is the smallest set of nodes that includes the head and tail of the back edge, and has no predecessors outside the set, except for the predecessors of the header. Algorithm \u00b6 delete h from the flow graph find those nodes that can reach t Preheader \u00b6 Optimizations often require code to be executed once before the loop. So Create a preheader basic block for every loop. From an optimization perspective, not every cycle is a loop. Static Single Assignment (SSA) \u00b6 What is SSA? \u00b6 {==Static single assignment==} is an IR where every variable is assigned a value at most once in the program text. $\\Phi$ merges multiple definitions along multiple control paths into a single definition. How do we choose which $x_i$ to use? \u00b6 In fact, we don't really care, because we just need to use mov on each incoming edge. Why SSA? \u00b6 SSA form makes use-def chains explicit in the IR, which in turn helps to simplify some optimizations. How to convert to SSA? \u00b6 In fact, we can directly insert $\\Phi$ functions for all live variables at each join point, but this is too costly, because there may be too many useless $\\Phi$ functions inserted. See example below, $x_2 = \\Phi(x_1,x_1)$ is totally useless and should be deleted. So how to get the minimal SSA? Algorithm Place all $\\Phi$. Rename all variables. When Do We Insert $\\Phi$? \u00b6","title":"CSCD70"},{"location":"Courses/CSCD70/#loops","text":"","title":"Loops"},{"location":"Courses/CSCD70/#definitions","text":"","title":"Definitions"},{"location":"Courses/CSCD70/#dominator","text":"Node d {==dominates==} node n in agraph (d dom n) if every path from the start node to n goes through d. Dominators can be organized as a tree.","title":"Dominator"},{"location":"Courses/CSCD70/#natural-loops","text":"A header dominates all nodes in the loop, and a back edge is an arc whose head dominates its tail. (tail -> head) The natural loop of a back edge is the smallest set of nodes that includes the head and tail of the back edge, and has no predecessors outside the set, except for the predecessors of the header.","title":"Natural loops"},{"location":"Courses/CSCD70/#algorithm-to-find-natural-loops","text":"","title":"Algorithm to find Natural Loops"},{"location":"Courses/CSCD70/#finding-dominators","text":"Use dataflow analysis framework to find Dominators. Direction forward Values Basic blocks Meet operator $\\cap$ Top all BBs Bottom Empty set Boundary condition $OUT(E) = E$ Initialization for internal nodes $OUT(BB) = T$ Transfer function $f(b) = {b} \\cup (\\cap_{p = pre(b)}OUT[p])$","title":"Finding Dominators"},{"location":"Courses/CSCD70/#finding-back-edges","text":"Traverse edges in a depth-first search of the flow graph form a depth-first spanning tree. Then we categorize edges in graph into : - Advancing (A) edges: from ancestor to proper descendant - Cross (C) edges: from right to left - Retreating (R) edges: from descendant to ancestor (not necessarily proper) Then for each retreating edge t->h, we will check if h is in t's dominator list.","title":"Finding Back Edges"},{"location":"Courses/CSCD70/#constructing-natural-loops","text":"The natural loop of a back edge is the smallest set of nodes that includes the head and tail of the back edge, and has no predecessors outside the set, except for the predecessors of the header.","title":"Constructing Natural Loops"},{"location":"Courses/CSCD70/#algorithm","text":"delete h from the flow graph find those nodes that can reach t","title":"Algorithm"},{"location":"Courses/CSCD70/#preheader","text":"Optimizations often require code to be executed once before the loop. So Create a preheader basic block for every loop. From an optimization perspective, not every cycle is a loop.","title":"Preheader"},{"location":"Courses/CSCD70/#static-single-assignment-ssa","text":"","title":"Static Single Assignment (SSA)"},{"location":"Courses/CSCD70/#what-is-ssa","text":"{==Static single assignment==} is an IR where every variable is assigned a value at most once in the program text. $\\Phi$ merges multiple definitions along multiple control paths into a single definition.","title":"What is SSA?"},{"location":"Courses/CSCD70/#how-do-we-choose-which-x_i-to-use","text":"In fact, we don't really care, because we just need to use mov on each incoming edge.","title":"How do we choose which $x_i$ to use?"},{"location":"Courses/CSCD70/#why-ssa","text":"SSA form makes use-def chains explicit in the IR, which in turn helps to simplify some optimizations.","title":"Why SSA?"},{"location":"Courses/CSCD70/#how-to-convert-to-ssa","text":"In fact, we can directly insert $\\Phi$ functions for all live variables at each join point, but this is too costly, because there may be too many useless $\\Phi$ functions inserted. See example below, $x_2 = \\Phi(x_1,x_1)$ is totally useless and should be deleted. So how to get the minimal SSA? Algorithm Place all $\\Phi$. Rename all variables.","title":"How to convert to SSA?"},{"location":"Courses/CSCD70/#when-do-we-insert-phi","text":"","title":"When Do We Insert $\\Phi$?"},{"location":"DeducingTypes/item2/","text":"Understand auto type deduction \u00b6 \u5f53\u4e00\u4e2a\u53d8\u91cf\u4f7f\u7528 auto \u8fdb\u884c\u58f0\u660e\u7684\u65f6\u5019\uff0c auto \u626e\u6f14\u4e86\u6a21\u7248\u4e2d\u7684 T \u7684\u89d2\u8272\uff0c\u53d8\u91cf\u7684\u7c7b\u578b\u8bf4\u660e\u7b26\u626e\u6f14\u4e86 ParamType \u7684\u89d2\u8272\u3002\u4f46\u662f\u6709\u4e00\u4e2a\u4e0d\u592a\u4e00\u6837\uff0c\u90a3\u5c31\u662f\u5f53 auto \u58f0\u660e\u7684\u53d8\u91cf\u4f7f\u7528\u82b1\u62ec\u53f7\u8fdb\u884c\u521d\u59cb\u5316\u7684\u65f6\u5019\uff0c auto \u7c7b\u578b\u63a8\u5bfc\u63a8\u51fa\u7684\u7c7b\u578b\u5219\u4e3a std::initializer_list \uff0c\u8fd9\u79cd\u60c5\u51b5\u5c06\u5728\u6700\u540e\u8ba8\u8bba\u3002 \u6211\u4eec\u5c06\u4ece\u4e0b\u9762\u51e0\u4e2a\u65b9\u9762\u6765\u63a2\u8ba8 auto \u4f5c\u4e3a\u7c7b\u578b\u8bf4\u660e\u7b26( ParamType )\u7684\u53d8\u91cf\u58f0\u660e\u7684\u60c5\u51b5\u3002 \u7c7b\u578b\u8bf4\u660e\u7b26\u662f\u4e00\u4e2a\u6307\u9488\u6216\u8005\u5f15\u7528 int x = 23 ; const auto & rx = x ; // rx \u7684\u7c7b\u578b\u662fconst int& \u7c7b\u578b\u8bf4\u660e\u7b26\u65e2\u4e0d\u662f\u6307\u9488\u4e5f\u4e0d\u662f\u5f15\u7528 auto x = 2 ; // x \u7684\u7c7b\u578b\u662fint \u7c7b\u578b\u8bf4\u660e\u7b26\u662f\u4e00\u4e2a\u901a\u7528\u5f15\u7528 auto x = 27 ; const auto cx = x ; auto && uref1 = x ; //x\u662fint\u5de6\u503c\uff0c //\u6240\u4ee5uref1\u7c7b\u578b\u4e3aint& auto && uref2 = cx ; //cx\u662fconst int\u5de6\u503c\uff0c //\u6240\u4ee5uref2\u7c7b\u578b\u4e3aconst int& auto && uref3 = 27 ; //27\u662fint\u53f3\u503c\uff0c //\u6240\u4ee5uref3\u7c7b\u578b\u4e3aint&& uniform initialization int x1 { 12 }; int x2 = { 12 }; C++11 \u6dfb\u52a0\u4e86\u7528\u4e8e\u652f\u6301\u7edf\u4e00\u521d\u59cb\u5316(uniform initilization)\u7684\u8bed\u6cd5 {}","title":"Item2"},{"location":"DeducingTypes/item2/#understand-auto-type-deduction","text":"\u5f53\u4e00\u4e2a\u53d8\u91cf\u4f7f\u7528 auto \u8fdb\u884c\u58f0\u660e\u7684\u65f6\u5019\uff0c auto \u626e\u6f14\u4e86\u6a21\u7248\u4e2d\u7684 T \u7684\u89d2\u8272\uff0c\u53d8\u91cf\u7684\u7c7b\u578b\u8bf4\u660e\u7b26\u626e\u6f14\u4e86 ParamType \u7684\u89d2\u8272\u3002\u4f46\u662f\u6709\u4e00\u4e2a\u4e0d\u592a\u4e00\u6837\uff0c\u90a3\u5c31\u662f\u5f53 auto \u58f0\u660e\u7684\u53d8\u91cf\u4f7f\u7528\u82b1\u62ec\u53f7\u8fdb\u884c\u521d\u59cb\u5316\u7684\u65f6\u5019\uff0c auto \u7c7b\u578b\u63a8\u5bfc\u63a8\u51fa\u7684\u7c7b\u578b\u5219\u4e3a std::initializer_list \uff0c\u8fd9\u79cd\u60c5\u51b5\u5c06\u5728\u6700\u540e\u8ba8\u8bba\u3002 \u6211\u4eec\u5c06\u4ece\u4e0b\u9762\u51e0\u4e2a\u65b9\u9762\u6765\u63a2\u8ba8 auto \u4f5c\u4e3a\u7c7b\u578b\u8bf4\u660e\u7b26( ParamType )\u7684\u53d8\u91cf\u58f0\u660e\u7684\u60c5\u51b5\u3002 \u7c7b\u578b\u8bf4\u660e\u7b26\u662f\u4e00\u4e2a\u6307\u9488\u6216\u8005\u5f15\u7528 int x = 23 ; const auto & rx = x ; // rx \u7684\u7c7b\u578b\u662fconst int& \u7c7b\u578b\u8bf4\u660e\u7b26\u65e2\u4e0d\u662f\u6307\u9488\u4e5f\u4e0d\u662f\u5f15\u7528 auto x = 2 ; // x \u7684\u7c7b\u578b\u662fint \u7c7b\u578b\u8bf4\u660e\u7b26\u662f\u4e00\u4e2a\u901a\u7528\u5f15\u7528 auto x = 27 ; const auto cx = x ; auto && uref1 = x ; //x\u662fint\u5de6\u503c\uff0c //\u6240\u4ee5uref1\u7c7b\u578b\u4e3aint& auto && uref2 = cx ; //cx\u662fconst int\u5de6\u503c\uff0c //\u6240\u4ee5uref2\u7c7b\u578b\u4e3aconst int& auto && uref3 = 27 ; //27\u662fint\u53f3\u503c\uff0c //\u6240\u4ee5uref3\u7c7b\u578b\u4e3aint&& uniform initialization int x1 { 12 }; int x2 = { 12 }; C++11 \u6dfb\u52a0\u4e86\u7528\u4e8e\u652f\u6301\u7edf\u4e00\u521d\u59cb\u5316(uniform initilization)\u7684\u8bed\u6cd5 {}","title":"Understand auto type deduction"},{"location":"Distributed%20Systems/","text":"All materials come from the course @Cambridge. You can visit the course by the website https://www.cl.cam.ac.uk/teaching/2021/ConcDisSys/materials.html","title":"Index"},{"location":"Distributed%20Systems/Broadcast%20protocols%20and%20logical%20time/Broadcast%20protocols%20and%20logical%20time/","text":"logical vs. physical clocks It cannot be guranteened by the physical time that if a->b, time(a) is less than time(b). Logical clocks focus on correctly capturing the order of events in a distributed system. Lamport clocks algorithm Using Lamport timestamps we can extend this partial order into a total order. vector clocks Given the Lamport timestamps of two events, it is in general not possible to tell whether those events are concurrent or whether one happened before the other. Delivery order in broadcast protocols \u00b6 How to achieve fault tolerance in replication Read-afet-write consistency","title":"Broadcast protocols and logical time"},{"location":"Distributed%20Systems/Broadcast%20protocols%20and%20logical%20time/Broadcast%20protocols%20and%20logical%20time/#delivery-order-in-broadcast-protocols","text":"How to achieve fault tolerance in replication Read-afet-write consistency","title":"Delivery order in broadcast protocols"},{"location":"Distributed%20Systems/Introduction/About%20distributed%20systems/","text":"Why make a system distributed? Reason Example Some applications are inherently distributed Sending a message from your phone to your friend's phone. For better reliability The system as a whole keeps functioning even if one node fails. For better performance Get data from a nearby node rather than one halfway around the world. To solve bigger problems Huge amounts of data which can't fit on one machine. Why not make a system distributed? Reason Example Communication may fail Process may crash Fault tolerance Distributed systems and computer networking \u00b6 Note The study of distributed systems builds upon computer networks, and instead focuses on how several nodes should coordinate by computer networks to achieve some shared task. So the detail about networking is not important. Example: Remote Procedure Calls (RPC) \u00b6 RPC The type of interaction, where code on one node appears to call a function on another node, is called a Remote Procedure Call. How RPC works? When an application wishes to call a function on another node, the RPC framework provides a stub in its place. The stub has the same type signature as the real function, but instead of executing the real function, it encodes the function arguments in a message and sends that message to the remote node, asking for that function to be called. REST Today, the most common form of RPC is implemented using JSON data sent over HTTP. A popular set of design principles for such HTTP-based APIs is known as representational state transfer or REST, and APIs that adhere to these principles are called RESTful. These principles include: communication is stateless (each request is self-contained and independent from other requests), resources (objects that can be inspected and manipulated) are represented by URLs, and the state of a resource is updated by making a HTTP request with a standard method type, such as POST or PUT, to the appropriate URL. The popularity of REST is due to the fact that JavaScript code running in a web browser can easily make this type of HTTP request. IDL When different programming languages are used, the RPC framework needs to convert datatypes such that the caller\u2019s arguments are understood by the code being called, and likewise for the function\u2019s return value. A typical solution is to use an Interface Definition Language (IDL) to provide language-independent type signatures of the functions that are being made available over RPC. From the IDL, software developers can then automatically generate marshalling/unmarshalling code and RPC stubs for the respective programming languages of each service and its clients. message PaymentRequest { message Card { required string cardNumber = 1; optional int32 expiryMonth = 2; optional int32 expiryYear = 3; optional int32 CVC = 4; } enum Currency { GBP = 1; USD = 2; } required Card card= 1; required int64 amount= 2; required Currency currency = 3; } message PaymentStatus { required bool success = 1; optional string errorMessage = 2; } service PaymentService { rpc ProcessPayment(PaymentRequest) returns(PaymentStatus) {} }","title":"About distributed systems"},{"location":"Distributed%20Systems/Introduction/About%20distributed%20systems/#distributed-systems-and-computer-networking","text":"Note The study of distributed systems builds upon computer networks, and instead focuses on how several nodes should coordinate by computer networks to achieve some shared task. So the detail about networking is not important.","title":"Distributed systems and computer networking"},{"location":"Distributed%20Systems/Introduction/About%20distributed%20systems/#example-remote-procedure-calls-rpc","text":"RPC The type of interaction, where code on one node appears to call a function on another node, is called a Remote Procedure Call. How RPC works? When an application wishes to call a function on another node, the RPC framework provides a stub in its place. The stub has the same type signature as the real function, but instead of executing the real function, it encodes the function arguments in a message and sends that message to the remote node, asking for that function to be called. REST Today, the most common form of RPC is implemented using JSON data sent over HTTP. A popular set of design principles for such HTTP-based APIs is known as representational state transfer or REST, and APIs that adhere to these principles are called RESTful. These principles include: communication is stateless (each request is self-contained and independent from other requests), resources (objects that can be inspected and manipulated) are represented by URLs, and the state of a resource is updated by making a HTTP request with a standard method type, such as POST or PUT, to the appropriate URL. The popularity of REST is due to the fact that JavaScript code running in a web browser can easily make this type of HTTP request. IDL When different programming languages are used, the RPC framework needs to convert datatypes such that the caller\u2019s arguments are understood by the code being called, and likewise for the function\u2019s return value. A typical solution is to use an Interface Definition Language (IDL) to provide language-independent type signatures of the functions that are being made available over RPC. From the IDL, software developers can then automatically generate marshalling/unmarshalling code and RPC stubs for the respective programming languages of each service and its clients. message PaymentRequest { message Card { required string cardNumber = 1; optional int32 expiryMonth = 2; optional int32 expiryYear = 3; optional int32 CVC = 4; } enum Currency { GBP = 1; USD = 2; } required Card card= 1; required int64 amount= 2; required Currency currency = 3; } message PaymentStatus { required bool success = 1; optional string errorMessage = 2; } service PaymentService { rpc ProcessPayment(PaymentRequest) returns(PaymentStatus) {} }","title":"Example: Remote Procedure Calls (RPC)"},{"location":"Distributed%20Systems/Models%20of%20distributed%20systems/Models%20of%20distributed%20systems/","text":"The two generals problem The Two Generals' Problem is a thought experiment meant to illustrate the pitfalls and design challenges of attempting to coordinate an action by communicating over an unreliable link. Here is an example to adapt the model to the application of paying for goods in an online shop. The Byzantine generals problem \u00b6 Byzantine fault It is a condition where components may fail and there is imperfect information on whether a component has failed. Describing nodes and network behaviour \u00b6","title":"Models of distributed systems"},{"location":"Distributed%20Systems/Models%20of%20distributed%20systems/Models%20of%20distributed%20systems/#the-byzantine-generals-problem","text":"Byzantine fault It is a condition where components may fail and there is imperfect information on whether a component has failed.","title":"The Byzantine generals problem"},{"location":"Distributed%20Systems/Models%20of%20distributed%20systems/Models%20of%20distributed%20systems/#describing-nodes-and-network-behaviour","text":"","title":"Describing nodes and network behaviour"},{"location":"Distributed%20Systems/Time%2Cclocks%2Cand%20ordering%20of%20events/clock/","text":"Why distributed systems need clock? Schedulers, timeouts, failure detectors, retry timers timeout-based failure detectors need to measure time to determine when a timeout has elapsed. Performance measurements, statistics, profiling Log files & databases record when an event occurred Two types of clock Type Definition Physical clocks count number of seconds elapsed Logical clocks count events Clock synchronisation and monotonic clocks \u00b6 Causality and happens-before \u00b6 happens-before relation Happens-before relation is a relation between the result of two events, such that if one event should happen before another event.","title":"Clock"},{"location":"Distributed%20Systems/Time%2Cclocks%2Cand%20ordering%20of%20events/clock/#clock-synchronisation-and-monotonic-clocks","text":"","title":"Clock synchronisation and monotonic clocks"},{"location":"Distributed%20Systems/Time%2Cclocks%2Cand%20ordering%20of%20events/clock/#causality-and-happens-before","text":"happens-before relation Happens-before relation is a relation between the result of two events, such that if one event should happen before another event.","title":"Causality and happens-before"},{"location":"DistributedStys/","text":"Goals of distributed systems Goal Definition Making resource available Distribution transparency Access, Loaction, Migration, Relocation, Replication, concurrency, failure Openness System should conform to well-defined interfaces, support portability of applications and easily interoperate. Scalability policy vs. mechanism Take scheduling processes for example, policy is that \"OS can schedule\", mechanism is that \"how to schedule these processes\" Types of Distributed Systems Distributed computing systems Distributed information systems Distributed pervasive systems Distributed Computing Systems Cluster Computing Homogeneous:same OS; Grid Computing heterogeneous; Dispersed across several organizations; Span a wide-area network Why replication? Reliability Avoid single points of failure Performance Scalability in numbers and geographic areas Data-centric model and Client-centric model Data-centric consistency models aim at providing a systemwide consistent view on a data store. It deals with concurrent wrting. Client-centric model aims at dealing with these cases where users may sometimes operate on different replicas while updates have not been fully propagated. Consistency model Strict Consistency Rely on absolute global time Linearizability timestap order Sequential no requirement for timestap order Casual Writes that are potentially causally related must be seen by all processes in the same order FIFO Writes done by a single process are seen by all other process in the order in which they are issued, but writes from different processes may be seen in adifferent order by different process Weak Access to synchronization variables associated with a data store are sequentially consistent Release Entry Monotonic Reads If a process reads the value of a data item x, any successive read operation on x by that process will always return that same value or a more recent value. Monotonic Writes A write operation by a process on a data item x is completed before any successive write operation on x by the same process. Read your writes The effect of a write operation by a process on data item x will always be seen by a successive read operation on x by the same process. Push vs. Pull protocols In push protocols, the client opens a connection to the server and keeps it constantly active. The server will send (push) all new events to the client using that single always-on connection. In other words, the server PUSHes the new events to the client. In pull protocols, the client periodically connects to the server, checks for and gets (pulls) recent events and then closes the connection and disconnects from the server. The client repeats this whole procedure to get updated about new events. In this mode, the clients periodically PULLs the new events from the server. Primary-based protocols reomte-Write protocols local-write protocols Replicated Write protocols Active replication: require a process for each replica, that can perform the update on it. Quorum-based protocols: $V_r+V_w>V$ $V_w > V/2$ RPC Server crash solution Wait until the server reboots and try the operation again. Give up immediately and report black failure. Guarantee nothing. Client crash solutions Before send an RPC, make a log Entry Divide time up into sequentially numbered epochs. When a client reboots, it brocasts ameesage declaring the start of a new epoch. When broadcast comes, all remote computations are killed. Each RPC is given a standard amout of time. Advantage of Dynamic Binding Flexibility Can support multiple servers that support the same interface The binder can verify that both client and server are using the same version of the interface Disadvantages of Dynamic binding Extra overhead of exporting/importing interfaces The binder may become a bottleneck in alarge distributed system Transient/Persistent Messaging Transient: The sender puts the message on the net and id it cannot be delivered to the sender or to the next communication host, it is lost Persistent: The message is stored in the communication syatems","title":"Index"},{"location":"DistributedStys/Architectures/Architectural%20styles/","text":"software architecture The logical organization of a distributed system also means its software architecture. Layered architectures \u00b6 Note The basic idea for the layered style is simple: components are organized in a layered fashion where a component at layer $L_j$ can make a downcall to a component at a lower-level layer $L_i$ (with i < j) and generally expects a response. Only in exceptional cases will an upcall be made to a higher-level component. (a):shows a standard organization in which only downcalls to the next lower layer are made. This organization is commonly deployed in the case of network communication. (b): Consider, for example, an application A that makes use of a library $L_{OS}$ to interface to an operating system. At the same time, the application uses a specialized mathematical library $L_{math}$ that has been implemented by also making use of $L_{OS}$. In this case, referring to Figure 2.1(b), A is implemented at layer $N \u2212 1$, $L_{math}$ at layer $N \u2212 2$, and $L_{OS}$ which is common to both of them, at layer $N \u2212 3$. (c):A typical example is when an operating system signals the occurrence of an event, to which end it calls a user-defined operation for which an application had previously passed a reference (typically referred to as a handle). Layered communication protocols \u00b6 from socket import * s = socket ( AF_INET , SOCK_STREAM ) ( conn , addr ) = s . accept () # returns new socket and addr. client while True : # forever data = conn . recv ( 1024 ) # receive data from client if not data : break # stop if client stopped conn . send ( str ( data ) + \"*\" ) # return sent data plus an \"*\" conn . close () # close the connection from socket import * s = socket ( AF_INET , SOCK_STREAM ) s . connect (( HOST , PORT )) # connect to server (block until accepted) # send some data s . send ( \u2019 Hello , world \u2019 ) # send some data = s . recv ( 1024 ) # receive the response print data # print the result s . close () # close the connection Application layering \u00b6 Application layering A large class of distributed applications is targeted toward supporting user or application access to databases, many people have advocated a distinc- tion between three logical levels, essentially following a layered architectural style: The application-interface level The processing level The data level As a first example, consider an Internet search engine. Ignoring all the ani- mated banners, images, and other fancy window dressing, the user interface of a search engine can be very simple: a user types in a string of keywords and is subsequently presented with a list of titles of Web pages. The back end is formed by a huge database of Web pages that have been prefetched and indexed. The core of the search engine is a program that transforms the user\u2019s string of keywords into one or more database queries. It subsequently ranks the results into a list, and transforms that list into a series of HTML pages. This information retrieval part is typically placed at the processing level. Object-based and service-oriented architectures \u00b6 Note In essence, each object corresponds to what we have defined as a component, and these components are connected through a procedure call mechanism. Object-based architectures are attractive because they provide a natural way of encapsulating data (called an object\u2019s state) and the operations that can be performed on that data (which are referred to as an object\u2019s methods) into a single entity.","title":"Architectural styles"},{"location":"DistributedStys/Architectures/Architectural%20styles/#layered-architectures","text":"Note The basic idea for the layered style is simple: components are organized in a layered fashion where a component at layer $L_j$ can make a downcall to a component at a lower-level layer $L_i$ (with i < j) and generally expects a response. Only in exceptional cases will an upcall be made to a higher-level component. (a):shows a standard organization in which only downcalls to the next lower layer are made. This organization is commonly deployed in the case of network communication. (b): Consider, for example, an application A that makes use of a library $L_{OS}$ to interface to an operating system. At the same time, the application uses a specialized mathematical library $L_{math}$ that has been implemented by also making use of $L_{OS}$. In this case, referring to Figure 2.1(b), A is implemented at layer $N \u2212 1$, $L_{math}$ at layer $N \u2212 2$, and $L_{OS}$ which is common to both of them, at layer $N \u2212 3$. (c):A typical example is when an operating system signals the occurrence of an event, to which end it calls a user-defined operation for which an application had previously passed a reference (typically referred to as a handle).","title":"Layered architectures"},{"location":"DistributedStys/Architectures/Architectural%20styles/#layered-communication-protocols","text":"from socket import * s = socket ( AF_INET , SOCK_STREAM ) ( conn , addr ) = s . accept () # returns new socket and addr. client while True : # forever data = conn . recv ( 1024 ) # receive data from client if not data : break # stop if client stopped conn . send ( str ( data ) + \"*\" ) # return sent data plus an \"*\" conn . close () # close the connection from socket import * s = socket ( AF_INET , SOCK_STREAM ) s . connect (( HOST , PORT )) # connect to server (block until accepted) # send some data s . send ( \u2019 Hello , world \u2019 ) # send some data = s . recv ( 1024 ) # receive the response print data # print the result s . close () # close the connection","title":"Layered communication protocols"},{"location":"DistributedStys/Architectures/Architectural%20styles/#application-layering","text":"Application layering A large class of distributed applications is targeted toward supporting user or application access to databases, many people have advocated a distinc- tion between three logical levels, essentially following a layered architectural style: The application-interface level The processing level The data level As a first example, consider an Internet search engine. Ignoring all the ani- mated banners, images, and other fancy window dressing, the user interface of a search engine can be very simple: a user types in a string of keywords and is subsequently presented with a list of titles of Web pages. The back end is formed by a huge database of Web pages that have been prefetched and indexed. The core of the search engine is a program that transforms the user\u2019s string of keywords into one or more database queries. It subsequently ranks the results into a list, and transforms that list into a series of HTML pages. This information retrieval part is typically placed at the processing level.","title":"Application layering"},{"location":"DistributedStys/Architectures/Architectural%20styles/#object-based-and-service-oriented-architectures","text":"Note In essence, each object corresponds to what we have defined as a component, and these components are connected through a procedure call mechanism. Object-based architectures are attractive because they provide a natural way of encapsulating data (called an object\u2019s state) and the operations that can be performed on that data (which are referred to as an object\u2019s methods) into a single entity.","title":"Object-based and service-oriented architectures"},{"location":"DistributedStys/Communication/Foundations/","text":"","title":"Foundations"},{"location":"DistributedStys/Communication/Remote%20procedure%20call/","text":"RPC When a process on machine A calls a procedure on machine B, the calling process on A is suspended, and execution of the called procedure takes place on B. Information can be transported from the caller to the callee in the parameters and can come back in the procedure result. No message passing at all is visible to the programmer. This method is known as remote procedure call, or often just RPC. Basic RPC operation \u00b6 Strps of RPC The client procedure calls the client stub in the normal way. The client stub builds a message and calls the local operating system. 3.The client\u2019s OS sends the message to the remote OS. 4.The remote OS gives the message to the server stub. 5.The server stub unpacks the parameter(s) and calls the server. 6.The server does the work and returns the result to the stub. 7.The server stub packs the result in a message and calls its local OS. 8.The server\u2019s OS sends the message to the client\u2019s OS. 9.The client\u2019s OS gives the message to the client stub. 10.The stub unpacks the result and returns it to the client.","title":"Remote procedure call"},{"location":"DistributedStys/Communication/Remote%20procedure%20call/#basic-rpc-operation","text":"Strps of RPC The client procedure calls the client stub in the normal way. The client stub builds a message and calls the local operating system. 3.The client\u2019s OS sends the message to the remote OS. 4.The remote OS gives the message to the server stub. 5.The server stub unpacks the parameter(s) and calls the server. 6.The server does the work and returns the result to the stub. 7.The server stub packs the result in a message and calls its local OS. 8.The server\u2019s OS sends the message to the client\u2019s OS. 9.The client\u2019s OS gives the message to the client stub. 10.The stub unpacks the result and returns it to the client.","title":"Basic RPC operation"},{"location":"DistributedStys/Consistency%20and%20replication/Data-centic%20consistency%20models/","text":"Consistency model A consistency model basically refers to the degree of consistency that should be maintained for the shared memory data. Continuous consistency \u00b6 Consistent ordering of operations \u00b6 Note Type Definition Sequential consistency Given an execution history, could it have resulted from reordering concurrent operations such that the order of operations within a process is maintained. Casual consistency Writes that are potentially causally related must be seen by all processes in the same order. Concurrent writes may be seen in a different order on different machines.","title":"Data centic consistency models"},{"location":"DistributedStys/Consistency%20and%20replication/Data-centic%20consistency%20models/#continuous-consistency","text":"","title":"Continuous consistency"},{"location":"DistributedStys/Consistency%20and%20replication/Data-centic%20consistency%20models/#consistent-ordering-of-operations","text":"Note Type Definition Sequential consistency Given an execution history, could it have resulted from reordering concurrent operations such that the order of operations within a process is maintained. Casual consistency Writes that are potentially causally related must be seen by all processes in the same order. Concurrent writes may be seen in a different order on different machines.","title":"Consistent ordering of operations"},{"location":"DistributedStys/Consistency%20and%20replication/Introduction/","text":"Reasons for replication \u00b6 Note Reason Increase the reliability of a system. Performance","title":"Introduction"},{"location":"DistributedStys/Consistency%20and%20replication/Introduction/#reasons-for-replication","text":"Note Reason Increase the reliability of a system. Performance","title":"Reasons for replication"},{"location":"DistributedStys/Coordination/Clock%20synchronization/","text":"The Berkeley algorithm \u00b6 Note The time server will poll every machine from time to time to ask for the time and compute the average time ans send to others. The Berkeley algorithm is thus typically an internal clock synchronization algorithm.","title":"Clock synchronization"},{"location":"DistributedStys/Coordination/Clock%20synchronization/#the-berkeley-algorithm","text":"Note The time server will poll every machine from time to time to ask for the time and compute the average time ans send to others. The Berkeley algorithm is thus typically an internal clock synchronization algorithm.","title":"The Berkeley algorithm"},{"location":"DistributedStys/Coordination/Election%20Algorithms/","text":"","title":"Election Algorithms"},{"location":"DistributedStys/Coordination/Logic%20clocks/","text":"logical clocks A logical clock is a mechanism for capturing chronological and causal relationships in a distributed system. Distributed systems may have no physically synchronous global clock, so a logical clock allows global ordering on events from different processes in such systems. Lamport\u2019s logical clocks \u00b6 Lamport\u2019s logical clocks For Lamport\u2019s logical clocks, each process maintains a local counter $C_i$. These counters are updated according to the following steps: Before executing an event, $P_i$ increments $C_i$ : $C_i <- C_i + 1$ When process Pi sends a message m to process $P_j$, it sets m\u2019s timestamp ts(m) equal to $C_i$ after having executed the previous step. Upon the receipt of a message m, process $P_j$ adjusts its own local counter as $C_j$ \u2190 max { $C_j$ , ts(m)} after which it then executes the first step and delivers the message to the application. Example: Total-ordered multicasting \u00b6 // need to read more Vector clocks \u00b6 vector clocks A vector clock is a data structure used for determining the partial ordering of events in a distributed system and detecting causality violations.","title":"Logic clocks"},{"location":"DistributedStys/Coordination/Logic%20clocks/#lamports-logical-clocks","text":"Lamport\u2019s logical clocks For Lamport\u2019s logical clocks, each process maintains a local counter $C_i$. These counters are updated according to the following steps: Before executing an event, $P_i$ increments $C_i$ : $C_i <- C_i + 1$ When process Pi sends a message m to process $P_j$, it sets m\u2019s timestamp ts(m) equal to $C_i$ after having executed the previous step. Upon the receipt of a message m, process $P_j$ adjusts its own local counter as $C_j$ \u2190 max { $C_j$ , ts(m)} after which it then executes the first step and delivers the message to the application.","title":"Lamport\u2019s logical clocks"},{"location":"DistributedStys/Coordination/Logic%20clocks/#example-total-ordered-multicasting","text":"// need to read more","title":"Example: Total-ordered multicasting"},{"location":"DistributedStys/Coordination/Logic%20clocks/#vector-clocks","text":"vector clocks A vector clock is a data structure used for determining the partial ordering of events in a distributed system and detecting causality violations.","title":"Vector clocks"},{"location":"DistributedStys/Coordination/Mutual%20exclusion/","text":"categories of distributed mutual exclusion algorithms type advantage disadvantage token-based solutions 1. avoid starvation 2. avoid deadlock When the token is lost, an intricate distributed procedure needs to be started permission-based approach Note Algorithm Definition Advantage Disadvantage Graphics A centralized algorithm A process is elected as the coordinator. Whenever a process wants to access a shared resource, it send request to the coordinator for permission. 1. It's fair. 2. No starvation. 3. Easy to implement. 1. If the coordinator crashes, the entire system may go down.2.a single coordinator can become a performance bottleneck. A distributed algorithm When a process wants to access a shared resource, it sends the message to all other and then sits back and waits until everyone else has given permission. 1. No starvation. 2. No deadlock. 1. Any process crashes will cause the entire system to fail. 2. Multicast communication will lead to much resource consumption. A token-ring algorithm Token circulates aroud the ring and when a process acquires the token, it checks to see if it needs to access the shared resouce. 1. No starvation. 1. If the token is ever lost, it must be regenerated. A decentralized algorithm Each resource is assumed to be replicated N times. Every replica has its own coordinator for controlling the access by concurrent processes. whenever a process wants to access the resource, it will simply need to get a majority vote from m > N/2 coordinators. 1. When a coordinator crashes, it recovers quickly but will have forgotten any vote it gave before it crashed. 2. If many nodes want to access the same resource, it turns out that the utilization rapidly drops.","title":"Mutual exclusion"},{"location":"DistributedStys/Fault%20tolerance/Distributed%20commit/","text":"","title":"Distributed commit"},{"location":"DistributedStys/Fault%20tolerance/Introduction%20to%20fault%20tolerance/","text":"fault tolerance A distributed system needs to be fault-tolerant, which means that whenever a failure occurs, the system should continue to operate in an acceptable way. Basic concepts \u00b6 Requirements for a dependable system Being fault-tolerant is strongly re4lated to what are called dependable systems. There is a need to see the requirements for a dependable system. Requirement Definition Availability It refers to the property that the system is operating correctly at any given moment . Reliability It refers to the property that a system is operating correctly during a time interval . Safety It refers to the situation that when a system temporarily fails to operate correctly, no catastrophic event happens. Maintainability It refers to how easily a failed system can be repaired. fault vs. error vs. failure A fault causes an error and an error results in a failure. Failure models \u00b6 Failure masking by redundancy \u00b6 How to improve dependability? Type of redundancy Definition Information redundancy Extra bits are added to allow recovery from garbled bits. (eg. hamming code) Time redundancy An action is performed, and then, if need be, it is performed again. (TCP) Physical Redundancy Extra equipment or processes are added to make it possible for the system as a whole to tolerate the loss or malfunctioning of some components.","title":"Introduction to fault tolerance"},{"location":"DistributedStys/Fault%20tolerance/Introduction%20to%20fault%20tolerance/#basic-concepts","text":"Requirements for a dependable system Being fault-tolerant is strongly re4lated to what are called dependable systems. There is a need to see the requirements for a dependable system. Requirement Definition Availability It refers to the property that the system is operating correctly at any given moment . Reliability It refers to the property that a system is operating correctly during a time interval . Safety It refers to the situation that when a system temporarily fails to operate correctly, no catastrophic event happens. Maintainability It refers to how easily a failed system can be repaired. fault vs. error vs. failure A fault causes an error and an error results in a failure.","title":"Basic concepts"},{"location":"DistributedStys/Fault%20tolerance/Introduction%20to%20fault%20tolerance/#failure-models","text":"","title":"Failure models"},{"location":"DistributedStys/Fault%20tolerance/Introduction%20to%20fault%20tolerance/#failure-masking-by-redundancy","text":"How to improve dependability? Type of redundancy Definition Information redundancy Extra bits are added to allow recovery from garbled bits. (eg. hamming code) Time redundancy An action is performed, and then, if need be, it is performed again. (TCP) Physical Redundancy Extra equipment or processes are added to make it possible for the system as a whole to tolerate the loss or malfunctioning of some components.","title":"Failure masking by redundancy"},{"location":"DistributedStys/Fault%20tolerance/Process%20resilience/","text":"Group organization |Type|Definition|Advantages|Disadvantages|Graph| |-|-| |Flat group| All processes are equal|No single point of failure|Complicated| | |Hierarchical group|One process is the coordinator.|Easy to implement.|Loss of the coordinator brings the entire group to a grinding halt|src=\"../img/08-04b.png\" alt=\"l\" style=\"width:400px;\"/>| Failure masking and replication \u00b6 How many replicas? For K falut tolerant: Assumption: a process does not collude with another process |Type of fault|| |Fail-silent faults|K+1| |Byzantine faults|2K+1| Paxos \u00b6 \u76ee\u6807\uff1aproposer\u54113\u4e2aaceptort \u5c06name\u53d8\u91cf\u5199\u4e3av1\u3002 * \u7b2c\u4e00\u9636\u6bb5A\uff1aproposer\u53d1\u8d77prepare\uff08name\uff0cn1\uff09,n1\u662f\u9012\u589e\u63d0\u8bae\u7248\u672c\u53f7\uff0c\u53d1\u9001\u7ed93\u4e2aAcceptor\uff0c\u8bf4\uff0c\u6211\u73b0\u5728\u8981\u5199name\u8fd9\u4e2a\u53d8\u91cf\uff0c\u6211\u7684\u7248\u672c\u53f7\u662fn1 * \u7b2c\u4e00\u9636\u6bb5B\uff1aAcceptor\u6536\u5230proposer\u7684\u6d88\u606f\uff0c\u6bd4\u5bf9\u81ea\u5df1\u5185\u90e8\u4fdd\u5b58\u7684\u5185\u5bb9\uff0c\u53d1\u73b0\u4e4b\u524dname\u53d8\u91cf\uff08null\uff0cnull\uff09\u6ca1\u6709\u88ab\u5199\u5165\u4e14\u672a\u6536\u5230\u8fc7\u63d0\u8bae\uff0c\u90fd\u8fd4\u56de\u7ed9proposer\uff0c\u5e76\u5728\u5185\u90e8\u8bb0\u5f55name\u8fd9\u4e2a\u53d8\u91cf\uff0c\u5df2\u7ecf\u6709proposer\u7533\u8bf7\u63d0\u8bae\u4e86\uff0c\u63d0\u8bae\u7248\u672c\u53f7\u662fn1; * \u7b2c\u4e8c\u9636\u6bb5A\uff1aproposer\u6536\u52303\u4e2aAcceptor\u7684\u54cd\u5e94\uff0c\u54cd\u5e94\u5185\u5bb9\u90fd\u662f\uff1aname\u53d8\u91cf\u73b0\u5728\u8fd8\u6ca1\u6709\u5199\u5165\uff0c\u4f60\u53ef\u4ee5\u6765\u5199\u3002proposer\u786e\u8ba4\u83b7\u5f97\u8d85\u8fc7\u534a\u6570\u4ee5\u4e0aAcceptor\u540c\u610f\uff0c\u53d1\u8d77\u7b2c\u4e8c\u9636\u6bb5\u5199\u5165\u64cd\u4f5c\uff1aaccept\uff08v1,n1\uff09\uff0c\u544a\u8bc9Acceptor\u6211\u73b0\u5728\u8981\u628aname\u53d8\u91cf\u534f\u8baev1,\u6211\u7684\u7248\u672c\u53f7\u662f\u521a\u521a\u83b7\u5f97\u901a\u8fc7\u7684n1; * \u7b2c\u4e8c\u9636\u6bb5B\uff1aaccpetor\u6536\u5230accept\uff08v1,n1\uff09\uff0c\u6bd4\u5bf9\u81ea\u8eab\u7684\u7248\u672c\u53f7\u662f\u4e00\u81f4\u7684\uff0c\u4fdd\u5b58\u6210\u529f\uff0c\u5e76\u54cd\u5e94accepted\uff08v1,n1\uff09\uff1b * \u7ed3\u679c\u9636\u6bb5\uff1aproposer\u6536\u52303\u4e2aaccepted\u54cd\u5e94\u90fd\u6210\u529f\uff0c\u8d85\u8fc7\u534a\u6570\u54cd\u5e94\u6210\u529f\uff0c\u5230\u6b64name\u53d8\u91cf\u88ab\u786e\u5b9a\u4e3av1\u3002 \u60c5\u51b5\u4e8c\uff1a3\u4e2aaccpetor\uff0c\u4f46\u6709\u4e24\u4e2aproposer\u3002proposer1\u548cproposer2\u4ea4\u9519\u6267\u884c proposer1\u63d0\u8baeaccpetor1\u6210\u529f\uff0c\u4f46\u5199\u5165accpetor2\u548caccpetor3\u65f6\uff0c\u53d1\u73b0\u7248\u672c\u53f7\u5df2\u7ecf\u5c0f\u4e8eaccpetor\u5185\u90e8\u8bb0\u5f55\u7684\u7248\u672c\u53f7\uff08\u4fdd\u5b58\u4e86proposer2\u7684\u7248\u672c\u53f7\uff09\uff0c\u76f4\u63a5\u8fd4\u56de\u5931\u8d25\u3002 proposer2\u5199\u5165accpetor2\u548caccpetor3\u6210\u529f\uff0c\u5199\u5165accpetor1\u5931\u8d25\uff0c\u4f46\u6700\u7ec8\u8fd8\u662f\u8d85\u8fc7\u534a\u6570\u5199\u5165v2\u6210\u529f\uff0cname\u53d8\u91cf\u6700\u7ec8\u786e\u5b9a\u4e3av2\uff1b proposer1\u9012\u589e\u7248\u672c\u53f7\u518d\u91cd\u8bd5\u53d1\u73b0\u8d85\u8fc7\u534a\u6570\u4e3av2\uff0c\u63a5\u53d7name\u53d8\u91cf\u4e3av2\uff0c\u4e5f\u4e0d\u518d\u5199\u5165v1\u3002name\u6700\u7ec8\u786e\u5b9a\u8fd8\u662f\u4e3av2","title":"Process resilience"},{"location":"DistributedStys/Fault%20tolerance/Process%20resilience/#failure-masking-and-replication","text":"How many replicas? For K falut tolerant: Assumption: a process does not collude with another process |Type of fault|| |Fail-silent faults|K+1| |Byzantine faults|2K+1|","title":"Failure masking and replication"},{"location":"DistributedStys/Fault%20tolerance/Process%20resilience/#paxos","text":"\u76ee\u6807\uff1aproposer\u54113\u4e2aaceptort \u5c06name\u53d8\u91cf\u5199\u4e3av1\u3002 * \u7b2c\u4e00\u9636\u6bb5A\uff1aproposer\u53d1\u8d77prepare\uff08name\uff0cn1\uff09,n1\u662f\u9012\u589e\u63d0\u8bae\u7248\u672c\u53f7\uff0c\u53d1\u9001\u7ed93\u4e2aAcceptor\uff0c\u8bf4\uff0c\u6211\u73b0\u5728\u8981\u5199name\u8fd9\u4e2a\u53d8\u91cf\uff0c\u6211\u7684\u7248\u672c\u53f7\u662fn1 * \u7b2c\u4e00\u9636\u6bb5B\uff1aAcceptor\u6536\u5230proposer\u7684\u6d88\u606f\uff0c\u6bd4\u5bf9\u81ea\u5df1\u5185\u90e8\u4fdd\u5b58\u7684\u5185\u5bb9\uff0c\u53d1\u73b0\u4e4b\u524dname\u53d8\u91cf\uff08null\uff0cnull\uff09\u6ca1\u6709\u88ab\u5199\u5165\u4e14\u672a\u6536\u5230\u8fc7\u63d0\u8bae\uff0c\u90fd\u8fd4\u56de\u7ed9proposer\uff0c\u5e76\u5728\u5185\u90e8\u8bb0\u5f55name\u8fd9\u4e2a\u53d8\u91cf\uff0c\u5df2\u7ecf\u6709proposer\u7533\u8bf7\u63d0\u8bae\u4e86\uff0c\u63d0\u8bae\u7248\u672c\u53f7\u662fn1; * \u7b2c\u4e8c\u9636\u6bb5A\uff1aproposer\u6536\u52303\u4e2aAcceptor\u7684\u54cd\u5e94\uff0c\u54cd\u5e94\u5185\u5bb9\u90fd\u662f\uff1aname\u53d8\u91cf\u73b0\u5728\u8fd8\u6ca1\u6709\u5199\u5165\uff0c\u4f60\u53ef\u4ee5\u6765\u5199\u3002proposer\u786e\u8ba4\u83b7\u5f97\u8d85\u8fc7\u534a\u6570\u4ee5\u4e0aAcceptor\u540c\u610f\uff0c\u53d1\u8d77\u7b2c\u4e8c\u9636\u6bb5\u5199\u5165\u64cd\u4f5c\uff1aaccept\uff08v1,n1\uff09\uff0c\u544a\u8bc9Acceptor\u6211\u73b0\u5728\u8981\u628aname\u53d8\u91cf\u534f\u8baev1,\u6211\u7684\u7248\u672c\u53f7\u662f\u521a\u521a\u83b7\u5f97\u901a\u8fc7\u7684n1; * \u7b2c\u4e8c\u9636\u6bb5B\uff1aaccpetor\u6536\u5230accept\uff08v1,n1\uff09\uff0c\u6bd4\u5bf9\u81ea\u8eab\u7684\u7248\u672c\u53f7\u662f\u4e00\u81f4\u7684\uff0c\u4fdd\u5b58\u6210\u529f\uff0c\u5e76\u54cd\u5e94accepted\uff08v1,n1\uff09\uff1b * \u7ed3\u679c\u9636\u6bb5\uff1aproposer\u6536\u52303\u4e2aaccepted\u54cd\u5e94\u90fd\u6210\u529f\uff0c\u8d85\u8fc7\u534a\u6570\u54cd\u5e94\u6210\u529f\uff0c\u5230\u6b64name\u53d8\u91cf\u88ab\u786e\u5b9a\u4e3av1\u3002 \u60c5\u51b5\u4e8c\uff1a3\u4e2aaccpetor\uff0c\u4f46\u6709\u4e24\u4e2aproposer\u3002proposer1\u548cproposer2\u4ea4\u9519\u6267\u884c proposer1\u63d0\u8baeaccpetor1\u6210\u529f\uff0c\u4f46\u5199\u5165accpetor2\u548caccpetor3\u65f6\uff0c\u53d1\u73b0\u7248\u672c\u53f7\u5df2\u7ecf\u5c0f\u4e8eaccpetor\u5185\u90e8\u8bb0\u5f55\u7684\u7248\u672c\u53f7\uff08\u4fdd\u5b58\u4e86proposer2\u7684\u7248\u672c\u53f7\uff09\uff0c\u76f4\u63a5\u8fd4\u56de\u5931\u8d25\u3002 proposer2\u5199\u5165accpetor2\u548caccpetor3\u6210\u529f\uff0c\u5199\u5165accpetor1\u5931\u8d25\uff0c\u4f46\u6700\u7ec8\u8fd8\u662f\u8d85\u8fc7\u534a\u6570\u5199\u5165v2\u6210\u529f\uff0cname\u53d8\u91cf\u6700\u7ec8\u786e\u5b9a\u4e3av2\uff1b proposer1\u9012\u589e\u7248\u672c\u53f7\u518d\u91cd\u8bd5\u53d1\u73b0\u8d85\u8fc7\u534a\u6570\u4e3av2\uff0c\u63a5\u53d7name\u53d8\u91cf\u4e3av2\uff0c\u4e5f\u4e0d\u518d\u5199\u5165v1\u3002name\u6700\u7ec8\u786e\u5b9a\u8fd8\u662f\u4e3av2","title":"Paxos"},{"location":"DistributedStys/Introduction/Summary/","text":"","title":"Index"},{"location":"DistributedStys/Introduction/TypeOfDisSys/","text":"We make a distinction between distributed computing systems, distributed information systems, and pervasive systems. cluster computing vs. grid computing vs. cloud computing In cluster computing, the underlying hardware consists of a collection of similar workstations or PCs connected by LAN. But in grid computing, the subgroup consists of distributed systems that are different when it comes to hardware, software, and deployed network technology. As for cloud computing, it provides the facilities to dynamically construct an infrastructure and compose what is needed from avaliable services. Cluster computing \u00b6 Here we give two examples about cluster computing: Beowulf clusters Apart from the master node, the compute nodes are seen to be highly identical. The master handles the allocation of nodes and manages the jobs and provides an interface for the users of the systems. MOSIX system MOSIX attemps to provide a single-system image by allowing processes to dynamically and preemptively migrate between the nodes that make up the cluster. However, several morden cluster computers have moved to more hybrid solutions where middleware is functionally patitioned across different nodes, becuase compute nodes with dedicated middleware will most likely provide optimal performance. Grid computing \u00b6 Architecture A traditional architecture is shown below. This architecture consists of 4 layers. The fabric layer provides tailored interfaces to allow sharing resources within a virtual organization. The connectivity layer consists of communication protocols for supportinggrid transactions. The resource layer is responsible for managing a single resource. The collective layer deals with handling access to multiple resources. The application layer consists of the applications that operate within a virtual organization Cloud computing \u00b6 Utility computing, which means a customer could upload tasks to a data center and be charged on a per-resource basis formed the basis for what is now called cloud computing. Architecture In practice, clouds are organized into four layers. The Infrastructure deployes virtualization techniques to provide customers an infrastructure consisting of virtual storage and computing resources. The platform layer provides to a cloud-computing customer what an operating system provides to application developers, namely the means to easily develop and deploy applications that need to run in a cloud, somewhat like exec command in Unix. Cloud-computing providers offer these layers to their customers through various interface , leading to three different types to service. different types of services Infrastructure-as-a-Service (IaaS) covering the hardware and infrastructure layer. Platform-as-a-Service (PaaS) covering the platform layer. Software-as-a-Service (SaaS) in which their applications are covered. Distributed information systems \u00b6 Distributed transaction processing \u00b6 ACID Atomic: To the outside world, the transaction happens indivisibly. Consistent: The transaction does not violate system invariants. Isolated: Concurrent transactions do not interfere with each other. Durable: Once a transaction commits, the changes are permanent. nested transaction In distributed systems, transactions are often constructed as a number of subtransactions, jointly forming a nested transaction as shown below. The top-level transaction may fork off children that run in parallel with one another, on different machines, to gain performnance or simplify programming. Each of these children may also execute one or more subtractions, or fork off its own children. Enterprise application integration \u00b6 The need for interapplication communication led to many different communication models. The main idea was that existing applications could directlyexchange information. RPC vs RMI With RPC, an application component can effectively send a request to another application component by doing a local procedure call, which results in the request being packaged as a message and sent to th calle. Likewise, the result will be sent back and returned to the application as the result of procedure call. An RMI is essentially the same as an RPC, except that it operates on objects instead of functions. RPC and RMI have the disadvantage that the caller and callee both need to be up and running at the time of communication. In addition, they need to know exactly how to refer to each other. -> solution : message-oriented middleware. Pervasive systems \u00b6 Ubiquitous computing systems \u00b6 Ubiquitous computing systems Mobile computing systems \u00b6 Sensor networks \u00b6","title":"Index"},{"location":"DistributedStys/Introduction/TypeOfDisSys/#cluster-computing","text":"Here we give two examples about cluster computing: Beowulf clusters Apart from the master node, the compute nodes are seen to be highly identical. The master handles the allocation of nodes and manages the jobs and provides an interface for the users of the systems. MOSIX system MOSIX attemps to provide a single-system image by allowing processes to dynamically and preemptively migrate between the nodes that make up the cluster. However, several morden cluster computers have moved to more hybrid solutions where middleware is functionally patitioned across different nodes, becuase compute nodes with dedicated middleware will most likely provide optimal performance.","title":"Cluster computing"},{"location":"DistributedStys/Introduction/TypeOfDisSys/#grid-computing","text":"Architecture A traditional architecture is shown below. This architecture consists of 4 layers. The fabric layer provides tailored interfaces to allow sharing resources within a virtual organization. The connectivity layer consists of communication protocols for supportinggrid transactions. The resource layer is responsible for managing a single resource. The collective layer deals with handling access to multiple resources. The application layer consists of the applications that operate within a virtual organization","title":"Grid computing"},{"location":"DistributedStys/Introduction/TypeOfDisSys/#cloud-computing","text":"Utility computing, which means a customer could upload tasks to a data center and be charged on a per-resource basis formed the basis for what is now called cloud computing. Architecture In practice, clouds are organized into four layers. The Infrastructure deployes virtualization techniques to provide customers an infrastructure consisting of virtual storage and computing resources. The platform layer provides to a cloud-computing customer what an operating system provides to application developers, namely the means to easily develop and deploy applications that need to run in a cloud, somewhat like exec command in Unix. Cloud-computing providers offer these layers to their customers through various interface , leading to three different types to service. different types of services Infrastructure-as-a-Service (IaaS) covering the hardware and infrastructure layer. Platform-as-a-Service (PaaS) covering the platform layer. Software-as-a-Service (SaaS) in which their applications are covered.","title":"Cloud computing"},{"location":"DistributedStys/Introduction/TypeOfDisSys/#distributed-information-systems","text":"","title":"Distributed information systems"},{"location":"DistributedStys/Introduction/TypeOfDisSys/#distributed-transaction-processing","text":"ACID Atomic: To the outside world, the transaction happens indivisibly. Consistent: The transaction does not violate system invariants. Isolated: Concurrent transactions do not interfere with each other. Durable: Once a transaction commits, the changes are permanent. nested transaction In distributed systems, transactions are often constructed as a number of subtransactions, jointly forming a nested transaction as shown below. The top-level transaction may fork off children that run in parallel with one another, on different machines, to gain performnance or simplify programming. Each of these children may also execute one or more subtractions, or fork off its own children.","title":"Distributed transaction processing"},{"location":"DistributedStys/Introduction/TypeOfDisSys/#enterprise-application-integration","text":"The need for interapplication communication led to many different communication models. The main idea was that existing applications could directlyexchange information. RPC vs RMI With RPC, an application component can effectively send a request to another application component by doing a local procedure call, which results in the request being packaged as a message and sent to th calle. Likewise, the result will be sent back and returned to the application as the result of procedure call. An RMI is essentially the same as an RPC, except that it operates on objects instead of functions. RPC and RMI have the disadvantage that the caller and callee both need to be up and running at the time of communication. In addition, they need to know exactly how to refer to each other. -> solution : message-oriented middleware.","title":"Enterprise application integration"},{"location":"DistributedStys/Introduction/TypeOfDisSys/#pervasive-systems","text":"","title":"Pervasive systems"},{"location":"DistributedStys/Introduction/TypeOfDisSys/#ubiquitous-computing-systems","text":"Ubiquitous computing systems","title":"Ubiquitous computing systems"},{"location":"DistributedStys/Introduction/TypeOfDisSys/#mobile-computing-systems","text":"","title":"Mobile computing systems"},{"location":"DistributedStys/Introduction/TypeOfDisSys/#sensor-networks","text":"","title":"Sensor networks"},{"location":"DistributedStys/Processes/Clients/","text":"Networked user interfaces \u00b6 Two means for users to interact with remote servers Type characteristic example for each remote service the client machine will have a separate counterpart that can contact the service over the network. calendar thin-client provide direct access to remote services by offering only a convenient user interface, this means that the client machine is used only as a terminal with no need for local storage ATM Example: The X window system \u00b6","title":"Clients"},{"location":"DistributedStys/Processes/Clients/#networked-user-interfaces","text":"Two means for users to interact with remote servers Type characteristic example for each remote service the client machine will have a separate counterpart that can contact the service over the network. calendar thin-client provide direct access to remote services by offering only a convenient user interface, this means that the client machine is used only as a terminal with no need for local storage ATM","title":"Networked user interfaces"},{"location":"DistributedStys/Processes/Clients/#example-the-x-window-system","text":"","title":"Example: The X window system"},{"location":"DistributedStys/Processes/Servers/","text":"Concurrent versus iterative servers \u00b6 Two ways to organize servers type characteristic iterative server the server itself handles the request and, if necessary, returns a response to the requesting client concurrent server It does not handle the request itself, but passes it to a separate thread or another process, after which it immediately waits for the next incoming request. Contacting a server: end points \u00b6 Service without a preassigned end point type characteristics Client-to-server binding using a daemon The daemon keeps track of the current end point of each service implemented by a co-located server. The daemon itself listens to a well-known end point. A client will first contact the daemon, request the end point, and then contact the specific server. Client-to-server binding using a superserver have a single superserver listening to each end point associated with a specific service.When a request comes in, the daemon forks a process to handle it. (eg,inetd) Interrupting a server \u00b6 How to interrupt a server? Ways characteristics Users abruptly exit the client application Send out-of-band data Stateless versus stateful servers \u00b6 State of servers Type Characteristics examples stateless server not keep information on the state of its clients, and can change its own state without having to inform any client A Web Server soft state The server promises to maintain state on behalf of the client, but only for a limited time A server promising to keep a client informed about updates, but only for a limited time. stateful server maintains persistent information on its clients A file server that allows a client to keep a local copy of a file, even for performing update operations. cookies Information that often transparently stored by the client\u2019s browser will be sent to the server. Object servers \u00b6 Example: The Apache Web server \u00b6","title":"Servers"},{"location":"DistributedStys/Processes/Servers/#concurrent-versus-iterative-servers","text":"Two ways to organize servers type characteristic iterative server the server itself handles the request and, if necessary, returns a response to the requesting client concurrent server It does not handle the request itself, but passes it to a separate thread or another process, after which it immediately waits for the next incoming request.","title":"Concurrent versus iterative servers"},{"location":"DistributedStys/Processes/Servers/#contacting-a-server-end-points","text":"Service without a preassigned end point type characteristics Client-to-server binding using a daemon The daemon keeps track of the current end point of each service implemented by a co-located server. The daemon itself listens to a well-known end point. A client will first contact the daemon, request the end point, and then contact the specific server. Client-to-server binding using a superserver have a single superserver listening to each end point associated with a specific service.When a request comes in, the daemon forks a process to handle it. (eg,inetd)","title":"Contacting a server: end points"},{"location":"DistributedStys/Processes/Servers/#interrupting-a-server","text":"How to interrupt a server? Ways characteristics Users abruptly exit the client application Send out-of-band data","title":"Interrupting a server"},{"location":"DistributedStys/Processes/Servers/#stateless-versus-stateful-servers","text":"State of servers Type Characteristics examples stateless server not keep information on the state of its clients, and can change its own state without having to inform any client A Web Server soft state The server promises to maintain state on behalf of the client, but only for a limited time A server promising to keep a client informed about updates, but only for a limited time. stateful server maintains persistent information on its clients A file server that allows a client to keep a local copy of a file, even for performing update operations. cookies Information that often transparently stored by the client\u2019s browser will be sent to the server.","title":"Stateless versus stateful servers"},{"location":"DistributedStys/Processes/Servers/#object---servers","text":"","title":"Object   servers"},{"location":"DistributedStys/Processes/Servers/#example-the-apache-web-server","text":"","title":"Example: The Apache Web server"},{"location":"DistributedStys/Processes/Threads/","text":"Thread implementation \u00b6 Note Threads are often provided in the form of a thread package in user space or in kernel space. Advantage of user-level thread cheap to create and destroy threads (only need to allocate memory to set up a thread stack) cheap in context switch (few ubstructions) LWP Threads in distributed systems \u00b6 Multithreaded clients \u00b6 Multithreaded servers \u00b6 Three ways to construct a server Model Character Advantage Disadvantage Multithreading Parallelism, blocking system calls easy for programming and allow for parallelism Single-threaded process No parallelism, blocking system calls simple and easy to program hinder performance Finite-state machine Parallelism, nonblocking system calls achieves high performance hard to program","title":"Threads"},{"location":"DistributedStys/Processes/Threads/#thread-implementation","text":"Note Threads are often provided in the form of a thread package in user space or in kernel space. Advantage of user-level thread cheap to create and destroy threads (only need to allocate memory to set up a thread stack) cheap in context switch (few ubstructions) LWP","title":"Thread implementation"},{"location":"DistributedStys/Processes/Threads/#threads-in-distributed-systems","text":"","title":"Threads in distributed systems"},{"location":"DistributedStys/Processes/Threads/#multithreaded-clients","text":"","title":"Multithreaded clients"},{"location":"DistributedStys/Processes/Threads/#multithreaded-servers","text":"Three ways to construct a server Model Character Advantage Disadvantage Multithreading Parallelism, blocking system calls easy for programming and allow for parallelism Single-threaded process No parallelism, blocking system calls simple and easy to program hinder performance Finite-state machine Parallelism, nonblocking system calls achieves high performance hard to program","title":"Multithreaded servers"},{"location":"DistributedStys/Processes/Virtualization/","text":"Virtualization and distributed systems \u00b6 Why distributed systems need virtualization? portability is greatly improved as virtual machines provide a further decoupling between hardware and software, allowing a complete environment to be moved from one machine to another. Imporatnt in the context of reliability and security for (distributed) systems as it allows for the isolation of a complete application and its environment, a failure caused by an error or security attack need no longer affect a complete machine. Types of virtualization \u00b6 Three different types of virtualization Type Characteristic Advantage A process virtual machine Virtualization is only for a single process A native virtual machine monitor Interface offered by a virtual machine monitor can be offered simultaneously to different programs Different guest operating systems can run independently and concurrently on the same platform. A hosted virtual machine monitor Make use of existing facilities provided by that host operating system Easy to implement Application of virtual machines to distributed systems \u00b6 Three different types service provided by cloud Service Characteristic Infrastructure-as-a-Service (IaaS) covering the basic infrastructure Platform-as-a-Service (PaaS) covering system-level services Software-as-a-Service (SaaS) containing actual applications Virtualization plays a key role in IaaS. Instead of renting out a physical machine, a cloud provider will rent out a virtual machine (monitor) that may, or may not, be sharing a physical machine with other customers.","title":"Virtualization"},{"location":"DistributedStys/Processes/Virtualization/#virtualization-and-distributed-systems","text":"Why distributed systems need virtualization? portability is greatly improved as virtual machines provide a further decoupling between hardware and software, allowing a complete environment to be moved from one machine to another. Imporatnt in the context of reliability and security for (distributed) systems as it allows for the isolation of a complete application and its environment, a failure caused by an error or security attack need no longer affect a complete machine.","title":"Virtualization and distributed systems"},{"location":"DistributedStys/Processes/Virtualization/#types-of-virtualization","text":"Three different types of virtualization Type Characteristic Advantage A process virtual machine Virtualization is only for a single process A native virtual machine monitor Interface offered by a virtual machine monitor can be offered simultaneously to different programs Different guest operating systems can run independently and concurrently on the same platform. A hosted virtual machine monitor Make use of existing facilities provided by that host operating system Easy to implement","title":"Types of virtualization"},{"location":"DistributedStys/Processes/Virtualization/#application-of-virtual-machines-to-distributed-systems","text":"Three different types service provided by cloud Service Characteristic Infrastructure-as-a-Service (IaaS) covering the basic infrastructure Platform-as-a-Service (PaaS) covering system-level services Software-as-a-Service (SaaS) containing actual applications Virtualization plays a key role in IaaS. Instead of renting out a physical machine, a cloud provider will rent out a virtual machine (monitor) that may, or may not, be sharing a physical machine with other customers.","title":"Application of virtual machines to distributed systems"},{"location":"Hotspot/AllStatic/CompileBroker/CompileBroker/","text":"CompileBroker \u00b6 Description \u00b6 Private Attributeds \u00b6 Public Attributes \u00b6 Static Attributes \u00b6 bool _initialized bool _should_block jint _should_compile_new_jobs This flag can be used to stop compilation or turn it back on int _c1_count, _c2_count The maximum number of compiler threads to be determined during startup jobject *_compiler1_objects, *compiler2_objects jint _compilation_id, _osr_compilation_id Private Member Functions \u00b6 Public Member Functions \u00b6","title":"CompileBroker"},{"location":"Hotspot/AllStatic/CompileBroker/CompileBroker/#compilebroker","text":"","title":"CompileBroker"},{"location":"Hotspot/AllStatic/CompileBroker/CompileBroker/#description","text":"","title":"Description"},{"location":"Hotspot/AllStatic/CompileBroker/CompileBroker/#private-attributeds","text":"","title":"Private Attributeds"},{"location":"Hotspot/AllStatic/CompileBroker/CompileBroker/#public-attributes","text":"","title":"Public Attributes"},{"location":"Hotspot/AllStatic/CompileBroker/CompileBroker/#static-attributes","text":"bool _initialized bool _should_block jint _should_compile_new_jobs This flag can be used to stop compilation or turn it back on int _c1_count, _c2_count The maximum number of compiler threads to be determined during startup jobject *_compiler1_objects, *compiler2_objects jint _compilation_id, _osr_compilation_id","title":"Static Attributes"},{"location":"Hotspot/AllStatic/CompileBroker/CompileBroker/#private-member-functions","text":"","title":"Private Member Functions"},{"location":"Hotspot/AllStatic/CompileBroker/CompileBroker/#public-member-functions","text":"","title":"Public Member Functions"},{"location":"Hotspot/AllStatic/SharedRuntime/SharedRuntime/","text":"Description \u00b6 Private Attributeds \u00b6 Public Attributes \u00b6 Static Attributes \u00b6 | RuntimeStub* _wrong_method_blob | Handle call site that has been made non-entrant and return the callee's interpretation entry.| | RuntimeStub* _wrong_method_abstract_blob |Handle abstract method call| ||| Private Member Functions \u00b6 Public Member Functions \u00b6","title":"SharedRuntime"},{"location":"Hotspot/AllStatic/SharedRuntime/SharedRuntime/#description","text":"","title":"Description"},{"location":"Hotspot/AllStatic/SharedRuntime/SharedRuntime/#private-attributeds","text":"","title":"Private Attributeds"},{"location":"Hotspot/AllStatic/SharedRuntime/SharedRuntime/#public-attributes","text":"","title":"Public Attributes"},{"location":"Hotspot/AllStatic/SharedRuntime/SharedRuntime/#static-attributes","text":"| RuntimeStub* _wrong_method_blob | Handle call site that has been made non-entrant and return the callee's interpretation entry.| | RuntimeStub* _wrong_method_abstract_blob |Handle abstract method call| |||","title":"Static Attributes"},{"location":"Hotspot/AllStatic/SharedRuntime/SharedRuntime/#private-member-functions","text":"","title":"Private Member Functions"},{"location":"Hotspot/AllStatic/SharedRuntime/SharedRuntime/#public-member-functions","text":"","title":"Public Member Functions"},{"location":"Hotspot/AllStatic/StubRoutines/StubRoutines/","text":"Description \u00b6 Private Attributeds \u00b6 Public Attributes \u00b6 Static Attributes \u00b6 Private Member Functions \u00b6 Public Member Functions \u00b6","title":"StubRoutines"},{"location":"Hotspot/AllStatic/StubRoutines/StubRoutines/#description","text":"","title":"Description"},{"location":"Hotspot/AllStatic/StubRoutines/StubRoutines/#private-attributeds","text":"","title":"Private Attributeds"},{"location":"Hotspot/AllStatic/StubRoutines/StubRoutines/#public-attributes","text":"","title":"Public Attributes"},{"location":"Hotspot/AllStatic/StubRoutines/StubRoutines/#static-attributes","text":"","title":"Static Attributes"},{"location":"Hotspot/AllStatic/StubRoutines/StubRoutines/#private-member-functions","text":"","title":"Private Member Functions"},{"location":"Hotspot/AllStatic/StubRoutines/StubRoutines/#public-member-functions","text":"","title":"Public Member Functions"},{"location":"Hotspot/AllocatedObj/AllocatedObj/","text":"","title":"AllocatedObj"},{"location":"Hotspot/AllocatedObj/StackObj/StackObj/","text":"","title":"StackObj"},{"location":"Hotspot/AllocatedObj/StackObj/RegisterMap/RegisterMap/","text":"Description \u00b6 Public Member Functions \u00b6 Private Member Functions \u00b6 Private Attributeds \u00b6 Public Attributes \u00b6","title":"RegisterMap"},{"location":"Hotspot/AllocatedObj/StackObj/RegisterMap/RegisterMap/#description","text":"","title":"Description"},{"location":"Hotspot/AllocatedObj/StackObj/RegisterMap/RegisterMap/#public-member-functions","text":"","title":"Public Member Functions"},{"location":"Hotspot/AllocatedObj/StackObj/RegisterMap/RegisterMap/#private-member-functions","text":"","title":"Private Member Functions"},{"location":"Hotspot/AllocatedObj/StackObj/RegisterMap/RegisterMap/#private-attributeds","text":"","title":"Private Attributeds"},{"location":"Hotspot/AllocatedObj/StackObj/RegisterMap/RegisterMap/#public-attributes","text":"","title":"Public Attributes"},{"location":"Hotspot/frame/frame/","text":"Description \u00b6 Private Attributeds \u00b6 intptr_t* sp stack pointer address _pc program counter (the next instruction after this call) CodeBlob* _cb Codeblob that owns pc Public Attributes \u00b6 Private Member Functions \u00b6 Public Member Functions \u00b6","title":"Frame"},{"location":"Hotspot/frame/frame/#description","text":"","title":"Description"},{"location":"Hotspot/frame/frame/#private-attributeds","text":"intptr_t* sp stack pointer address _pc program counter (the next instruction after this call) CodeBlob* _cb Codeblob that owns pc","title":"Private Attributeds"},{"location":"Hotspot/frame/frame/#public-attributes","text":"","title":"Public Attributes"},{"location":"Hotspot/frame/frame/#private-member-functions","text":"","title":"Private Member Functions"},{"location":"Hotspot/frame/frame/#public-member-functions","text":"","title":"Public Member Functions"},{"location":"InsideTheC%2B%2BObjectModel/Readme/","text":"VTable Notes on Multiple Inheritance in GCC C++ Compiler \u00b6","title":"Readme"},{"location":"InsideTheC%2B%2BObjectModel/Readme/#vtable-notes-on-multiple-inheritance-in-gcc-c-compiler","text":"","title":"VTable Notes on Multiple Inheritance in GCC C++ Compiler"},{"location":"Is%20Parallel%20Programming%20Hard%3F/Introduction/Parallel%20Programming%20Goals/","text":"Performance \u00b6","title":"Parallel Programming Goals"},{"location":"Is%20Parallel%20Programming%20Hard%3F/Introduction/Parallel%20Programming%20Goals/#performance","text":"","title":"Performance"},{"location":"Is%20Parallel%20Programming%20Hard%3F/Tools%20of%20the%20Trade/POSIX%20Multiprocessing/","text":"4.2.1 POSIX Process Creation and Destruction \u00b6 primitives Name Definition fork() Create a process. kill() Kill a process. exit() Destroy a process. wait() Wait on its children. Processes Created Via fork() Do Not Share Memory int x = 0 ; int main ( int argc , char * argv []) { int pid ; pid = fork (); if ( pid == 0 ) { /* child */ x = 1 ; printf ( \"Child process set x=1 \\n \" ); exit ( EXIT_SUCCESS ); } if ( pid < 0 ) { /* parent, upon error */ perror ( \"fork\" ); exit ( EXIT_FAILURE ); } /* parent */ waitall (); printf ( \"Parent process sees x=%d \\n \" , x ); return EXIT_SUCCESS ; } 4.2.2 POSIX Thread Creation and Destruction \u00b6 note pthread_create() Create a thread within an existing process. pthread_exit() Threads Created Via pthread_create() Share Memory 1 int x = 0 ; 2 3 void * mythread ( void * arg ) 4 { 5 x = 1 ; 6 printf ( \"Child process set x=1 \\n \" ); 7 return NULL ; 8 } 9 10 int main ( int argc , char * argv []) 11 { 12 int en ; 13 pthread_t tid ; 14 void * vp ; 15 16 if (( en = pthread_create ( & tid , NULL , 17 mythread , NULL )) != 0 ) { 18 fprintf ( stderr , \"pthread_create: %s \\n \" , strerror ( en )); 19 exit ( EXIT_FAILURE ); 20 } 21 22 /* parent */ 23 24 if (( en = pthread_join ( tid , & vp )) != 0 ) { 25 fprintf ( stderr , \"pthread_join: %s \\n \" , strerror ( en )); 26 exit ( EXIT_FAILURE ); 27 } 28 printf ( \"Parent process sees x=%d \\n \" , x ); 29 30 return EXIT_SUCCESS ; 31 } 4.2.3 POSIX Locking \u00b6 primitives pthread_mutex_lock() \"acquires\" the specified lock pthread_mutex_unlock() \"releases\u201d the specified lock. pthread_mutex_init() PTHREAD_MUTEX_INITIALIZER","title":"POSIX Multiprocessing"},{"location":"Is%20Parallel%20Programming%20Hard%3F/Tools%20of%20the%20Trade/POSIX%20Multiprocessing/#421-posix-process-creation-and-destruction","text":"primitives Name Definition fork() Create a process. kill() Kill a process. exit() Destroy a process. wait() Wait on its children. Processes Created Via fork() Do Not Share Memory int x = 0 ; int main ( int argc , char * argv []) { int pid ; pid = fork (); if ( pid == 0 ) { /* child */ x = 1 ; printf ( \"Child process set x=1 \\n \" ); exit ( EXIT_SUCCESS ); } if ( pid < 0 ) { /* parent, upon error */ perror ( \"fork\" ); exit ( EXIT_FAILURE ); } /* parent */ waitall (); printf ( \"Parent process sees x=%d \\n \" , x ); return EXIT_SUCCESS ; }","title":"4.2.1 POSIX Process Creation and Destruction"},{"location":"Is%20Parallel%20Programming%20Hard%3F/Tools%20of%20the%20Trade/POSIX%20Multiprocessing/#422-posix-thread-creation-and-destruction","text":"note pthread_create() Create a thread within an existing process. pthread_exit() Threads Created Via pthread_create() Share Memory 1 int x = 0 ; 2 3 void * mythread ( void * arg ) 4 { 5 x = 1 ; 6 printf ( \"Child process set x=1 \\n \" ); 7 return NULL ; 8 } 9 10 int main ( int argc , char * argv []) 11 { 12 int en ; 13 pthread_t tid ; 14 void * vp ; 15 16 if (( en = pthread_create ( & tid , NULL , 17 mythread , NULL )) != 0 ) { 18 fprintf ( stderr , \"pthread_create: %s \\n \" , strerror ( en )); 19 exit ( EXIT_FAILURE ); 20 } 21 22 /* parent */ 23 24 if (( en = pthread_join ( tid , & vp )) != 0 ) { 25 fprintf ( stderr , \"pthread_join: %s \\n \" , strerror ( en )); 26 exit ( EXIT_FAILURE ); 27 } 28 printf ( \"Parent process sees x=%d \\n \" , x ); 29 30 return EXIT_SUCCESS ; 31 }","title":"4.2.2 POSIX Thread Creation and Destruction"},{"location":"Is%20Parallel%20Programming%20Hard%3F/Tools%20of%20the%20Trade/POSIX%20Multiprocessing/#423-posix-locking","text":"primitives pthread_mutex_lock() \"acquires\" the specified lock pthread_mutex_unlock() \"releases\u201d the specified lock. pthread_mutex_init() PTHREAD_MUTEX_INITIALIZER","title":"4.2.3 POSIX Locking"},{"location":"Is%20Parallel%20Programming%20Hard%3F/Tools%20of%20the%20Trade/Scripting%20Language/","text":"Is there a simpler way to create a parallel shell script? If so, how? If not, why not? One straightforward approach is the shell pipeline grep $pattern1 | sed -e 's/a/b/' | sort For a sufficiently large intput file, grep will patternmatch in parallel with sed editing and with the input processing of sort But if script-based parallel programming is so easy, why bother with anything else? In fact, it is likely that a very large fraction of parallel programs in use today are script-based. However, script-based parallelism does have its limitations: Creation of new processes is usually quite heavy-weight, involving the expensive fork() and exec() system calls. Sharing of data, including pipelining, typically involves expensive file I/O. The reliable synchronization primitives available to scripts also involves expensive file I/O. Scripting languages are often too slow, but are often quite useful when coordinating execution of long-running programs written in lower-level program languages. These limitations require that script-based parallelism use coarse-grained parallelism, with each unit of work having execution time of at least tens of milliseconds, and perferably much longer.","title":"Scripting Language"},{"location":"JVM/","text":"bang mechanism The VM handles stack overflow by framing the stack arena with inaccessible guard pages, and intercepting the accesses to those guard pages to detect the case where a stack overflow occurred. That also requires and additional logic of actually probing the stack when putting a new activation record on it: by touching the stack down trying to trigger the guard page fault. This mechanism has a fancy name of \"stack banging\", and if we want to do anything below stack pointer, we need to communicate the additional banging to the runtime. registers \u00b6 number of registers rax 0 rcx 1 rdx 2 rbx 3 rsp 4 rbp 5 rsi 6 rdi 7 r8 8 r9 9 r10 10 r11 11 r12 12 r13 13 r14 14 r15 15 XMM registers XMM registers are separate registers introduced with SSE(Data transfer Instructions) and still widely used nowadays. They are 128 bits wide, with instructions that can treat them as arrays of 64, 32(integer and floating point), 16 or 8 bit(integer only) values. You have 8 of them in 32 bit mode, 16 in 64 bit. graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; How to create a Symbol SymbolTable::new_symbols public abstract class AbstractCoder { public abstract int abstractWork ( byte [] data ); } public interface Coder { int work ( byte [] data ); } public class Coder0 extends AbstractCoder implements Coder { public static int staticWork ( byte [] data ) { return data . length ; } @Override public int work ( byte [] data ) { return data . length ; } @Override public int abstractWork ( byte [] data ) { return data . length ; } } LIR: B1 [0, 0] sux: B0 __id_Instruction___________________________________________ 0 label [label:0x00007f2d44363f60] 2 std_entry B0 std [0, 0] preds: B1 __id_Instruction___________________________________________ 8 label [label:0x00007f2d44363680] 10 return void LIR_OpLabel::emit_code const Register IC_Klass = rax; // where the IC klass is cached opcode 0X8B movl x86 instruction format \u00b6 000000 00001 00010 00011 00000 100000 Opcode Rs Rt Rd Sh. Amt. Operation x86 instruction format X86 prefix \u00b6 prefix REX 0x4 PEX prefix \u00b6 Field 0100 W R X B Bits 7,6,5,4 3 2 1 0 MacroAssembler \u00b6 Stack frame creation/removal void enter(); void leave(); JVM\u4e4bKlass\u6a21\u578b","title":"Index"},{"location":"JVM/#registers","text":"number of registers rax 0 rcx 1 rdx 2 rbx 3 rsp 4 rbp 5 rsi 6 rdi 7 r8 8 r9 9 r10 10 r11 11 r12 12 r13 13 r14 14 r15 15 XMM registers XMM registers are separate registers introduced with SSE(Data transfer Instructions) and still widely used nowadays. They are 128 bits wide, with instructions that can treat them as arrays of 64, 32(integer and floating point), 16 or 8 bit(integer only) values. You have 8 of them in 32 bit mode, 16 in 64 bit. graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; How to create a Symbol SymbolTable::new_symbols public abstract class AbstractCoder { public abstract int abstractWork ( byte [] data ); } public interface Coder { int work ( byte [] data ); } public class Coder0 extends AbstractCoder implements Coder { public static int staticWork ( byte [] data ) { return data . length ; } @Override public int work ( byte [] data ) { return data . length ; } @Override public int abstractWork ( byte [] data ) { return data . length ; } } LIR: B1 [0, 0] sux: B0 __id_Instruction___________________________________________ 0 label [label:0x00007f2d44363f60] 2 std_entry B0 std [0, 0] preds: B1 __id_Instruction___________________________________________ 8 label [label:0x00007f2d44363680] 10 return void LIR_OpLabel::emit_code const Register IC_Klass = rax; // where the IC klass is cached opcode 0X8B movl","title":"registers"},{"location":"JVM/#x86-instruction-format","text":"000000 00001 00010 00011 00000 100000 Opcode Rs Rt Rd Sh. Amt. Operation x86 instruction format","title":"x86 instruction format"},{"location":"JVM/#x86-prefix","text":"prefix REX 0x4","title":"X86 prefix"},{"location":"JVM/#pex-prefix","text":"Field 0100 W R X B Bits 7,6,5,4 3 2 1 0","title":"PEX prefix"},{"location":"JVM/#macroassembler","text":"Stack frame creation/removal void enter(); void leave(); JVM\u4e4bKlass\u6a21\u578b","title":"MacroAssembler"},{"location":"Papers/","text":"Here I will record papers I will read or have read. [ ] Optimizing Dynamically-Typed Object-Oriented Languages WithPolymorphic Inline Caches [ ] Software Foundations Logo VOLUME 1: LOGICAL FOUNDATIONS [ ] Is Parallel Programming Hard, And, If So, What Can You Do About It? [ ] Erik Rigtorp's blogs about C++ [x] Optimizing Declarative Graph Queries at Large Scale","title":"Index"},{"location":"ReadingList/Compilers/","text":"Reading List \u00b6 Reading list by topic: \u00b6 Compilers \u00b6 CS143: Compilers at Stanford. CSCD70 Compiler Optimization at UTORONTO. Assignment Slides and Videos my repo CS164: Programming Languages and Compilers SP19 at UCB projects slides notes video CS243: Program Analysis and Optimization at Stanford. CS 598CM: Machine Learning for Compilers and Architecture at UIUC. CS 380C: Advanced Topics in Compilers at utexas. 6.035: Computer Language Engineering at MIT. CS 343: Advanced Topics in Compilers (SP12) at Stanford. CS 6120: Advanced Compilers (SP21) at Cornell. 15-411 Compiler Design at CMU. 15-745 Optimizing Compilers for Modern Architectures at CMU. CS 293S: Advanced Compiler Optimizations at UCSB. CS 738: Advanced Compiler Optimizations at iitk CSE 231: Advanced Compilers at UCSB CS294-113: Virtual Machines and Managed Runtimes at UCB Crafting Interpreters CMSC 838E: Advanced Compilers at UMD CS350: SECURE COMPILATION at Stanford. CS 397/497: Advanced Topics in Compilers at Northwestern University. Advanced Compiler Design CS252: Advanced Topics in PL at Harvard. CS526: Advanced Compiler Construction at UIUC CS164 Programming Languages and Compilers at UCB Slides HW project Virtual Machines Summer School CS420: Compiler Design at KAIST COMP 512: Advanced Compiler Construction at Rice CS 4120/4121/5120/5121 : Introduction to Compilers at Cornell. CSE 401: Compiler Construction at UW. CPSC 421/521 Compilers and Interpreters at Yale. CSCI 1260 at Brown. CIS 341: Compilers at upenn. CS421: Programming Languages at UIUC \u7f16\u8bd1\u6280\u672f\u5165\u95e8\u4e0e\u5b9e\u6218\u516c\u5f00\u8bfe","title":"Compilers"},{"location":"ReadingList/Compilers/#reading-list","text":"","title":"Reading List"},{"location":"ReadingList/Compilers/#reading-list-by-topic","text":"","title":"Reading list by topic:"},{"location":"ReadingList/Compilers/#compilers","text":"CS143: Compilers at Stanford. CSCD70 Compiler Optimization at UTORONTO. Assignment Slides and Videos my repo CS164: Programming Languages and Compilers SP19 at UCB projects slides notes video CS243: Program Analysis and Optimization at Stanford. CS 598CM: Machine Learning for Compilers and Architecture at UIUC. CS 380C: Advanced Topics in Compilers at utexas. 6.035: Computer Language Engineering at MIT. CS 343: Advanced Topics in Compilers (SP12) at Stanford. CS 6120: Advanced Compilers (SP21) at Cornell. 15-411 Compiler Design at CMU. 15-745 Optimizing Compilers for Modern Architectures at CMU. CS 293S: Advanced Compiler Optimizations at UCSB. CS 738: Advanced Compiler Optimizations at iitk CSE 231: Advanced Compilers at UCSB CS294-113: Virtual Machines and Managed Runtimes at UCB Crafting Interpreters CMSC 838E: Advanced Compilers at UMD CS350: SECURE COMPILATION at Stanford. CS 397/497: Advanced Topics in Compilers at Northwestern University. Advanced Compiler Design CS252: Advanced Topics in PL at Harvard. CS526: Advanced Compiler Construction at UIUC CS164 Programming Languages and Compilers at UCB Slides HW project Virtual Machines Summer School CS420: Compiler Design at KAIST COMP 512: Advanced Compiler Construction at Rice CS 4120/4121/5120/5121 : Introduction to Compilers at Cornell. CSE 401: Compiler Construction at UW. CPSC 421/521 Compilers and Interpreters at Yale. CSCI 1260 at Brown. CIS 341: Compilers at upenn. CS421: Programming Languages at UIUC \u7f16\u8bd1\u6280\u672f\u5165\u95e8\u4e0e\u5b9e\u6218\u516c\u5f00\u8bfe","title":"Compilers"},{"location":"Static%20Program%20Analysis/DFA-AP/","text":"Understand the three data flow analyses reaching definitions A definition d at program point p reaches a point q if there is a path from p to q such that d is not \u201ckilled\u201d along that path. That's to say, definition of variable v at program point p reaches point q if there is a path from p to q such that no new definition of v appears on that path. Reaching definitions can be used to detect possible undefined variables. live variables Live variables analysis tells whether the value of variable v at program point p could be used along some path in CFG starting at p. If so, v is live at p; otherwise, v is dead at p. available expressions An expression x op y is available at program point p if (1) allpaths from the entry to p mustpass through the evaluation of x op y, and (2) after the last evaluation of x op y, there is no redefinition of x or y Can tell the differences and similarities of the three data flow analyses Type Transfer Function Control Flow Algorithm Reaching Definition Analysis may analysis Live Variables Analysis may analysis (gen->kill) Available Expressions Analysis must analysis (kill->gen) Understand the iterative algorithm and can tell why it is able to terminate Out will not shrink. Set of facts is finite.","title":"DFA AP"},{"location":"Static%20Program%20Analysis/DFA-FD/","text":"Understand the functional view of iterative algorithm The iterative algorithm reaches a fixed point. The definitions of lattice and complete lattice How to summarize may and must analyses in lattices Understand the fixed-point theorem The relation between MOP and the solution produced by the iterative algorithm Constant propagation analysis Given a variable x at program point p, determine whether x is guaranteed to hold a constant value at p Worklist algorithm","title":"DFA FD"},{"location":"Static%20Program%20Analysis/Datalog/","text":"Datalog language Datalog is a declarative logic programming language that is a subset of Prolog. How to implement pointer analysis via Datalog How to implement taint analysis via Datalog","title":"Datalog"},{"location":"Static%20Program%20Analysis/IFDS/","text":"Understand CFL-Reachability A path is considered to connect two nodes A and B, or B is reachablefrom A, only if the concatenation of the labels on the edges of the pathis a word in a specified context-free language. Understand the basic idea of IFDS IFDS is for interprocedural data flow analysiswith distributive flow functions over finite domains. Understand what problems can be solved by IFDS Given a statement S, besides S itself, if we need to consider multiple input data facts to create correct outputs, then the analysis is not distributive and should not be expressed in IFDS. In IFDS, each data fact (circle) and its propagation (edges) could be handled independently, and doing so will not affect the correctness of the final results.","title":"IFDS"},{"location":"Static%20Program%20Analysis/IR/","text":"3AC There is at most one operator on the right side of an instruction. SSA(Static Single Assignment) All assignments in SSA are to variables with distinc names. The relation between compilers and static analyzers Understand 3AC and its common forms 3AC: There is at most one operator on the right side of an instruction. How to build basic blocks on top of IR How to construct control flow graphs on top of BBs?","title":"IR"},{"location":"Static%20Program%20Analysis/Inter/","text":"How to build call graph via class hierarchy analysis Concept of interprocedural control-flow graph An ICFG of a program consists of CFGs of the methods in the program, plus two kinds of additional edges: Call edges: from call sites to the entry nodes of their callees Return edges: from exit nodes of the callees to the statements following their call sites (i.e., return sites) Concept of interprocedural data-flow analysis Interprocedural constant propagation","title":"Inter"},{"location":"Static%20Program%20Analysis/PTA-CS/","text":"Concept of context sensitivity (C.S.) Context sensitivity models calling contexts by distinguishing different data flows of different contexts to improve precision Concept of context-sensitive heap (C.S. heap) The most common choice is to inherit contexts from the method where the object is allocated Why C.S. and C.S. heap improve precision In dynamic execution, an allocation site can create multiple objects under different calling contexts, different objects (allocated by the same site) may be manipulated with different data flows, e.g., stored different values to their fields. In pointer analysis, analyzing such code without heap contexts may lose precision by merging the data flows of different contexts to one abstract object.In contrast, distinguishing different objects from the same allocation site by heap contexts gains precision. Context-sensitive pointer analysis rules Algorithm for context-sensitive pointer analysis Common context sensitivity variants Call-site sensitivity Object sensitivity Type Sensitivity Differences and relationship among common context sensitivity variants In practice, object sensitivity generally outperforms call-site sensitivity for OO languages (like Java) Under the same k-limiting, the precision of type sensitivity is no better than object sensitivity","title":"PTA CS"},{"location":"Static%20Program%20Analysis/PTA-FD/","text":"Understand pointer analysis rules Understand pointer flow graph We use a graph to connect related pointers, When pt(\ud835\udc65) changes, propagate the changed part to \ud835\udc65\u2019s successors Understand pointer analysis algorithms Understand pointer analysis rule for method call Understand inter-procedural pointer analysis algorithm Understand on-the-fly call graph construction","title":"PTA FD"},{"location":"Static%20Program%20Analysis/PTA/","text":"What is pointer analysis? Computes an over-approximation of the set of objects that a pointer can point Understand the key factors of pointer analysis Understand what we analyze in pointer analysis We only focus on pointer-affecting statements","title":"PTA"},{"location":"Static%20Program%20Analysis/Security/","text":"Concept of information flow security Tracks how information flows through the program to make sure that the program handles the information securely. Concerns how information is propagated. Confidentiality and integrity Confidentiality Prevent secret information from being leaked Integrity Prevent untrusted information from corrupting (trusted) critical information Command injection,SQL injection,XSS attacks Explicit flows and covert channels Explicit flow: information flows through direct copying. Channels that exploit a mechanism whose primary purpose is not information transfer are called covert channels Use taint analysis to detect unwanted information flow Taint analysis tracks how tainted data flow through the program and observes if they can flow to locations of interest (called sinks). In practice, sinks are usually some sensitive methods.","title":"Security"},{"location":"Static%20Program%20Analysis/all/","text":"Security Information example Access control vs. Information Flow security Information flow Information flow policy Noninterference Confidentiality Integrity How does information Flow Implicit Flows Covert/Hidden Channels Taint Analysis Taint Analysis: Two Applications Taint and Pointer Analysis, Together Domains and Notations Taint Analysis: Inputs & Outputs Rules: Call Datalog Imperative vs Declrative Datalog ... Pointer Analysis via Datalog Datalog Model for Taint Analysis CFL-Reachablility and IFDS CFL-Reachability IFDS","title":"All"},{"location":"Static%20Program%20Analysis/introduction/","text":"What are the differences between static analysis and (dynamic) testing? Static analysis is done without executing any of the code; dynamic analysis relies on studying how the code behaves during execution. Understand soundness, completeness, false negatives, and false positives. Why soundness is usually required by static analysis? Soundness is critical to a collection of important (static-analysis) applications such as compiler optimization and program verification. Soundness is also preferable to other (static-analysis) applications for which soundness is not demanded, e.g., bug detection, as better soundness implies more bugs could be found. How to understand abstraction and over-approximation? Abstraction: Application-specific data Over-approximation: Not miss any bug!","title":"Introduction"},{"location":"TheArtOfCommandLine/","text":"The art of Command line \u00b6 Here I will give detailed examples of the command introduced in the repo . This is a very good repo that I think every programmer need to master every item mentioned in it. Use pgrep and pkill to find or signal processes by name ( -f is helpful) pgrep is a command-line utility that allows you to find the process IDs of a running program based on the given criteria.Here I give some examples of how to use it. Note use -l option to show the process name along with its ID: ## example 1: pgrep -l \"ssh\"","title":"Index"},{"location":"TheArtOfCommandLine/#the-art-of-command-line","text":"Here I will give detailed examples of the command introduced in the repo . This is a very good repo that I think every programmer need to master every item mentioned in it. Use pgrep and pkill to find or signal processes by name ( -f is helpful) pgrep is a command-line utility that allows you to find the process IDs of a running program based on the given criteria.Here I give some examples of how to use it. Note use -l option to show the process name along with its ID: ## example 1: pgrep -l \"ssh\"","title":"The art of Command line"},{"location":"TheArtOfCommandLine/item1/","text":"Bash AutoComplete In Bash, use Tab to complete arguments or list all available commands and ctrl-r to search through command history (after pressing, type to search, press ctrl-r repeatedly to cycle through more matches, press Enter to execute the found command, or hit the right arrow to put the result in the current line to allow editing).","title":"Item1"},{"location":"TheArtOfCommandLine/item10/","text":"Note Check what processes are listening via netstat -lntp or ss -plat (for TCP; add -u for UDP) or lsof -iTCP -sTCP:LISTEN -P -n (which also works on macOS).","title":"Item10"},{"location":"TheArtOfCommandLine/item11/","text":"See also lsof and fuser for open sockets and files.","title":"Item11"},{"location":"TheArtOfCommandLine/item12/","text":"See uptime or w to know how long the system has been running.","title":"Item12"},{"location":"TheArtOfCommandLine/item13/","text":"Use alias to create shortcuts for commonly used commands. For example, alias ll='ls -latr' creates a new alias ll .","title":"Item13"},{"location":"TheArtOfCommandLine/item14/","text":"Save aliases, shell settings, and functions you commonly use in ~/.bashrc , and arrange for login shells to source it. This will make your setup available in all your shell sessions.","title":"Item14"},{"location":"TheArtOfCommandLine/item2/","text":"move cursor ctrl-w : delete the last word, ctrl-u : delete the content from current cursor back to the start of the line. alt-b and alt-f : move by word ctrl-a : move cursor to beginning of line ctrl-e : move cursor to end of line ctrl-l : clear the screen. See man readline for all the default keybindings in Bash.","title":"Item2"},{"location":"TheArtOfCommandLine/item3/","text":"history To see recent commands, use history . Follow with !n (where n is the command number) to execute again. !$ stands for last argument and !! stands for last command. For example, when I executed ls -al , then !! means ls -al and !$ means -al","title":"Item3"},{"location":"TheArtOfCommandLine/item4/","text":"save a command If you are halfway through typing a command but change your mind, hit alt-# to add a # at the beginning and enter it as a comment","title":"Item4"},{"location":"TheArtOfCommandLine/item5/","text":"xargs xargs takes the data coming in on its standard input, splits it up, and uses it to run the command given in its arguments. By default, it splits on blanks or newlines, find + xargs find . -name \u201c*.b\u201d | xargs rm -rf This command will delete all file suffixed with .b in the current directory. find . -type f -not -name '*gz' -print0 | xargs -0 -I {} rm -v {} This shows how to delete all files within a directory except one or few files with a given extension. The -0 option instructs xargs to split its input on null bytes instead of blanks or newlines. Combined with find's -print0 , this allows filenames containing blanks or newlines to be handled properly. The -I option changes the way the new command lines are built. Instead of adding as many arguments as possible at a time, xargs will take one name at a time from its input, look for the given token ({} here) and replace that with the name. Let's see a another example: LearningCS \u00b1 | master | \u2192 find . -mindepth 1 -maxdepth 1 -print0 | xargs -0I {} echo {} ./requirements.txt ./.DS_Store ./update.sh ./.github ./README.md ./.git ./mkdocs.yml ./docs ./.vscode ./LICENSE","title":"Item5"},{"location":"TheArtOfCommandLine/item6/","text":"pstree pstree -p is a helpful display of the process tree.","title":"Item6"},{"location":"TheArtOfCommandLine/item7/","text":"pgrep and 'pkill' Use pgrep and pkill to find or signal processes by name ( -f is helpful) pgrep is a command-line utility that allows you to find the process IDs of a running program based on the given criteria. examples use ` -l ` option to show the process name along with its ID: ## example 1: pgrep -l \"ssh\"","title":"Item7"},{"location":"TheArtOfCommandLine/item8/","text":"Know the various signals you can send processes. There are many ways to send signals to processes. Use kill command to send a signal to a process. For example, you can suspend a process by suspend a process Use the UNIX system call kill (from a C program) to send signal from one process to another. int send_signal ( int pid ) { int ret ; ret = kill ( pid,SIGHUP ) ; printf ( \"ret : %d\" ,ret ) ; } When a process is running on the terminal, you can send signal to that process from the keyboard by using some specific combination of keys. Pressing Ctrl + C kills the running foreground process.","title":"Item8"},{"location":"TheArtOfCommandLine/item9/","text":"Use nohup or disown if you want a background process to keep running forever & puts the job in the background, that is, makes it block on attempting to read input, and makes the shell not wait for its completion. disown removes the process from the shell's job control, but it still leaves it connected to the terminal. One of the results is that the shell won't send it a SIGHUP . Obviously, it can only be applied to background jobs, because you cannot enter it when a foreground job is running. nohup disconnects the process from the terminal, redirects its output to nohup.out and shields it from SIGHUP. One of the effects (the naming one) is that the process won't receive any sent SIGHUP. It is completely independent from job control and could in principle be used also for foreground jobs (although that's not very useful).","title":"Item9"},{"location":"eBPF/","text":"Type of eBPF programs \u00b6 Map \u00b6 Map Helper Functions \u00b6 Function Name Functionality Space Notes bpf(BPF_MAP_CREATE,,) create a map Kernel & User bpf_map_update_elem() update elements Kernel & User BPF_NOEXIST : successs only when the key not exist ; BPF_EXIST : successs only when the key exist bpf_map_lookup_elem read elements from a BPF map Kernel & User bpf_map_delete_element removing an element from a BPF map Kernel & User bpf_map_get_next_key help iterate a map User bpf_map_lookup_and_delete_element looking up and deleting elements Kernel bpf_spin_lock lock an element bpf_spin_unlock unlock an elemnt bpf_obj_pin save the map in the filesystem /sys/fs/bpf/ bpf_obj_get loads that map from the file system Types pf BPF Maps \u00b6 Type Functionality Notes BPF_MAP_TYPE_HASH Useful for keeping structured data that\u2019s read frequently. BPF_MAP_TYPE_ARRAY Array maps are commonly used to store information that can change in value, but it\u2019s usually fixed in behavior. A disadvantage of using array maps is that the elements in the map cannot be removed and you cannot make the array smaller than it is. BPF_MAP_TYPE_PROG_ARRAY You can use this type of map to store references to BPF programs using their file descriptor identifiers which makes tail call possible. BPF_MAP_TYPE_HASH This type of map is useful if your BPF program collects metrics and aggregates them in hash-table maps. BPF_MAP_TYPE_ARRAY Useful for for high-performant lookups and aggregations. BPF_MAP_TYPE_STACK_TRACE stores stack traces from the running process BPF_MAP_TYPE_CGROUP_ARRAY stores references to cgroups. This map is useful when you want to share cgroup references between BPF maps for controlling traffic, debugging, and testing. BPF_MAP_TYPE_LRU_HASH / BPF_MAP_TYPE_LRU_PERCPU_HASH If the map is full, these maps will erase elements that are not used frequently to make room for new elements in the map. BPF_MAP_TYPE_LPM_TRIE LPM trie maps are types of map that use longest prefix match (LPM) to look up elements in the map. Require key sizes to be multiples of eight and in a range from 8 to 2,048. BPF_MAP_TYPE_ARRAY_OF_MAPS / BPF_MAP_TYPE_HASH_OF_MAPS store references to other maps These types of maps are useful when you want to be able to replace entire maps at runtime. BPF_MAP_TYPE_DEVMAP stores references to network devices. Useful for network applications that want to manipulate traffic at the kernel level. BPF_MAP_TYPE_XSKMAP stores references to open sockets. useful for forwarding packets BPF_MAP_TYPE_SOCKMAP / BPF_MAP_TYPE_SOCKHASH store references to open sockets in the kernel. BPF_MAP_TYPE_CGROUP_STORAGE / BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE BPF_MAP_TYPE_REUSEPORT_SOCKARRAY stores references to sockets that can be reused by an open port in the system BPF_MAP_TYPE_QUEUE BPF_MAP_TYPE_STACK Tracing with BPF \u00b6 Types of Probes \u00b6 Class Name Probe Name Notes Example Kernel Probes Kprobes Insert BPF programs before any kernel instruction is executed. Need to know the function signature Kernel Probes Kretprobes Insert your BPF program when a kernel instruction returns a value after being executed. Tracepoints Tracepoints are static markers in the kernel\u2019s code that you can use to attach code in a running kernel. Available tracepoints in your system by listing all the files in /sys/kernel/debug/tracing/events . User-Space Probes Uprobes Uprobes are hooks that the kernel inserts into a program\u2019s instruction set before a specific instruction is executed. User-Space Probes Uretprobes User Statically Defined Tracepoints(USDT) provide static tracepoints for applications in user-space. BPF Utilities \u00b6 BPFTool \u00b6 Command Functionality bpftool prog show Inspecting what eBPF programs you have running in your system bpftool prog show --json id 52 | jq -c '[.id, .type, .loaded_at]' bpftool prog dump xlated id 52 Dump the eBPF binary with id 52 sysctl -w kernel.bpf_stats_enabled=1 + bpftool prog show get two more pieces of information: run_cnt / run_time_ns pftool map show bpftool cgroup tree Linux Networking and BPF \u00b6 tcpdump -n 'ip and tcp port 8080' tcpdump -d 'ip and tcp port 8080'","title":"eBPF"},{"location":"eBPF/#type-of-ebpf-programs","text":"","title":"Type of eBPF programs"},{"location":"eBPF/#map","text":"","title":"Map"},{"location":"eBPF/#map-helper-functions","text":"Function Name Functionality Space Notes bpf(BPF_MAP_CREATE,,) create a map Kernel & User bpf_map_update_elem() update elements Kernel & User BPF_NOEXIST : successs only when the key not exist ; BPF_EXIST : successs only when the key exist bpf_map_lookup_elem read elements from a BPF map Kernel & User bpf_map_delete_element removing an element from a BPF map Kernel & User bpf_map_get_next_key help iterate a map User bpf_map_lookup_and_delete_element looking up and deleting elements Kernel bpf_spin_lock lock an element bpf_spin_unlock unlock an elemnt bpf_obj_pin save the map in the filesystem /sys/fs/bpf/ bpf_obj_get loads that map from the file system","title":"Map Helper Functions"},{"location":"eBPF/#types-pf-bpf-maps","text":"Type Functionality Notes BPF_MAP_TYPE_HASH Useful for keeping structured data that\u2019s read frequently. BPF_MAP_TYPE_ARRAY Array maps are commonly used to store information that can change in value, but it\u2019s usually fixed in behavior. A disadvantage of using array maps is that the elements in the map cannot be removed and you cannot make the array smaller than it is. BPF_MAP_TYPE_PROG_ARRAY You can use this type of map to store references to BPF programs using their file descriptor identifiers which makes tail call possible. BPF_MAP_TYPE_HASH This type of map is useful if your BPF program collects metrics and aggregates them in hash-table maps. BPF_MAP_TYPE_ARRAY Useful for for high-performant lookups and aggregations. BPF_MAP_TYPE_STACK_TRACE stores stack traces from the running process BPF_MAP_TYPE_CGROUP_ARRAY stores references to cgroups. This map is useful when you want to share cgroup references between BPF maps for controlling traffic, debugging, and testing. BPF_MAP_TYPE_LRU_HASH / BPF_MAP_TYPE_LRU_PERCPU_HASH If the map is full, these maps will erase elements that are not used frequently to make room for new elements in the map. BPF_MAP_TYPE_LPM_TRIE LPM trie maps are types of map that use longest prefix match (LPM) to look up elements in the map. Require key sizes to be multiples of eight and in a range from 8 to 2,048. BPF_MAP_TYPE_ARRAY_OF_MAPS / BPF_MAP_TYPE_HASH_OF_MAPS store references to other maps These types of maps are useful when you want to be able to replace entire maps at runtime. BPF_MAP_TYPE_DEVMAP stores references to network devices. Useful for network applications that want to manipulate traffic at the kernel level. BPF_MAP_TYPE_XSKMAP stores references to open sockets. useful for forwarding packets BPF_MAP_TYPE_SOCKMAP / BPF_MAP_TYPE_SOCKHASH store references to open sockets in the kernel. BPF_MAP_TYPE_CGROUP_STORAGE / BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE BPF_MAP_TYPE_REUSEPORT_SOCKARRAY stores references to sockets that can be reused by an open port in the system BPF_MAP_TYPE_QUEUE BPF_MAP_TYPE_STACK","title":"Types pf BPF Maps"},{"location":"eBPF/#tracing-with-bpf","text":"","title":"Tracing with BPF"},{"location":"eBPF/#types-of-probes","text":"Class Name Probe Name Notes Example Kernel Probes Kprobes Insert BPF programs before any kernel instruction is executed. Need to know the function signature Kernel Probes Kretprobes Insert your BPF program when a kernel instruction returns a value after being executed. Tracepoints Tracepoints are static markers in the kernel\u2019s code that you can use to attach code in a running kernel. Available tracepoints in your system by listing all the files in /sys/kernel/debug/tracing/events . User-Space Probes Uprobes Uprobes are hooks that the kernel inserts into a program\u2019s instruction set before a specific instruction is executed. User-Space Probes Uretprobes User Statically Defined Tracepoints(USDT) provide static tracepoints for applications in user-space.","title":"Types of Probes"},{"location":"eBPF/#bpf-utilities","text":"","title":"BPF Utilities"},{"location":"eBPF/#bpftool","text":"Command Functionality bpftool prog show Inspecting what eBPF programs you have running in your system bpftool prog show --json id 52 | jq -c '[.id, .type, .loaded_at]' bpftool prog dump xlated id 52 Dump the eBPF binary with id 52 sysctl -w kernel.bpf_stats_enabled=1 + bpftool prog show get two more pieces of information: run_cnt / run_time_ns pftool map show bpftool cgroup tree","title":"BPFTool"},{"location":"eBPF/#linux-networking-and-bpf","text":"tcpdump -n 'ip and tcp port 8080' tcpdump -d 'ip and tcp port 8080'","title":"Linux Networking and BPF"}]}